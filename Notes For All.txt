public class Name{

	public static void main(String[] args){
		String firstName;
		String	custName = "Sally Smith";
		int spaceIndex;
		
		//Get the  index of the space character " "
		spaceIndex = custName.indexOf(" ");

		//Use the substring method to locate the first name
		firstName = custName.substring(0, spaceIndex);
		System.out.println(firstname);
	}
}


Using the JAVA API documentation

Consist of a set of webpages;
	list all the classes in the API
		description of what the class does
		list of constructors, methods, and fields for the class
	Highly hyperlinked to show the interconnections between classes and to facilitate lookup


StringBuilder Class

-mutable alternative to string
-instantiated using the new keyword
-has many method for manipulating a value

StringBuilder mySB = new StringBuilder ("Hello");
mySB.append(" World");

public class Shoppingcart{

	public static void main(String[] args){
		String firstName;
		String	custName = "Sally Smith";
		int spaceIndex;
		StringBuilder sb;
		
		//Get the  index of the space character " "
		spaceIndex = custName.indexOf(" ");

		//Use the substring method to locate the first name
		firstName = custName.substring(0, spaceIndex);
		System.out.println(firstName);
		//Instantiate and initialize sb to firstName
		sb = new StringBuilder(firstName);
		System.out.println(sb);

		sb.append(" Smith");
		System.out.println(sb);
	}
}


Primitive Data Types
Integral types - byte, short, int, and long
Floating point type -float and double
Textual Type -char
Logical type - boolean
Unicode - primitive type

final - constant and cannot be changed

The remaining numeric operators
remainder = modulus %
	ex. 31/6
	    - mod is 1

preincrement =++variable
postincrement =variable++
predecrement =--variable
postdecrement =variable--



Promoting and Casting Variable

Promotions
	Automatic promotion

Type Casting
When to cast:
	If you assign a larger type to a smaller type
	If you assign a floating point type to an integral type

Beware of the possibility of lost precision

All literal floating point values are viewed as double

L notifies the compiler that a number is double value
F notifies the compiler that a number is float value



public class Shoppingcart{

	public static void main(String[] args){
	
		int int1;
		long long1 = 99000000000L;
		float fit1 = 13.5F;
		char ch1 = '0';
		
		//print the long variable
		System.out.println("long: " + long1);
		//Assign the long to the int and print the int variable
		int1 =(int)long1;
		System.out.println("Long assign to int variable " + int1);	
	}
}


Method and Conditionals
void method - nothing to return
main method = calling method
diplay method = worker method
constructor method - is a special method that is invoked when you create an object instance
	it is called by using the new keyword
	its purpose is to instantiate an object of the class and store the reference in the reference variable
	it has unique method signature

Method arguments and return values
arguments - is a value that is passed during a method call
parameter- is a variable defined in the method declaration

use the keyword return within a method




Static method and variables
static modifier is applied to a method or variable
method/variable:
	belongs to the class and is shared by all object of that class
	is not unique


Creating and Accessing Static Members
To create a static variable or method
	static String mSmall;
	static void setMSmall(String desc);
To access a static variable or method
	From another class
		ItemSizes.mSmall;
		ItemSize.setMSmall("Men's Small");
	From withim the class
		mSmall;		
		setSmall("Men's Small);


Method Overloading
	have the same name
	have different signatures
		the number, types, order of parameter
	have different functionality


ACCESS CONTROL
hide fields and methods from other classes
determine how internal data is changed
keep the implementation separate from the public interface
	public interface
		setPrice(Customer cust)
	implementation		
		public void setPrice(Customers cust){
			// set price discount relative to customer
		}
access modifier
	public: accessible by anyone
	private:accessible only within the class

Encapsulation
	hiding object fields
	mandates programming to the interface
	encourages good object-oriented design
   Get and set
 
Declaring 2 dimentional array
	ex. int [] [] yearlySales;
	Syntax:	type [] [] array_identifier;

Instantiating 2 Dimensional array
	ex. yearlySales = new int [5] [4]'
	syntax: array_identifier = new type [number_of_arrays] [lenght];

Initializing a 2 Dimentional Array
	ex. int [] [] yearlySales = new int [5] [4];
		yearlySales[0][0] = 1000;

Introduction to Object
Defining Object Properties
Instantiating Object
Describing Object References
Reference Different Object
Reference and Ojects in Memory
Two Reference for One Object
Describing Arrays Object in Memory
Describing Constructor and Methods
Implementing Constructors
Method Parameter
Method Return Types
Method Overloading
Variable Scope
Exercise: Creating Overloading Methods
Take Test

Java Array are stored in memory, object stored on the heap
Arguments is a value passed into a method called
What makes up the method signature
	Method Name
	Parameter Types
	Order of parameters
	Number of parameters

Java scope defines where a certain variable or method is accessible in a program

Class components 
	noun-class name
	verb - behavior or method
	adjective- property or field

Heap - object instance
Stack - Reference type & Primitive type


Static Variable is shared by all object in class
Instance variable is unique to an individual object 


Introduction to Static Members
Creating and Accessing Static Members
Exploring Constants
Promoting and casting variables
Converting data values
Introduction to access control
Using public and private modifier
Encapsulation
Using Setter Method with checking
Overloading Constructors
Passing an Object Reference
Passing by value
Exercise: Data Conversion in a Setter Method
Take Test

Static modifier - can be accessed without instantiating the class
		-Is shared by all object of the class
		- Is not unique to an object instance

If someone attempts to change the value of a constant after it has already been assigned a value, the compiler will give an error

Promotion - ex. int to double
		byte to short
Casting - ex. long to int
		double to float

Method use to convert a string to a primitive int type, Interger.parseInt

Benefits of Access Control
	keep the implementation separate from the public interface
	determine how internal data gets changed
	hide fields and methods from other classes


Benefits of encapsulation
	method can change the data type to match the field
	encourages good object-oriented design 
	a class can be changed as long as the interface remains the same

Benefits of checking in setter methos provide
	it ensures the validity of data

this- keyword use to call a overloaded constructor from other constructor

Object Reference - value is copied


Testing String Equality
Comparing Strings Lexicographically
Introduction To Mutable Strings
Using StringBuilder to Concatenate Strings
Splitting Strings
Iterating Over Words in a String
Performing a String Replace
Primitive Data Types
Using the modulus Operator
Using Combined Assignment Operator
Exercise:Concatenate a string of Numbers
Take Test

StringBuilder provides a mutable alternative to String
	-is instantiated using the new keyword
	- has many methods for manipulating its value
	-provides better performance because it is mutable
	-can be created with an initial capacity
	-methods for data manipulation: append, delete, insert, replace
String is still needed
	- it may be safer to use an immutable object	
	-  method in the API may require a string
	- instantiation without new

append- method used to concatenate a String to a StringBuilder object
String[]- object type is returned by the String split method

StringBuilder advantages over String for concatenation(or appending)

Declaring and Instantiate StringBuilder
	StringBuilder mySB = new StringBuilder("Hello");

StringBuilder Append
	StringBuilder mySB = new StringBuilder("Hello");
	mySB.append(" World");



String Replace
	String result = phrase.replace("the", "a");
	System.out.println(result);

String split
	String word: result.split("\\s+")
	System.out.println(word); 

\\s+ -newlines, spaces, tabs

Methods used to test for the equality of String Values
	-equalsIgnoreCase
	-equals
	
Negative return value indicate when calling the compareTo method on a String
	-the String is lexicographically less than the string argument

byte -8
short-16
long-64
int-32

Java API Documentation
	Consist of a set of webpages
		List all the classes in the API
			Description of what the class does
			list of constructors, methods, and fields, for the class
		Highly hyperlinked to show the interconnections between classes and to facilitate lookup
		


Java Platform SE & JDK Version 10 API Specification
	This document is divided into three sections:
	JAVA SE:
		The java platform, standard Edition (Java SE) API's define the core Java platform for general-purpose computing
		These API's are in modules whose name start with java
	JDK
		The JDK APIs are specific to the JDK and will not necessarily be available in all implementations of the Java SE platform.
		These API's are in modules whose names start with jdk
	JavaFX
		defines a set of user-interface controls, graphics, media
		and web packages for developing rich client application 
		These API's are in modules whose names start with javafx
		
	

Creating a LocalDateTime Object

	LocalDateTime myDate = LocalDateTime.now();
	System.out.println(mydate);
	System.out.println(mydate.getDayOftMonth() );
	System.out.println(mydate.getHours() );

Using Calendar
	import java.time.LocalDateTime;
	import java.time.chrono.JapaneseDate;
	import java.time.chrono.ThaiBuddhistDate;


	LocalDateTime myDate = LocalDateTime.now();	
	System.out.println(mydate);

	JapaneseDate jDate = JapaneseDate/from(myDate);
	System.out.println(jDate);

	ThaiBuddhishDate tDate = ThaiBuddhishDate.from(mydate);
	System.out.println(jDate);


	
	
Online Documentation would you find information for classes belonging to the core platform
	Modules beginning with javafx
	Modules beginning with java
	
Method of LocalDateTime can be used to get the current date and time
	now()

java.time.chrono - package contains Java classes that represent alternate calendar system


Valid values from the FormatStyle enumeration
	LONG, SHORT, FULL

parse() - method of the LocalDate class, is able to convert a string into a LocalDate
		instance

Approaches valid way to avoid an infinitte while loop - in the body of the while block, adjust values that effect the expression


enhanced for - type of loop most appropriate for processing elements in Java array




 Nested for loop is the most appropriate for iterating a 2d array

step over - debugger action allow us to skip over a method call when in debug mode

The purpoes of breakpoint when developing a Java app is pause the app when running in debug mode

When paused at a breakpoint in a debugging session for a Java app - it define new breakpoint, modify variable values and inspect the stack trace


Inheritance allows one class to be derived from another
	less code duplication
	edits are done in one directions
	Parent class is known as superclass
	child class is known as subclass


Java Class Hierarchy and Inheritance
Creating Subclasses
Overriding Methods in the Superclass
Using the super keyword
Polymorphism
Casting Superclass References
Using the instanceof Operator
Contrasting Abstract and Non-Abstract Classes
Extending an Abstract Class


Polymorphism 
	means that the same message to two different object can have different results
	in Java , it means the same method is implemented differently by different classes
		This is especially powerful in the context of inheritance
		it relies upon the "is a" relationships

Superclass and subclass relationship
	use inheritance only when it is completely valid or unavoidable
		use the "is a" test to decide whether an inheritance relationship makes sense



 
benefits of Encapsulation
	protects an object from unwanted access by clients
	prevents assigning undesired values for its variable by the client, which can make the state of an object unstable
	allows changing the class implementation without modifying the client interface


Pupose of Java Community Process
	Produces java specification requests
	Develop new Java standards
	Provides early access to specifications


public class ClassName{} - Defines a class and the name must be the same as the filename
public static void main(String args[]){} - defines a class method that is dspecial and is invoked when the class is run by the runtime
import<package> -defines other classes of groups of classes used in your class
package<package_name> - Defines where a class lives relative other classes




StringBuilder class method available
	substring
	append
	insert
	length

Singleton Pattern
	details a class implementation that can be instantiated only once
	


Abstract Method
	Cannot have a method body
	Must be declared in an abstract class
	Is overriden in subclasses

final method cannot be overriden and extended


Rules in creating Interface, for your access modifiers, all the methods in the interface are going to be public


default methods 		
	are declared by using the keyword default
	are fully implemented methods within an interface
	privide useful inheritance mechanics



Anonymous Inner Class
Comparing Classes, Interfaces and Lambda Expressions
Lambda Expressions
Writing Lambda Expressions
	


Lambda Expression Defines
arguments list- int x, int y
arrow token ->
body - x+y

example:
	(int x, int y) -> x +y
	(x, y) -> x+y
	(x,y) -> { System.out.println (x +y) ;}
	(String s) -> s.contains("word")
	s -> s.contains("word")

ContainsAnalyzer.java
public class ContainsAnalyzer implements StringAnalyzer{
public boolean analyze( String target, String searchStr) {
	return target.contains (searchStr);
	}
}

Generics
	Provides flexible type safety to your code
	Move many common errors from runtime to compile time
	Provide cleaner, easier-to-write code
	Reduce the need for casting with collections
	Are used heavily in the Java Collections API

Generics with type inference diamond
	Syntax
		There is no need to repeat types on the right side of the statement
		Angle brackets  indicate that type parameters are mirrored
	Simplifies generics declarations
	Saves Typing



Collections 
	is a single object designed to manage a group of object.			
		Objects in  a collection are called elements
		Primitives are not allowed in a collectoin
	Various collection types implement many common data structures:
		Stack, queue, dynamic array, hash
	The collection API relies heavily on generics for its implementation


Set Interface
A set is an interface that contains only unique elements
A set has no index
Duplicate elements are not allowed
You can iterate through elements to access them. 	
TreeSet provides sorted implementation



Map Interface
A collection that stores multiple key-value pairs
	Key: Unique identifier for each element in a collection
	Value: A value stored in the element associated with the key
Called:"associative arrays" in other languanges


Ordering Collections
Th Comparable and Comparator interfaces are used to sort collections
	Both are implemented using generics
Using the Comparable interface:
	Overrides the compareTo method
	Provides only one sort option
Using the Comparator interface:
	is implemented by using the compare methos
	enables you to create multiple Comparator classes
	enables you to create and use numerous sorting options



Using the Builder Pattern
allows object creation using mthod chaining
	makes code easier to read
	more flexible object creation	
	Object returns itself
	A fluent approach
Java Streams 
	Streams
		java.util.stream
		a sequence of elements on which various methods can be chained
	Method Chaining
		multiple methods can be called in one statement
	Stream Characteristics
		Immutable
		Once elements are consumed, they are no longer available from the stream
		A chain of operations can occur only once on a particular stream (a pipeline)
		Can be serial(default) or parallel

Pipeline defined
	A stream pipeline consist of;
		A source 
		0 Or more intermediate operations
		One terminal operation	
The filter MEthod
	The stream class converts collections to a pipeline
		immutable data
		can only be used once and then tossed
	Filter methos uses predicate lambdas to select items
Syntax;
	System.out.println("\n== CA Transations Lambda ==");
	tList.stream()
		.filter(t -> t.getState().equals("CA"))
		.foreach(SalesTxn: :printSummary); -------> Lambda expression


Method references
	
	alternatively, you can use a method reference
		- foreach(SalesTxn: :printSummary));
	Use of method reference
		Reference to a static method
			- ContainingClass: :staticMethodName
			-Reference to an instance method
			-Reference to ana  instance method of an arbitrary object of a particular type(e.g.. String: : compareToIgnoreCase)
			-Reference to a constructor
				- ClassName: :new


Built in Functional Interfaces
	why not just jump to the cool streams stuff?
	Lambda expression rely on functional interfaces
		Important to understand what an interface does
		concept make using lambdas easier
	Focus on the purpose of main functional interfaces
	Become aware of many primitive variations
	Lambda expressions have properties like a variable
		Use when needed
		or can be stored and reused

The java.util.function package
	Predicate: an expression that returns a boolean
	Consumer: An expression that performs operations on an object passed as argument and has a void return type
	Function: Transform a T to a U
	Supplier: Provides an instance of a T (such as a factory)
	Primitive variations
	Binary Variations


Primitve Interfaces
Primitive versions of all main interfaces
	will see these a lot in method calls
Return a primitive
	ex. ToDoubleFunction
Consume a primitive
	ex. DoubleFunctions
Why have these?
	avoid auto-boxing and unboxing



Using Binary Version of Base Interfaces
Using the Unary Operator Functional Interfaces

	
Types of Opertions
	Intermdiate
		-filter() map()	peek()
	Terminal
		foreach() count() sum() average() min() max() collect()
	Termimal short-circuit
		findFirst() findAny()	anyMatch() allMatch() noneMatch()


Extracting Data with Map
map(Function<? super T,? extends R> mapper)
	a map takes one Function as an argument.
		a function take one generic and return something else.
	Primitive versions of map	
		- mapToInt() mapToLong() mapToDouble()


Flatten Data with flatMap
	use the flatMap method to flatten data in a steam.

Taking a Peek
	peek(Consumer<? super T> action)
		The peek method performs the operations specified by the lambda expression and returns the elements to the stream.
		Great for printing intermediate results



Search Methods: Overview
	findFirst()
		returns the first elements that meets the specified criteria
	allMatch()
		returns true if all the elements meet the criteria
	noneMatch()
		returns true of none of the elemets meeet the criteria
	All of the above are short-circuit terminal operations.

Search Methods
	Nondeterministic search methods
		for nondeterministic cases. In effect , situations where parallel are more effective
		Results may vary between invocations
	findAny()
		returns the first element found that meets the specified criteria
		results may vary when performed in parallel
	anyMatch()
		returns true if any elements meet the criteria 
		results may vary when performed in parallel

Optional Class
	Optional<T>
		a container object that may or may not contain a  non-null value
		if a value is present , isPresent() returns true.
		get() returns the value
		Found in java.util.
	Optional Primitives
		OptionalDouble OptionalInt OptionalLong

Lazy Operations
	only do the needful
	- can be optimized
	-only required operations are performed



Steam Data methods
	count()
		returns the count of elements in this stream
	max(Comparator<? super T> comparator)
		Returns the maximum elements of this streams according to the provided Comparator
	min(Comparator<? super T> comparator)
		returns the minimum element of this stream according to the provided Comparator

Performing Calculations
	average()
		returns an optinal describing the arithmetic mean of elements of this stream
		return an empty optional if this stream is empty
		type returned depends on primitive class
	sum()
		returns the sum of elements in this stream
		Methods are found in primitive streams
			DoubleStream, IntStream, LongStream



Sorting
	sorted()
		returns a stream consisting of  the elements sorted according to natural order
	sorted(Comparator<? super T> comparator
		returns a stream consisting of the elements  sorted according to the Comparator


Saving Data from a stream
	collect(Collector<? super T, A, R> collector)
		allows you to save the result of a stream to a new data structure
		relies on the collections class
		ex. 
			stream().collect(Collector.toList());
			stream().collect(Collector.toMap());

Collector class
	averagingDouble(ToDoubleFunction<? super T> mapper)
		produces the arithmetic mean of a double-valued function applied to the inputs elements
	groupingBy(Function<? super T,? extends K> classifier)
		a "group by" operation on input elements of type T, grouping elements according to a classification function, and returning the results in a map
	joining()
		concatenates the input elements into a String, in encounter order
	partitioningBy(Predicate<? super T> predicate)
		partition the input elements according to a predicate

Quick Stream with Stream.of
	stream.of method allows you to easily create a stream


Error Handling
	errors:
		should be the "exception" and not the expected behavior
		must be handled to create reliable applications
		can occur as the result of application bugs
		can occur because of factors beyond the control of a the application
			databases becoming unreachable
			hard drives failing

Exception Handling in Java
	Handling an exception means you must add in a code block to handle the error
	declaring an exception means you declare that a method may fail to execute successfully

Checked exeptions, which must be "handled or declared"
Unchecked exceptions, which are not typically " handled or declared"        



Using try-with-resources statements
	is a try statement that declares one or more resources
	any class that implements java.lang.AutoCloseable can be used as a resources

Custom exceptions
	you can create custom exception classes by extending Exception or one of its subclasses

Assertions

	use assertions to document and verify the assumptions and internal logic of a single method;
		internal invariants
		control flow invariants
		class invariants
	Inappropriate uses of assertions
		do not use assertions to check the parameters of a public method
		do not use method that can cause side effects in the assertion check



Assertion Syntax
	2 forms of assert statement:
		assert booleanExpression;
			this statements test the boolean expression.
			it does nothing if the boolean expression evaluates to true.		
			if the boolean expression evaluates to false, this statement throws an AssertionError.
		assert booleanExpression : expression;
			this form acts just like assert booleanExpression;
			in addition , if the boolean expresssion evaluated to false, the second argument is converted to a string and is used as descriptive text in the AssertionError message.



Controlling Runtime Evaluation of Assertions
	if assertion checking is disabled, the code runs as fast as if the check were never there.
	assertions check are disable by default. Enable assertions with either of the following commands:
	
	java -enablesassertions MyProgram
	java -ea MyProgram
	

	Assertions checking can be controlled on class, packages, and package hierarchy basis

Previous Java Date and Time
	Disadvantages of java.util.Date (Calendar, TimeZone & DateFormat):
		Does not support fluent API approach
		Instances are mutable - not comapatible with lambda
		not thread safe
		weakly typed calendars
		one size fits all


Java Date and Time API: Goals
	The classes and methods should be straighforward
	The API should support a fluent API approach.
	Instances of time/date objects should be immutable.(This is important for lambda operations.)
	Use ISO standards to define date and time.
	Time and Date operations should be thread safe.
	The API should support strong typing, which makes it much easier to develop good code first. (the compiler is your friend)
	toString will always return a human-readable format
	Allow developers to extend the API easily




The java.time API defines two classes for working with local dates and times (without a time zone):
	LocalDate:
		does not include time		
		a year-month-day representation
		toString- ISO 8601 format(YYYY-MM-DD)
	LocalTime:
		does not include date
		stores hours: minutes:seconds.nanoseconds
		toString -(HH:mm:ss.SSSS)

Modeling Time Zones
	ZoneId: is a specific location or offset relative to UTC
	ex. ZoneId nyTZ= ZoneId.of("America/New_York");
	
	ZoneOffset: Extends ZoneId; specifies the actual time difference from UTC
	ex. ZoneOffset USEast = ZoneOffset.of("-5");
	
	ZoneRules: is the class used to determine offsets


Dates and time amounts
Instant - Stores an instant in time on the time-line
	useful for: timestamps, e.g login events
	Store as seconds (long) , and  nanoseconds (int)
	Methods used to compare before and after

Period is a class that holds a date-based amount
	Years, months, and days based on the ISO-8601 calendar
	Plus and minus work with a conceptual day, thus preserving daylight savings changes

Duration is a class that stores a time-based amount.	
	Time is model as actual seconds and nanoseconds
	Days are treated as 24 hours, and ignores daylight savings

              
                  Calculating Between Days
TemporalUnit is an interface representing a unit of time. 
	Implemented by the enum class ChronoUnit
	Period also provides a between method

DateTimeFormatter produces formatted date/times
	Using predefined constant, patterns letters, or a localized style.


LocalDate -class that holds an events such as bdays, anniversary, or meetings
ChronoUnit- holds time units such as half days, hours, years, and weeks
ZoneId- defines as a specific location or offset relative to Coordinated Universal Time or UTC

"MMMM d, yyyy"- US common string date format



Java I/O Basics
	java defines  an I/O channel as a stream
	an I/O stream represents an input source or an output destination
	an I/O stream can represent many different kinds of sources and destination, including disk files, devices, other programs , and memory arrays
	I/O streams support many different kinds of data, including simple bytes , primitive data types, localized characters, and objects

Byte Streams InputStream Methods
	3 Basic read method are:
	int read()
	int read(byte[] buffer)
	int read(byte[] buffer, int offset, int length)

	Other methods include:
	void close();			//close an open stream
	int available();		//Number of bytes available
	long skip(long n);		//Discard n bytes from stream


	
Character Stream
	
	3 basic read method are:
	int read()
	int read(char[] cbuf)
	int read(char[] cbuf, int offset, int length)

	Other methods include:
	void close()
	boolean ready()
	long skip(long n)
	boolean markSupported()
	void mark(int readAheadLimit)
	void reset()

Chaining Stream
	
	Data source | -> File Input Stream -> Buffered Input Stream -> Data Input Stream -> Program

	Program -> Data Output Stream -> Buffered Output Stream -> File Output Stream -> | Data Sink
 

Reading and Writing data from the console

Console I/O
	The System class in the java.lang package has 3 static instance field: out, in, and err.
	The System.out field is a static instance of a PrintStream object that enables you to write to standard output
	The System.in field is a static instance of an InputStream object that enables you to read from standard input.
	The System.err field is a static instance of a PrintStream object that enables you to write to standard error.

Writing to Standard Output
	The println and print method are part of the java.io.PrintStream class.
	The println method print the arguments and a newline character(\n).
	The print method print the argument without a newline character.
	The print and printLn methods are overloaded for most primitive types (boolean, char, int, long, float, and double) and for char[], object, and String.
	The print(object) and println(object) methods call the toString method on the argument


java.io.InputStreamReader; - get the input of the user


Serialization

Persistence
	Saving data to some type of permanent storage is called persistence. An Object that is pesistent-capable can be stored on disk (or any other storage device), or sent to another machine to be store there.
		A non-persisted object exists only as long as the Java Virtual Machine is running
		Java serialization is the standard mechanism for saving an object as a sequence of bytes that can later be rebuilt into a copy of the object.
		To serialize an object of a specific class , the class must implement the java.io.Serialization interface.


Serialization and Object Graphs
	When an object is serialized, only the field of the object are preserved.
	When a field references an object, the fields of the referenced object are also serialized, if that object's class is also serializable.
	The tree of an object's fields constitutes the object graph.

Trancient Fields and Objects
	Some objects classes are not serializable because they represent transient operating System--specific information. 
	If the object graph contains a non-serializable reference,a NotSerializableException is thrown and the serialization operation fails.
	Fields that should not be serialized or that do  not need to be serialized can be marked with the keyword transient.

Serial Version UID
	During serialization, a version number, serialVersionUID, id used to associate the serialized output with the class used in the serialization process.
	After Deserialization, the serialVersionUID is checked to verify that the classes loaded are compatible with the object being deserialized.
	If the receiver of a serialized object has loaded classes for that object with different serialVersionUID, deserialization will result in an InvalidClassException.
	A serializable class can declare its own serialVersionIUD by explicitly declaring a field named serialVersionIUD as a static final and of type long:
		private static long serialVersionUID = 42L;



Conclusion:
	Streams - used to perform Java input and output operations
	void flush(); - OutputStream method that is used to force a write to the stream
	FileReader & FileWriter- classes that are used when using the character format rather than the byte format
	Mark transient - when the object should not or does not need to be serialized.




Limitation of java.io.File
	Does not work well with symbolic links
	Scalability Issues
	Performance Issues
	Very limited set of file attributes
	Very basic file system access functionality

In NIO.2, both files and directories are represented by a path, which is the relative or absolute location of the file or directory.

Relative Path Vs. Absolute Path
	a path is either relative or absolute
	an absolute path always contains the root elements and the complete directory list required to locate the file.
	ex. ...
	    /home/peter/statusReport
	    ...

	A relative path must be combined with another path in order to access a file.
	ex. ...
	    clarence/foo
	    ...

Java NIO.2 Concepts
Prior to JDK 7, the java.io.File class was the entry point for all file and directory operations. With NIO.2, there is a new package and classes:
	java.noi.file.Path: Locates a file or a directory by using a system-dependent path
	java.io.file.Files: Using a Path, performs operations on files and directories
	java.nio.file.FileSystem: Provides an interfaces to a file system and a factory for creating a Path and other object that accesss a file system.
	All the methods that access the file system throw IOException or a subclass.

Path Interface
	The java.io.file.Path interface provides the entry point for the NIO.2 file and directory manipulation.
	
	ex. FileSystem fs = FileSystems.getDefault();
	Path p1 = fs.getPath("/home/oracle/labs/resources/myFile.txt");
	
	To Obtain a Path object , obtain an instance of the default file system. and then invoke the getPath method:
	
	ex. 
	Path p1 = Path.get("/home/oracle/labs/resources/myFile.txt");
	Path p2 = Path.get("/home/oracle", "labs", "resources", "myFile.txt");

Path Interface Features
	The path interface defines the methods used to locate a file or a directory om a file system. These methods include:
		To access the components of a path:
			- getFileName, getParent, getRoot, getNameCount
		To operate on a path:
			-normalize, toUri, toAbolutePath, subpath, resolve, relativize
		To compare path:
			-startsWith, endsWithm equals


Removing Redundancies from a Path
	Many files system use "." notation to denote the current directory and ".." to denote the parent directory.
	ex. /home/./clarence/foo
		/home/peter../clarence/foo
	
	The normalize method removes any redundant elements, which includes any "." or "directory/.." occurrences
	ex.
		Path p = Path.get("/home/peter/../clarence/foo");
		Path normalizedPath = p.normalize();
	
		/home/clarence/foo

Creating a Subpath
	A portion of a path can be obtained by creating a subpath using the subpath method:
	
	Path subpath(int beginIndex, int endIndex);
	
	The element returned by endIndex is one less that the endIndex value.
	ex.
	Path p1 = Path.get ("/home/oracle/Temp/foo/bar");
	Path p2 = p1.subpath (1,3);
	oracle/Temp


Joining 2 Paths
	The resolve method is used to combine 2 paths
	ex. 
	Path p1 = Path.get ("/home/clarence/foo/");
	p1.resolve("bar"); // Returns /home/oracle/Temp/foo/bar
	
	Passing an absolute path to the resolve method returns the passing-in path
	ex. Path.get("foo").resolve("/home/clarence"); // Returns /home/clarence


Checking a file or Directory
	a Path object represents the concept of a file or a directory location. Before  you can access a file or directory, you should first access the file system to detemine whether it exist using the following Files methods:
		exists(Path p, LinkOption... option)
		Test to see wheter a file exist. By default, symbolic links are followed.
		notExist(Path p, LinkOption... option)
		Test to see wheter a file does not exist. By default, symbolic links are followed.



To verify that a file can be accessed , the Files class provides the following boolean methods.
	isReadable (Path)
	isWritable(Path)
	isExecutable(Path)



Creating Files and Directories
	Files and directorues can be created using of the following methods:
		Files.createFile (Path dir);
		Files.createDirectory (Path dir);
	The createDirectories method can be used to create directories that do not exist, from top to bottom:
	Files.createDirectories(Paths.get("/home/oracle/Temp/foo/bar/example"));

Deleting a File or Directory
	You can delete files, directories, or links. The Files class provides 2 methods:
	 	delete(Path)
		deleteIfExist(Path)
	//...
	Files.delete(path);
	//...


Copying a File or Directory
	using the copy(Path,Path, CopyOption...) method

Moving  a File or Directory
	using the move(Path,Path, CopyOption...) method
  

Walk the Directory Structure
	The Files.walk() method walk the Directory Structure


BufferedReader File Stream
	The new lines() method converts a BufferedReader into  a stream.
	The lines() method can be called using NIO classes
	Use readAllLines() to load a file into an ArrayList


Conclusion:


Concurrency & Parallelism

absulute - type of path always contains the root element and the complete directory list that is required to locate the file
lines() -new method converts a BufferedReader into a stream


Legacy Thread and Runnable
	Extends the Thread Class
		simpler code
	Implements the Runnable interface
		- More flexible
		- extends is still free

java.util.concurrent package- contains classes that are useful in concurrent programming


java.util.concurrent.Callable
- callable interface
	similar to Runnable, but can: 	
		return a result using generics
		throw a checked exception

Threading Concerns
	Thread Safety
		Classes should continue to behave correctly when accessed from multiple threads
	Performance: Deadlock and livelock
		Threads typically interact with other threads. As more threads are introduced into an application, the possibility exist threads will reach a point where they cannot continue


Atomic Operation
	functions as a single operation


Deadlock results when two or more threads are blocked forever, waiting for each other.

java.util.concurrent.atomic package
	lock free thread-safe variables
CyclicBarrier
	a class that blocks until a specified number of threads are waiting for the thread to complete
Concurrency collections


Without Parallelism
	modern system contain multiple CPUs. If you do not leverage threads in some way, only a portion of your system's processing power will be utilized

Naive parallelism
	a simple parallelism solution breaks the data to be processed into multiple sets. One data set for each CPU and one thread to process each data set.

         

Fork-Join Framework

	splitting datasets into equal sized subset for each thread to process has a couple of problems. Ideally all CPUs should be fully utilized until the task is finished but:
		CPUs may run a  different speeds
	

Work-Stealing
	divide the data to be processed into a large number of subsets
	Assign the data subset to a thread's processing queue
	Each thread will have many subsets

ForkJoinPool is used to execute a ForkJoinTask. It creates a thread for each CPU in the system by default.


Fork-Join framework Recommendations
	Avoid I/O or blocking operations
	Know your hardware
	Know your Problem


Reduction - an operation that takes a sequence of input elements and combines them into a single summary result by repeated application of a combining operation
		- implemented with the reduce() method


Performance
	Do not assume parallel is always faster
	Qualitative Considerations
	Primitive Streams provided for performance



The JDBC API & Localization


Properties
java.util.Properties class is used to load and save key-value pairs in Java
can be stored in a simple text file
File name ends in .properties
File can be anywhere that compiler can find it.	

Resource Bundle
ResourceBundle class isolates locale-specific data:
	Returns key/value pair stored separately
	Can be a class or a .properties file
Step to use:
	Create bundle files for each locale
	Call a specific locale from your application

Format Date and Currency
java.time.format.DateTimeFormatter
java.text.NumberFormat
Create object using Locale.

Displaying Currency
Format Currency:
	Get a currency instance from NumberFormat
	Pass the Double to the format method


Displaying Dates
Format a dates
	get a DateTimeFormatter object based on the Locale.
	From the LocaleDateTime variable, call the format method passing the formatter


----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

SOFTWARE TESTING CONCEPTS

IMPLEMENTING UNIT TESTING BEST PRACTICES

Agile testing
	-testing practice that follows agile principle
	-begins at project initiation with continuous integration
	- not sequential

Agile testing Principles
	- Enables quality gate with continuous feedback mechanism 
	- Adopts test-driven development approach
	- Provides clean codes

Agile Testing Strategies
	- Iteration 0
	- construction Iteration
	- release
	-production

Agile testing plan Checklist
	- determine testing scope
	-Identify new funtionalities to test
	- List level or types of testing based on features complexities
	- Plan load and performance testing
	- Plan for risk mitigation
	- List deliverables and milestone

Agile Testing Quadrant
	Supporting the team
	-Automated
	- Automated and manual
	Business facing
	- Automated and manual
	- manual
	Critique product
	-manual
	-Tools
	Technology facing
	- Tools	
	-Automated


Core Unit testing Pattern
	Result test pattern
	State test pattern
	Database test Pattern
	Integration test Pattern

Good and Bad Unit Tests

Features of Good Test
	Small and isolated cases
	Avoid test Interdependence
	Mock as little as required
	Maintain clear naming convention
	Keep test independent of external factors

Features of Bad Unit Test
	Using non-deterministic factors in the codebases
	Using side-effecting methods
	Mutable global state
	Mocking interfaces and classes outside the codebases

Writing Good Test
	Plan early
	Use DRY principle
	Should be deterministic
	Avoid ignoring tests
	One Logical assertion per test

Test Automation Frameworks
	Module-based
	Library Architecture
	Data-driven 
	Keyword-driven
	Hybrid
	BDD




Types of Test Doubles

Dummy objects
Stub class
Fake objects
Mock object


Using Test Double

	Mock
	 |
	Execution
	 |
	Validation

Benefits Of Mocking API
	API MOCK
FOr tester to stimulates external dependencies and unexpected behavior
For operation and architect to enable isolated development project
For functional tester to create test during development 
For Customers to try APIs 
For developers to be independent of API availability and functionality


4 types of machine Learning Problems

Never mock values
Avoid mocking concrete classes
Use Intergration tests
Mock Selectively


Course Summary

Implementing Unit Testing Best Practices
	Unit Testing pattern and frameworks
	JUnit and TestNG AAA testing
	Testing REST APIs 
	Unit testing with TDD
	Automated testing with JUnit and selenium


ESSENTIAL CHECKLIST FOR PLANNING AGILE TESTING
-Listing deliverables and milestones
-Planning load and performance testing


PROMINENT TESTING PATTERN THAT IS USED TO IMPLEMENT UNIT TESTING
-Database test pattern
-State test pattern

Characteristics of bad test
-Using non-deterministic factors in the codebases
-Mocking interfaces and classes outside the codebases

Valid category of test automation framework
-Hybrid
-Keyword-driven


Annotation we use to implement AAA pattern in JUnit
@RunWith
@Parameters

Best Practices that we can follow when using Mocks
-We should avoid mocking concrete classes
-we should never mock values


Different Approach that we can use to mock object using Mockito
-Using the @Mock annotation
-using the static mock() method



Assert libraries that we can use with Mocha to test RESTfuk APIs
-Chai
-Should.js

Different type of Mocks that we can use with SoapUI to unit test web services.
-Soap mock
-REST mock


Subclass of DBTestCase that we can use to write DBUnit test cases to connect and execute test cases
-JdbcBasedDBTestCase
-DataSourceBasedDBTestCase


Annotation can we use to manage test fixtures to implement Test-driven Development
-@After
-@Before

Classes of openQA package that we use to integrate unit test creation with JUnit and Selenium to test browser compatibility
-By
-WebDriver


Automated Testing: Design Patterns
Importance of Automated Testing
Why Test?
	- reliability
	- Accuracy
	- Safety
	-Efficiency

Repetitive Tasks
- Automation
-Bug Prevention
-Productivity

Improve Understanding
-Documentation
-Auditing
-Refactoring

Manual Testing
-Discovery
-Establish Patterns
-Determine what to automate

Software Developers Testing Roles
QA Tester- traditional software development role
Automation test Engineer- Test-centric code and operations


Roles and Responsibilities
Test strategy - testing methodologies
Coordination- Reporting and tracking
Tools- getting the job done

Domain Considerations
Scalability
Efficiency 
Reliability

Unit testing
	verify individual parts

Code paths
Code coverage
	
Manually- testing the test
Automated-testing regressively

Testing Effectively
Proactive
Creative
Think Outside-the-box

Functional Tests- comprehensive end-to-end

High-level Planning
Goals
Support
Ease to use


Functional testing
-unit testing
-intregration testing
- White box and black box testing
-regresssion testing

Non-Functional
-Performance Testing
-Stress Testing
-Penetration Testing
-Migration Testing

Strategic components
Team expertise
Maintainability
Ecosystem
Efficiency

Unit Testing-code-centric
API testing-interface-centric

UNIT Testing
Code coverage
Testing possible paths
Individual parts
Developer-driven

API Testing
Inputs ans outputs
Expected behavior
Integration
QA-driven

Complementary Features
Work outwards


Test-Driven
Write tests first- then code to pass test
Consider all inputs- expected errors
Improve refactoring- refactor test first

The AAA Pattern
Arrange
Act
Assert

Behavior-driven Development (BDD)
Outside-in
User Interactions
Multi-step Automation
Case-based

Outside-in 
User-centric
Use cases
Highest level
Customers expectation
Validation

Inside-out
Code-centric
Application units
Lowest level
Specification details
Verification

Programming Libraries-driven by unit tests
Command Line applications
	Inside-out
	Options and Arguments
	Limited Interaction

GUI applications
	Underlying code
	Interface code
	Stateful assumptions

Web application
	Server-page generation and API tests
	Browsers-Multi-client considerations
	Page tests-behavior and functional

Traditional- scripts and macros

Programming Language Oriented
	Request Libraries
	Simulation
	Unit testing
	Framework testing
	Postman and  swagger
	Web-driven- selenium webDriver
	Page Objects- reusable components

Navigationg with Selenium webDriver

python --version
pip --version
pip3

Conclusion

The main purpose of manual testing is to determine what to automate

Quality Assurance Tester- Traditional software developments team role
Automation Test Engineer- test centric code and operations role

Unit Test effectively used in automated testing by testing the smallest testable parts


Web- type of application is often associated with multi-client considerations

Web bases- type of testing tool is Selenium

Web browser- element does the selenium WebDriver provide interface for.


Assertion- the result of  a unit test typically verified

Creating reusable code- main benefits of using the Selenium page Object pattern

TestCase- class that implemented in creating a test case using the Python unittest library.

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

JUnit Fundamentals


When doing regression testing we want to be able to manage test in small groups. What class is defined in JUnit to allows us to do this?
	---@SuiteClasses


The @After annotation provides us a way to help clean up our testing environment. The @After annotation signals JUnit to run the methods at which point in the testing cycle?
	--After each test has been run

There are times when we want to put control to the results in the hands of the test designer and developer, which may or may not be the same person that's developing the code. What annotation in JUnit allows us to be able to specify what will be returned by the called method regardless of how that method actually behaves?
	---@Mock

In JUnit there is a really powerful way to allow us me to focus in, to just run a specific type of test. We can define at a method level much more than at class level, which types of test I want to run. Which annotation allows us to unlock this functionality?
	---@Category


JUnit provides a basic test runner that will execute most test cases for you. As we expand the custom features that needs special test condition or use third party solutions, we need to use the smarter test runner to execute our test. What must be passed as a parameter into the @RunWith cutom runner annotation in order for test cases to execute correctly?	
	--A class object



While the test fixture capability provides many good options Managing files, database connection, pr any customized solution you wish to create, in a reusable way can be accomplished by which of the following annotations?
	--@Rule

Test cases are written to check functionality, but the test space can often be expanded dramatically by simply changing the input values to a test. JUnit provides a mechanism, by which we can execute a test many times across a changing set of inputs. What is the annotation that allows us to use this functionality?
	--@Parameters

When doing performance testing or testing to see how the system responds to a lot of data, JUnit provides us with a tool to simplify the process. This tool allows us to perform rapud test data generation and clear mechanism for externalizing data. It even gives us the ability to check that the data is valid and this reducing false failures. What is the feature within JUnit that allows us to do so?
	--Theories


Test suites have always existed in JUnit, but have changed quite a bit from the legacy to the current approach. If you deal with legacy test suites, it may be useful to see how they can be used or converted into their modern equivalent. Legacy JUnit testing required you to do what to the TestSuitee class in order to be able to use it?
	--extend

In JUnit there is an annotation that provides us an extension to give us universal checks across all test cases within a JUnit test, or further details and control within each test. It gives us moere granularity and control to create customized testing, beyond what is provided in basic JUnit. What is that annotation?
	--@Rule


JUnit has been a solid testing framework for a very long time. The most recent versions take a great advantage of annotations. But many test were created before this job enchancement. Legacy test cases had extended out what class?
	--TestCase

JUnit is most effective when run with every change, to ensure that the code is always working. Integrating JUnit into tools, which executes many Java builds these days, allows us to test the code each time it is recompiled. What is a tool that can be integrated with JUnit to do this?
	--Maven

While we wan out test to always be passing, it's inevitable that some will fail ovet time. As features are not yet developed, are being changed, or simply we just don't have time to fix the test. While we still may want that test around, we now have the ability to temporarily ignore it's execution using a simple annotation. Which of the following annotation allows for this functionality?
	--@Ignore


Most testing is directed at funtional requirements and satisfying the behavior within the system. We cannot forget, however, that execution time is a factor for the acceptability of solution as well. Which of the following is a properly formatted annotation that will have a time limit of 2 seconds before the test is considered to have failed?
	--@Test(timeout=2000)


By default JUnit will execute test cases in whatever order it decides, which could vary each time the test is executed. Some test designs must assume a specific orfer for each test case. What annotation in JUnit allow us to be able to specify the order that tests will run?
	--@FixMethodOrder

_________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

CompTIA Linux+ 

Introduction to Linux & Command Line Interface

Crtl + Alt + F1 = open CLI

Pound symbol = root user
Dollar sign = regular user

COMMANDS
ls =shows all the file that are in my home directory 

uname = show the Unix name of the system

history = show all the different command that you've typed since you started the system

clear = clear the screen

pwd = show your present working directory

echo = used to show text on the screen

touch = create a empty file

vi = use to edit file 
nano = use to edit file

cat = shows the text  index

whoami = shows you what user account you're logged in as.

su = substitute to other user

su root = become a root user
su - 

cd/etc = access sudoer file
sudo = stands for super user do, we're telling the super user to do something, use if you only use dew commands

sudoer file = if you make mistake in sudoer's file you could make  it where you're no longer able to use the sudo command, and you might end up locking yourself out of the machine 


sudo visudo = special version of vi that is specifically set to edit the sudoer file
sudoedit = shortcut for the default sudo editor
which ip = which command tell you where that command actually exist




Conclusion

There are hundreds of linux distribution.

sudo vi/etc/sudoer  &
sudoedit /etc/sudoers - command that grants additional users access to use the sudo command

[root@localhost ~]# ls -la /usr = the argument is the /usr

man = linux shell command that is used to display help

sudo <command> = command is used to run only a single command under the root administrator context

1991 =Linus Torvalds annouce his new free operating system

When changing user contexts what benefits if there to using su -<username> instead of su <usename>, it create a full login session that changes directories.
 
What is the impact of running the dash shell instead of bas shell?
	A small percentage of the commands will be different

What is the focus of Open Source software
	enabling community collaboration

What domain in the Linux+ Exam is particularly useful to new user who are frustrated when their installation of a Linux based OS doesn't work and they don't know how to fix it?
	Linux Troubleshooting and Diagnostics





CompTIA Linux+: Managing Users & Groups


man useradd
useradd = command that add users
-c = command that allows you to put comment
  ex. -c "Elizar Gimenez"

-e = command that is use for expiration date of the user
  ex. 2019/12/31

-s = command to change the shell
  ex. -s /bin/dash

-d = command to create a folder
  ex. -d home/jane_smith


Example of adding user 
sudo useradd -c "Jane Smith" -e 2019/12/31 -s /bin/dash -d /home/jane_smith jsmith


Get the user id
	sudo useradd sarah
	sudo id sarah 

Delete account = deleting user is not a good practice but if you do add -r to remove their home directory 
	sudo userdel sarah
	sudo userdel -r sarah



man usermod =command where you can modify any login

usermod -l = -l  change the name

sudo passwd <username>= change password

man chage = designed to change the age of a password or set an expiration

sudo chage -l <username> = it will tell everything about their password

sudo useradd -D = it will show all the defaults

cd /etc/skel = skeleton folder


sudo less /etc/login.defs = login definition


GROUP creating
ex. sudo groupadd Sales
    tail  etc/group


Group deletion
	groupdel or group delete

Changing the name
sudo groupmod -n <new name> <old name>


Add user into the group
sudo gpasswd -a <username> <group name> = group password command and also allow you to add user to the group

Remove the user from the group
sudo gpasswd -d <username> <group name>

Make the user the administrator to the group
sudo gpasswd -A <username> <group name>

CHANGE THE GROUP CONTENT FOR A MOMENT
newgrp <group name> = change the context for a moment

chown = to change the owner

getent or get entity = used to find information inside of the /etc/group/ and /etc/passwd file as well

CONCLUSION:

passwd = command can an administrator use to change the password of an existing user account

The advantage of using the -r switch in the context of the userdel command is it removes user's home directory

Currently the most common use of the -c switch of the useradd command is to store user's fullname

cat etc/group |grep <username> = command that would reveal the MOST information about groups of a certain username.

The effects of using the -A switch when executing the gpasswd command are add a user to a group and then makes the defined user a group administrator


CompTIA Linux+: File Access & Permissions
Working with File Permission and Ownership

ls -l = command for longer list of names



	
	Owner 
	permissions
	   |
	   |	Other permissions
	   |       |
	d rwx r-x r-x DirA
	|      |	  
    Type     Group
    of 	     permission
    Objects


rwx= means read, write, execute

Identities
u            = user
g	     = group
o	     = other

Permissions
- 		=none
r		=read
w		=write
x		=execute  

Numerical Values
4		= Read
2		= write
1		= execute

Numerical Notation
0	=none
1	=execute
2	=write
3	=Write and execute
4	=read
5	=read and execute
6	=read and write
7	=read, write and execute


Modify Permissions

man chmod
ex.
chmod g+w <file>
chmod o-r <file>
chmod g+w, o-r <file>
chmod u=rw, g=rw, o-rwx <file>   // Equal symbol override the permission

File listing
ls -l file* = files details


umask = what defines the default permission

umask Values

0 =read, write and execute
1 =read and write
2 = read and execute
3 =read only
4 = write and execute
5 =write only
6 =execute only
7 = no permissions

mkdir <directory name> = make directories

chown <specify the owner you want to be> 
sudo chown <name of owner>:<group> <file> = change the owner


Change the group
chgrp <group> <file>

Change the group without changing the owner
sudo chown :<group> <file>


Change the ownership in sub-directories
sudo chown -R <name> /home/<filename>/*

When you take the archieve, if you use the tar command to wrap up the files first, the tar
command will actually back up the permission as well.

USING FILESYSTEM ACCESS CONTROL  LISTS

What FACLs do, is they allows us to assign extra stuff, you still have the UGO that doesn't change

getfacl
setfacl = modify new style FACL permission and also the old style Unix.
-m = means modify
ex. setfacl -m o::r <file> 
    setfacl -m u:<username>:rw <file>
    setfacl -m g:<group name>:rw <file>


-t = Sticky bit is designed for shared folders, it tells the folder to watch for when people create documents to be able to tack that on and keep track of who created it

Turn on the sticky bit using the chmod
ex. chmod o+t,g+t CorpData

CONCLUSION:

setfacl and getfacl commands enables for Linux administrator to access to more advance and granular permissions

chmod u=rwx,g=rw,o=r file2.txt & chmod u+x,o-w file2.txt =commands that grant owners read, write and execute; group memeber read and write; and other read only permission on afile named file2.txt that already had the permission -rw-rw-rw

An administrator types ls -l they recieve the results d rwx r-x r-wx DirA. What does the "r-x" represent in this output?
	group permissions


What is the purpose of the sticky bit in Linux permission?
	ensure that only file creators can delete their files



CompTIA Linux+: Disk Partition & File Systems

lsblk partition command 

sudo fdisk /dev/sdb = take you to the fdisk editor 



man mkfs = show the help files for make file system
ls usr/sbin/mkfs*


making swap partition
sudo mkswap /dev/sdv3
sudo swapon /dev/sdv3

CONCLUSION:

MBR	-default Linux partition ID is 83
	-Uses the fdisk utility to manage partitions
	- Limited to 4 primary partitions
	-Support an extended number of partitions through logical partitions

GPT	-Limited to 128 partitions
	-Uses the gdisk utility to manage partitions
	-Default Linux partition ID is 8300


ext4	-A very mature and fully supported file system used as the default by ubuntu.
ZFS	-Has a strong following but mainly designed foe network storage appliances or clusters doing shared storage.
Btrfs	-Tends to be a more cutting edge file system that has built-in support for software raid.
XFS	-Has built-in support for partition resizing, backed by Red Hat, and is the default in CentOS.

Which commands can format the first partitions of /dev/sdb using the XFS file system?
	mkfs.xfs /dev/sdb1
	mkfs -t xfs /dev/sdb1

What command makes the first ext4 formatted disk partition on /dev/sdb available from /mnt/private?
	mount/dev/sdb1/mnt/private


CompTIA Linux+: Logical Volumes & Filesystem Hierarchy

Logical Volume Manager	
	allows us to have a lot of flexibility with our file systems.

sudo yum list lvm*

if the lvm is not installed
sudo yum install lvm2
lsblk
ls /usr/sbin/vg*
ls /usr/sbin/lv*
sudo pvcreate /dev/sdb1/dev/sdc1 
sudo pvdisplay
sudo vgcreate vgl /dev/sdb1/dev/sdc1 
sudo lvcreate -L 1500G vgl -n lv1
sudo lvdisplay


CONCLUSION:

What directory represents all of the executable that are currently running in memory?
	-proc

What is the correct descriptive syntax for creating a logical volume using LVM?
	-lvcreate -L <size> <physical disk name> -n <logical volume name>


What is the purpose of the Linux Foundations Filesystem Hierarchy Standard?
	-Ensure user and software can file and directory locations


What directory is designed to hold data that is temporary and not mission critical?
	-var

What commands are needed to increase the size of a logical volume located on physical volumes that are completely allocated?
	-lvresize
	-pvcreate
	-vgextend

What LVM component represent the aggregation of disk space before it is dispersed to mountable blocks of storage?
	- Volume Group

What is the purpose of the Linux Foundation Filesystem Hierarchy Standard?
	- Ensure users and software can file and directory locations





CompTIA Linux+: Using vi/vim to Edit files
Using the vi/vim Text Editor
vi - is extremely non-user friendly

MODES
		Command Mode
      :(colon)	/ / Esc \ \ i
	       / /	 \ \
	Execute Mode    Insert Mode


ls
ls -l
ls -lh


vi <filename> --> edit document

press i to go to the insert mode
press colon to go to execute mode
:w --> save the document
press dd or :d --> delete line
:q! --> quit and dont save changes
:set number --> add line number

vi ~/.vimrc --> put preferences
:<starting pageto delete>,<ending page to delete>d --> delete paragraph

Searching in vi
/<word to search> and press n to go to the next word and N is going backwards
?<word> --> search backwards

Search and Replace
/<word>/<word to replace> --> single line
:%s/<word>/<word to replace> --> whole document
:<paragraph no.>,<paragraph no.>s/<word>/<word to replace> 

:<line no.> --> jump over the line number



Using Advanced vi/vim Text Editor Features

vi <filename>

Open document and search
vi +/<word to search> <filename>

Navigation without Arrow
HJKL

New Line
o --> insert in new line
a --> insert after the cursor



Cut, Copy and Paste
yanking --> coping 
yy --> copy the line
p or :p --> paste
:<line no.>,<line no>y --> copy lines

Saving the document
:w 
:w <filename change> --> change filename

:q --> exit the document


Saving and Exit at the same time
:wq

Edit another file while in the other existing file
:e <filename>
:e! --> switch to other document without saving it


Saving and Exiting at the same time
hold shift and press ZZ


CONCLUSION:

What vi character navigation method is supported even across distributions or terminal methods?
	j, k, h, l

What features are available in the vim editor that are not available in vi?
	line numbers
	

What mode in VIM enables you to add text to a document?
	Insert	


What vi command exits a document without saving?
	:q!


What vi command would copy the current line into the buffer?
	yy	






CompTIA Linux+: Locating & Manipulating Files///few file are missing

sudo tail /var/log/messages

Move the file
cp /var/log/messages home/ <destination>
mv " " " " " " " " " "  = mv is move


cp -r = make it recursive
cp = means copy

mkdir <filename> = make directory

rm <file> = remove file and directories 
rmdir <file> = remove directory specifically
rm -rf  <file> = force remove the file


Finding Files and Using Aliases

Find and locate

find . -name <file> = . means scan this directory
find / -name <filename> 2>/dev/null = search the entire hard drive, 2>/dev/null means throw away the errors
find /usr/bin -perm -x 
find / -size <size ex. 5M>  2>/dev/null= find the file through the size
 
locate <filename> = fast but not up-to-date
ip addr = ip address

whereis ip = locate ip
which command = it will show only one 

type = what type it is
grep = search file inside the file


CONCLUSION:

What command would display the first 20 lines of a text document named db_log.txt?
	head -n 20 db_log.txt

What command enumarates all the hidden files in a directory and displays the permissions associated with those lines?
	ls -la


What is the potential hazard of using the locate command to find a file?
	It's database may be out of sync with new files

What command outputs the text from the file, adding pagination that only moves forwards through a document?
	more

What command would search the current directory and sub-directories for a files with the txt.extensions?
	find. -name"*.txt"





CompTIA Linux+: Searching& Manipulating File Contents

Using grep and Regular Expressions to Find Data

man grep
man 7 regex

Wildcards

[] list of possible values (square bracket)
-  Range of values (hypen)
.  Any single character
*  Any number character (asterisk)
^  Beginning of line (carrot)
$  End of line (dollar sign)
|  or (pipe symbol)
() Sub-expression or slice
\  escape character (backslash)

Two mode of grep
fixes string
regular expression

grep -r <file> <home directory>


Manapulating Text File Content

printf = format text

wc <filename> = character counts
wc -w <filename>= just the word count
sort command =sort the file(temporary)

ex. sort <file>

put -r and it will reverse it
ex. sort -r <file>

ex. sort -k 2 -t" " ./<file> = " " is a delimeter it can be , or - or anything


cut command = similar to sort
ex. 
	cut -f 2 -d, ./<file>

Spaces is not good delimiter

diff command = compare file and show the difference

ex.
	diff <file> <file>

Use for scripting and automation
man sed 
man awk

CONCLUSION


What command brings up the manual information pages for creating POSIX.2 regular expression statements?
	man 7 regex


Which command deletes any line that contains the word remove from a text file called myInfo.txt?
	sed /remove/d myinfo.txt


What commands would find and return the lines that contain the names Bob, Bobby, Rob, or Robert in a text file?
	cat mydoc.txt | grep E Bob|Bobby|Rob|Robert
	cat mydoc.txt | grep E Bob*|Rob*


What command searches for all files and subdirectories in the /media directory for the name Bob?
	grep r Bob /media


What command would sort, in descending order, a text file containing a list of employee names?
	sort r employees.txt

What command would list only the first names from a comma separated file containing only employee names where the first field contains the last name and the second field contains the first name?
	cut f 2 d, employees.csv




CompTIA Linux+: Boot Process & Kernel

Configuring the Linux Kernel
kernel = the heart and soul of linux operating system


Kernel  - memory
	- File System Access
	- Processes	
	- Devices
	- Resource Allocation


User space:
user-level programs

Kernel space:
Modules, drivers, services

Hardware

LINUX OS
	its the Linux kernel combined with the GNU utilities

Linux is a monolithic kernel not a microkernel

uname -a = information about kernel

insmod = install modules
rmmod e1000 = remove modules
lsmod = see information about modules


modprobe = take a look at the hardware that is present  and all of the modules that are present, and if it sees a hardware that's missing a module, it will load the module. It keeps the system Update while its runnning

cd/etc/modprobe.d

sysctl -a = show the parameter of the kernel


Describing the Boot process

BIOS/UEFI		|
MBR/GPT			|
GRUB 2			|
initrd/kernel		|
systemd process		|

cd/boot


vim /etc/grub.d/40_custom
	|
/etc/grub.d/40_custom
	|	
	| grub2-mkconfig
	|
/boot/efi/EFI/centos/grub.cfg		





CONCLUSION:

Where does the grub.cfg file reside in the Linux OS directory?
	/boot/grub2

Where do the modules for the kernel reside in the Linux OS directory?
	/lib/modules


modprobe -Add or removes modules while system is running

rmmod -Remove a module

insmod - Install a module

lsmod - Pull a list of modules in Linux

modinfo - Provide a description of a module

Which key allows the ability to go to command shell on GRUB loader and edit the configuration on boot?
	e

Which command will provide a list information regarding the parameters being passed to the kernel?
	sysctl




CompTIA Linux+: Graphical User Interfaces

Describing GUIs in Linux

Input
   |
X server
   |	x client web browser
   |	x client graphics
   |	x client terminal
   |
Compositor


Input
   |
Wayland Compositor
   |-   Wayland client web browser
   |-	Wayland client graphics
   |-	Wayland client terminal


CONCLUSION:


What is the X Server communicating with to receive information to send to the other components?
	Compositor

Which X client GUI is normally installed by default for Red Hat and Centos distributions?
	Gnome


What is a default X client GUI installed on SUSE?
	KDE




CompTIA Linux+: Managing Services

Configuring Services with systemd


Daemon - any program that runs in the background as part of the operating system that it runs unattended from the user.



ps aux = command that show all of the processes with the user that's attached to them.



CONCLUSION:

Where do the systemd unit files reside in the Linux OS directory?
	/lib/systemd/system

Which command would allow the mysqld service to run on runlevel 2, 3, and 5?
	chkconfig --level 235 mysqld on


Which command will identify the services and tell you their runlevels?
	chkconfig --list

Which systemctl command keeps the httpd service active when a machine reboots or is shut down?
	systemctl enable httpd

Which term refers to a predated systemd as an initialization system for major Linux distributions?
	SysVinit

rc3.d -Full multiuser mode
rc6.d -Reboot
rc1.d -Single user mode
rc0.d -Halt



CompTIA Linux+: Troubleshooting Services

Describing and Analyzing Processes

systemd-analyze blame = command that troubleshoot systemd on your system


Troubleshooting Problem Processes

bg <number> = command for background processes
fg <number> = foreground


Priorities program

Niceness value range is from -20 to +19
+19 is a slowest
-20 is the fastest 

nice -n <number> vim ./<filename>

renice = command changes the priority of a running application
	= you must know the process ID you can't use application name

ex.
Check the process ID
ps aux | grep vim

renice -n <number> 14735


pgrep vim = shortcut for process ID

KILL the application
kill <process ID> =command
killall <application name>

CONCLUSION:

What command can terminate a process, with process ID 14735, that is no longer responding or working?
	kill 14735


What is the range and priority (from fastest to slowest) for setting a nice value for a Linux process?
	-20 to 19

In what state of the process life cycle is a process that is a child of a process that has finished but has not been told to stop by its parent process?
	Zombie State



ps aux	-Shows the process table where you can see parent and child processes listed

top	-Shows an updating real-time display of running processes sorted by their utilization

lsof	-Lists files that are open by processes running on the system

uptime	-Shows how long the system has been online and the load averages in a single line

system-analyze blame	-Lists all services since bootup and the time they use



CompTIA Linux+: Managing & Configuring Hardware

Managing Hardware

cd /dev

force reload 
sudo udevadm control --reload-rules
sudo udevadm trigger

lspci - list the hardware


dmesg | less=command it will show you the log in the hardware

dmesg --follow


Configuring Printers

sudo yum list cups
*if not installed
sudo yum install cups
sudo systemctl enable --now cups
sudo systemctl status cups


sudo yum install hplip = print driver cups

Add printer
browse through 127.0.0.1:631

connection: socket://10.0.10.50


Use the printer
lp -d <Name of the printer> ./cal-2019.txt

lp = for printing
lpstat =info
cancel = cancel


CONCLUSION:


Which Linux command correctly activates the CUPS service immediately and keeps it running on restart on Red Hat distro?
	systemctl enable --now cups


Which command can be used to list all USB specific devices plugged into a laptop using Linux?
	lsusb

Which command lists all the hardware plugged into a PCI bus of a laptop on an Ubuntu OS?
	lspci

What format are printer drivers in CUPS?
	.ppd

Which directory is typically the main location for viewing all the device files in Linux?
	/dev

What command provides a user-friendly command reference to create and define a printer in CUPS?
	lpadm




CompTIA Linux+: TCP/IP & Networking

Describing Networking

ip addr = show network adapter
Types of Networks
Class A -255.0.0.0	/8	-16,77,214 host		ex. 10.x.x.x /8
Class B	-255.255.0.0	/16	-65,534 host		ex. 172.16.x.x -> 172.31.x.x /16
Class C	-255.255.255.0	/24	-254 host		ex. 192.168.x.x /24
	

ARIN = organization that make sure there is no duplicate ip address

IPV4 = 4.3 ip addresses


Application 	HTTP	FTP	SMTP	TFTP	SNMP
		  \      |	/	|	/
		   \	 |     /	|      /
Transport		TCP		UDP
			 \		/
			  \	       /
Internet			IP
			       / \
			      /   \
Media Access	 802.3Ethernet	   802.11 Wireless	


Common TCP/UDP ports

Port Number	Protocol	TCP/UDP
20		  FTP		  TCP
21		  FTP		  TCP
22		  SSH 		  TCP
23		  TELNET	  TCP
25		  SMTP		  TCP
53		  DNS		  TCP/UDP
80		  HTTP		  TCP
110		  POP3		  TCP
119		  NNTP		  TCP
123		  NTP		  UDP
139		  NetBIOS	  TCP/UDP
143		  IMAP		  TCP
161		  SNMP		  UDP
443		  HTTPS		  TCP
465		  SMTP-SSL	  TCP
993		  IMAPS		  TCP
995		  POP3S		  TCP


Configuring Networking in Linux

Old Commands
ifconfig
route

New Commands
ip addr
ip route

Run the DHCP
sudo dhclient = turn on dhcp
sudo dhclient -r = reboot dhcp

Restart the system network
sudo systemctl restart network
service network restart


Change the network configuration
CentOS, RedHat and Fedora
cd /etc/sysconfig
cd network-script
sudo vim ifcfg-ens33


CHANGE HOSTNAME
cat /etc/hostname = check the host name
sudo hostnamectl set-hostname <name>


nmcli device status
nmcli device show ens33
sudo nmcli connection edit ens33
set connection.autoconnect yes
set ipv4.method manual
set ipv4.addr 192.168.0.2/24
set ipv4.gateway 192.168.0.1
save
quit
sudo nmcli connection reload


CONCLUSION:


Which command can acquire a lease or send another DHCP request on a system?
	dhclient


What purpose does TCP and UDP provide on the network?
	Transport


What is /24 in IP addressing converted to in bits when referring to the subnet of an IP address?
	255.255.255.0

Which directory contains script files to configure the network interface on a Red hat-based Linux distro?
	/etc/sysconfig/network-scripts

What command can be used to determine the gateway of the network?
	route


CompTIA Linux+: Troubleshooting Network Connections

Command
ping

IPV6 ping
	ping6

traceroute www.google.com

ping the default gateway
ping own ip address
ping 127.0.0.1

tracepath www.google.com

nslookup www.google.com

nslookup www.google.com 1.1.1.1
dig www.google.com
cat /etc/resolve.conf
cat /etc/hosts
ip link

sudo systemctl restart network

If using Netplan
sudo netplan apply

ss -atp

ss -tp
ss --route
ss --program

sudo tcpdump -i ens33 ./data.txt


CONCLUSION:
	
Which command can be used to follow a path to destination?
	tracepath


Which command can be used to perform name server lookups when troubleshooting network issues?
	dig

Which protocol analyzer tool provides a GUI to sniff networks when troubleshooting connections?
	wireshark



CompTIA Linux+: Installing & Managing Software

Managing Software Packages Using apt

pkg

apt-get
apt-cache

apt = for aplitude
sudo apt install mc
cd /etc/apt
cd sources.list.d
less ./sources.list


if you know what you're looking for you can use
the apt list
ex. apt list apache2

if you dont know what your looking for you can;
apt search


sudo apt update
sudo apt upgrade
sudo disk-upgrade
sudo apt remove webmin
sudo apt remoce mc



Managing Software Packages Using yum and dnf

DNF - means Dandified Yum 


man rpm
cd /etc/yum.repos.d
yum list apache

yum info httpd
sudo yum install httpd
sudo yum install nano
sudo yum search webmin

sudo rpm --import jcameron.key.asc

sudo yum update
sudo yum remove <software name> 
sudo yum erase <software name>
sudo dnf autoremove


CONCLUSION:
	
What command adds a new key for verifying the software from a new repository where the key has been stored in the file repo-key.asc?
	apt-key add repo-key.asc	


What command returns additional information for a package called httpd?
	yum info httpd


Where does apt check for the list of repositories it can use to find and download software on Debian or Ubuntu?
	/etc/apt/sources.list


What command forces yum to check the repositories and update any software which has been installed?
	yum update
	
Where are the repositories for yum and dnf stored on Red Hat Enterprise Linux or CentOS?
	/etc/yum.repos.d/

Which apt commands can find matching packages for apache on Debian or Ubuntu?
	apt list apache*
	apt search apache



CompTIA Linux+: Installing Software from Source code
Building and Installing from Source Code

sudo yum install gcc


sudo yum install gcc make gzip
tar xvzf ./<file name>
ex.

tar xvzf ./john-1.8.0.tar.gz
cd src

make config
make
make clean linux-x86-64
cd run
sudo make install
  
CONCLUSION:

What command can usually be run, especially after a previous make command ran with an error, to erase the left-over files created while attempting to compile the software?
	make clean


What are three common tools generally used to build software on Linux?
	gcc, make, and gzip
	



CompTIA Linux+: Security Best Practices
Describing Linux Security

Confidentiality
Availability
Integrity


sudo yum install audit
cd /etc/audit

less audit.rules
cd /var/log
cd audit

paintext - encryption - ciphertext
	       |
ciphertext - decryption - paintext


Hashing
message - hash function - digest

LUKS Setup
blkid
sudo umount /dev/sdb1
shred -v --iterations=1 /dev/sdb1
cryptsetup --verbose --verify-passpharse luksFormat /dev/sdb1

blkid
cryptsetup luksOpen /dev/sdb1 storage1
mkfs.xfs /dev/mapper/storage1
mount /dev/mapper/storage1 /mnt/storage1
cd /mnt/storage1
cp -R /home/dpezet/Documents/* ./
ls


Hardening SSH Clients and Servers

sudo yum list ssh*
sudo yum list openssh*

systemctl status sshd
cd /etc/ssh

sudo vim /etc/ssh/sshd_config

sudo systemctl  restart sshd
ls
sudo rm -f * key*
ls
sudo systemctl stop sshd
sudo ssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_key
sudo ssh-keygen -t ed25519 -f /etc/ssh/ssh_host_ed25519_key
sudo ssh-keygen -t ecdsa -f /etc/ssh/ssh_host_ecdsa_key

sudo systemclt start sshd

cd
ls
ls -a
cs .ssh
ls -l
ls -la
ssh-keyscan 127.0.0.1
ssh-keyscan 127.0.0.1 >> -/.ssh/known_hosts
cat ~/.ssh/known_hosts
cat ~/.ssh/l=known_hosts
rm known_hosts
sudo vim/etc/ssh/ssh_config

sudo mkdir .ssh
cd .ssh
ls
cd /etc
cd ssh
pwd
sudo vim ./ssh config
 
ssh-keyscan 127.0.0.1
ssh-keygen -lf /etc/ssh/ssh_host_ecdsa_key.pub
ssh-keygen -lf /etc/ssh/ssh_host_ecdsa_key.pub -E sha512
ssh-keygen -lf /etc/ssh/ssh_host_ecdsa_key.pub -E md5
ssh-keygen -lf /etc/ssh/ssh_host_ecdsa_key.pub -E sha256



CONCLUSION:
	
What value is there in defining known hosts for SSH?
	Clients can recognize trusted Servers

	
What are the common packages that provide SSH protocol functionality to a Linux system?
	oenssh
	sshd

What file controls the server side configuration of SSH on a Linux system?
	sshd_config


What is the typical order of operations by an attacker who does not have credentials to access a system directly?
	Discovery
	Enumerate
	Gain A Foothold
	Maintain Persistence
	Cover Tracks

 Picking and choosing who has access to a particular piece of data is described by what aspect of the CIA Triad?
	Confidentiality


What is the most secure assumption to make with Linux distributions regarding SSH private keys?
	It is best to generate new keys


What is the security technique that creates a digest from a message in order to provide a guarantee of data integrity?
	Hashing


CompTIA Linux+:SELinux & AppArmor

Configuring SELinux Security

sestatus
sudo setenforce permissive
sestatus
sudo vim /etc/selinux/config
sudo setenforce enforcing
getenforce
cd /var/log/audit
sudo -s
cd /var/log/audit
tail audit.log
 
ps aux | grep crond
ps auxZ | grep crond
  
ps aux | grep httpd
ls -lZ

mkdir /website
vim /etc/httpd/conf.d/
cd /etc/httpd
ls
cd conf
ls
vim httpd.conf 
service httpd stop
service httpd start

cd
chcon -Rv --type=httpd_sys_content_t /website 

restorecon -Rv /website
sudo semanage fcontext -a -t httpd_sys_content_t /website
sudo yum install policycoreutils.python
sudo semanage fcontext -a -t httpd_sys_content_t /website
restorecon -Rv /website

semanage port -a -t http_port_t -p tcp 8080
semanage port -l

semanage port -l | grep 8080


Configuring AppArmor Security

apparmore_status

Ubuntu
sudo apparmor_status

sudo apt list apparmor*

apparmor is based on path name

ss -an

cd tunables
ls
aa-unconfined
sudo aa-unconfined
which apache2

sudo systemclt restart apache2 
sudo apt install libapache2-mod-apparmor

sudo aa-enforce /etc/apparmor.d/usr.sbin.apache2
sudo systemclt restart

CONCLUSION:
	

What command is used to add permanent policy changes to the label contexts defined for SELinux?
	semanage


What command changes the SELinux mode to permanently enforced?
	sudo vim etc/selinux/config and set SELINUX=enforcing

	
What can AppArmor do to protect a Linux system?
	Limit the resources a particular application can use

SELinux
	Designed to protect the entire operating system
	Default for Red Hat Distributions


Apparmor
	Default for Debian and Ubuntu distributions
	Designed to protect specific applications
	Uses path names	


What command identifies applications that are not protected by AppArmor?
	sudo aa-unconfined

What is the technique used by SELinux to secure running applications?
	Require system-wide label matching between applications and resources





CompTIA Linux+: Network Firewall & Traffic Filtering 
Using firewall to implement a Host-based Firewall


systemctl status firewalld
sudo firewall-cmd --state
sudo -s
firewall-cmd --get-zones
firewall-cmd --get-default-zone
firewall-cmd --get-active-zone
firewall-cmd --new-zone=testlab
firewall-cmd --permanent --new-zone=testlab
firewall-cmd  --list-all
firewall-cmd --list-get-zones
firewall-cmd --reload
firewall-cmd --get-zones
cat /etc/sysconfig/network-scripts/ifcfg-ens33

firewall-cmd --get-active-zones
firewall-cmd --get-services


firewall-cmd --permanent --add-service=http
firewall-cmd --permanent --add-service=ftp
firewall-cmd --add-service=ftp
firewall-cmd --add-service=http

firewall-cmd --list-services
firewall-cmd --permanent --list-services

firewall-cmd --permanent --add-port=8080/tcp
firewall-cmd --permanent --add-port=50000-60000/udp
firewall-cmd --permanent --get-services 

firewall-cmd --permanent --list-services
firewall-cmd --permanent --list-ports


Using iptables to Implement a Host-based Firewall
sudo -s
iptables --list

firewall-cmd --get-zones

yum list iptables*
yum install iptables-services -y
systemctl stop firewalld
systemctl mask firewalld
systemctl enable --now iptables
 
systemctl enable -now ip6tables ---> for IPV6 

iptables --list
iptables --list-rules

iptables -A INPUT -p tcp --dport 80 -j ACCEPT
iptables --list
iptables -A INPUT -p tcp --dport ssh -s 10.0.222.222 -j ACCEPT
iptables --list
iptables-save 
cat /etc/sysconfig/iptables
iptables-save > /etc/sysconfig/iptables
iptables-save | tee /etc/sysconfig/iptables

iptables -F ---> flush
iptables --list 

systemctl restart iptables
iptables --list

vim /etc/sysconfig/iptables

iptables -vnL --line ---> statistics 

watch -n 0.5 iptables -vnL


CONCLUSION:

What command identifies zones that are currently linked to network interfaces?
	firewall-cmd --get-active-zones


What objects are used by firewalld to control traffic flow?
	Zones

What iptables policy typically has the most individual entries on a workstation?
	Input

What technique ensures that firewalld cannot be started by other applications?
	systemctl mask firewalld


What iptables command would allow any device to access to a web servers default HTTP port?
	iptables -A Input -p tcp dport 80 -j ACCEPT
	



CompTIA Linux+: Backup and Restore
Performing Backups and Restoring Files


Differential and Incremental backup

man tar ---> glue together the files

tar cvzf /mnt/storage1/backup/tgz <where to back up ex. home/dpezet> ---> c means compress(backing up)
								     ---> x means extract(restoring)


ls /mnt/storage1
ls -lh /mnt/storage1

RESTORE IT
mkdir restore
cd restore
tar xvzf /mnt/storage1/backup.tgz
ls
cd home
cd /mnt/storage1

DAR - disk archive as opposed to tape archive

Ubuntu
dar
sudo apt install dar
dar -R /home/dpezet -c /mnt/storage1/full.bak
ls -lh /mnt/storage1
touch test1.txt
vim ./text1.txt

dar -R /home/dpezet/ -c /mnt/storage1/incr1.bak -A /mnt/storage1/full.bak.1.dar

lsblk
sudo dd if=/dev/sdb1 of=/dev/sdd1d
sudo mkdir /mnt/storage3
sudo mount /dev/sdd1/mnt/storage3
sudo -s
cd /mtn
cd /mnt 

CONCLUSION:


What command creates a compressed tar file containing the home directory and its subdirectories in a file called backup.tgz?
	tar cvzf /mnt/backup.tgz /home
	

Which backup strategy allows you to backup the changes each night since the last full backup was completed?
	Differential	

Which command can create a duplicate of the disk at /dev/sdb on to the disk at /dev/sdc?
	dd if=/dev/sdb of=/dev/sdc




CompTIA Linux+: Bourne-again Shell & Scripting
Using and Configuring Bash

cd /etc
ls pro*
less /etc/profile

ps aux | grep bash
source ~/bash_profile

sysinfo.sh 

set -o allexport ----> take any of my variables and set them to be exported


Creating Bash Script
vim sample.sh
	#!/bin/bash
	echo "Hello World


cat sample.sh

bash ./sample.sh
vim ./sample.sh

./sample.sh
ls -l
chmod  +x sample.sh
ls -l
./sample.sh


cat ./sample.sh

man read
man test
man seq
seq 1 10


CONCLUSION:

What should be the first line of a Bash script if you want to let the terminal know that Bash must be used to run the script?
	#!/bin/bash

                 
Which Bash configuration files can regular users edit in their home directories to override the system default Bash configuration files?
	bash_profile
	.bashrc


	
Where is the best place to put global custom Bash configuration settings that would apply to every user on a system?
	/etc/profile.d



echo -e --> Displays data on a single line and lets the next command continue displaying on that same line

read --> Gets data from the standard input and captures that input

test --> Asks a question used for comparing two values

seq --> Prints or generates a list of numbers


What command would make a variable called SCRDEPTH global so that it could be used in any Bash session?
	export SCRDEPTH

What command can be used inside a Bash script to determine if a directory called /srv exists?
	test -d /srv
	



CompTIA Linux+: Scheduling Tasks
Using at and cron to Schedule Tasks

ls
man at
at 10 PM Fri

/user/bin/bash /home/dpezet/backup.sh
uptime
press ctrl + d 
atq

cd/etc

cat at.deny
sudo cat at.deny

cron is a replacement of at

cd cron
cat logrotate
sudo cat logrotate


Run in specific time
cat /etc/crontab

the first asterisk is minutes, then hour, then day, then month, day

cd cron.d
ls
sysstat
sudo cat ./sysstat


Using cron and anacron to Schedule Tasks

cat /etc/crontab
ls /etc/cron.d
sysstat
cd
pwd
ls -a
cd /var/spool
cd cron
ls
sudo -s
cd cron
ls
ls -la
 
exit
whoami
crontab -e ---> edit

Install Anacron
sudo yum install anacron --> nickname is cronie

cat anacrontab


CONCLUSION:

Which crontab entry running as root gets cron to run the myinfo command every 15 minutes?
	*/15 * * * * root myinfo

Where do you find the hourly, daily, weekly, and monthly folders that contain the scripts scheduled for cron to run?
	/etc

		
What command allows you to set up a sequence of commands to run at 11 pm on Friday?
	at 11 PM Fri


What service can be used, or installed if it isnt already installed, to run scheduled cron tasks that cron missed because the system was off at the time the job was scheduled?
	anacron	


What command allows a regular user to add or edit their own cron tasks?
	crontab -e
	



CompTIA Linux+: Git Version Control
Describing Version Control and Using Git	

sudo yum list git
sudo yum install git

mkdir Projects
cd Projects

ls
cd
git config --global user.email <email>
git config --global user.name <name>

CONCLUSION:

What is the core purpose of the git command?
	Version control


What command is used to create a copy of a project that could allow for a project owner to approve or reject another persons changes to a git project?
	git checkout -b

What are prerequisites to using the git command for version control?
	Define email
	Define username
	Install git package

	

CompTIA Linux+: Installing CentOS
Describing CentOS and How it is Installed
Completing a CentOs Installation

CONCLUSION:

What are the first two actions recommended to protect a freshly installed instance of CentOS?
	install updates
	assign the root password
	
	
 What partition can be flagged as read-only for protection of the Linux kernel?
	/boot


What Base Environment installation choice installs the most common end user desktop onto CentOS?
	GNOME Desktop


What properties could be assumed if an ISO file has the name CentOS-7-x86_64-DVD-1810.iso?
	Released in October
	64 bit version of CentOS
	CentOS version 7


What is the minimum amount of memory required for CentOS with a graphical user interface?
	512 MB



CompTIA Linux+: Installing Ubuntu
- based on debian

CONCLUSION:

What installation option helps to ensure that an Ubuntu installation is as current and safe as possible?
	Download updates


What is the minimum amount of memory required for Ubuntu Desktop Edition?
	2 GB

What enables the application of updates that normally require restarting?
	Canonical Livepatch






___________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Virtualization Concepts

CompTIA A+ 220-1001: Virtualization

Overview  Virtualization
-Resource Utilization
-Software abstraction
-Behaves like hardware
-Redefines elements of IT



- Multiple installations of an operating systen on a single physical computer
	-Not simulated

-Isolated enabled by protocols and APIs
	-Greater flexibility
	-Reduced costs
	-Increased value

- Memory Requirements
	-Multiple operating system
	-Large memory requirements


Key benefits
-Flexibility
-Cost
-Scalability
-Reliability
-Performance


Purpose of Virtual Machines
-Perform tasks like a separate computer
-Guest VMs are created within the host
-A host can service multiple guest VMs
-Limited only by the physical resources available
	-On the physical host itself
	-How much has been allocated to each virtual machines

Common Uses 
- Trying new operating systems
- Testing new software
- Disaster recovery
- System Backup
- Business continuity
- Legacy systems
- Physical-to-virtual conversion 


Determining Virtual Machine Resource Requirements
-Study vendor published requirements
-Ensure appropriate amount of memory for application
-Providing excess memory resources
	-May improve VM performance
	- In certain cases, operating system will not recognize excess memory
	-Ineffective use of resources


Considerations for Using the performance Monitor
-Used traditionally inside a VM
-Work well for memory usage
-Not ideal for tracking CPU and I/O usage
-Can help with VM capacity planning
-Does not capture resources available to the whole(host) system
-Measurements can be skewed


Overview of Emulators
-Guest system do not have direct access to the actual hardware of the host system
-Guest systems use virtual devices for their configuration
-Emulator are used to present what appears to be an actual device to the guest system
-Emulator translate requests from the guest system to the host system

Common Emulated Devices
-Legacy Network adapters
-Floppy disk drives
-IDE/SCSI hard drives
-CD/DVD drives

Emulator Requirements
-Dependent on the host system
	-Host operating system and/or version
	-Hypervisor
-Virtual Machines are generally unaware that they are running as virtual machines, but newer host computer are aware of the virtual machine they are hosting
	-Newer Operating system and hypervisor require fewer emulators
		-Microsoft Hyper-V
			-Generation 1 vs Generation 2
			-Generation 2 supports VMBus which reduces the use of emulators





Security of Virtualization
-Evaluate risks
-Implements Measures
-Monitor
-Manage

Virtualization Security Measures
-Granular Security controls
-Granular security procedures
-Granular control and authority
-Protecting against vulnerabilities of physical system
-Setting security policies



Meeting Network Requirements
-Physical Computer hosting multiple virtual machine can have much higher network demands
	-Bandwith optimization
	-Multiple network adapters 
	- Compression or encrytion offloading	
	-Traffic prioritization techniques

Network Challenges with VDI
-Virtual desktop infrastructure is taxing to network
-Types of networks
	-Local area networks
	-Wide area networks
	-Internet
-Delayed performance/lag
	-Particularly for real-time applications
-Test and verify you network performance thoroughly before deploying a VDI configuration



Hypervisor
-Central to the concept of virtualization
-Separates OS and application from physical hardware
-Enables a physical host machine to operate numerous guest machines
-Capabilities extend to personal computers as well as servers

Key benefits
-Logical separation
-Isolation
-Easier to move and migrate

Types of Hypervisor
Type 1 Hypervisor
		Hardware
		   |
		Hypervisor
		   |
		___|___
		|     |
	    Guest 1  Guest 2


Type 2 
		Hardware
		   |
		Host OS
		   |
		Hypervisor
		   |
		___|___
		|     |
	    Guest 1  Guest 2


Security Concerns
-Malware
-Rootkits



CONCLUSION:

 If you have a virtual machine running a 32-bit version of an operating system and it currently has 4 GB of RAM configured, what level of performance boost should you expect if you allocate an additional 4 GB?
	None


 What functionality is provided by emulators in virtualization?
	They intercept hardware requests from the virtual machine and pass them to the physical machine



Which virtual machine resource setting often cannot be changed while the virtual machine is running?
	Memory


Which type of computing configuration can result in a much higher demand on your local area network when using virtualization?
	Virtual Desktop Infrastructure (VDI)



Why should the security of a physical host machine be given additional consideration?
	Because corruption of the host can result in corruption of all virtual machines on that host


Which type of computing scenario most closely describes virtualization?
	A single physical computer hosting multiple logical computers


Which feature of hypervisors distinguishes type 1 from type 2?
	Type 2 has a local operating system installed on the host system




_________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Java Defensive Programming

Defensive Java Fundamentals



Java Certified Foundation Associate: Java Debugging & Exceptions
Java Debugging with JDB

Java Platform Debugger Architecture (JPDA)
Java Debug Interface (JDI)

Java Debugging
-Stepping
-Breakpoints
-Exceptions

Debugging Methods
-Attaching class
-Comments in programs
-Code Debugging 
-Debugging on demand
-Java bytecode
-Remote debugging

Java Debugger
-Command-line debugger
-Notepad of VI driven
-IDEs (contains own debugger)
-Standalone debugger(GUIs)


JDB in Java Development kit (JDK)
-Java virtual machine tool interface(JVM TI)
-Java Debug Wiring Pool (JDWP)
-Java Debugger Interface(JDI)

Java Debugging Installation Steps
-Verifying Java Installation
-Setting up Java environment
-Verifying JDB Installation

Syntax of JBD Tool
-JDB
-Option
-Class
-Arguments


Option with command in JDB
-help
-attach
-listenany
-tclient
-tserver

Java JDB session
-Adding a class
- Adding to a running JVM


Java JDB Basic Commands
-help or ?
-run
-cont
-print
-dump
-threads  	
-thread
-where

Debug Code using IntelliJ
-Launch program with debugger attached
-Interferes with program and provides information
	-What's happening under the hood
-Facilitates detection
	-Fixing bugs


Executing code in Debug mode
-invoke context actions by using ALT+Enter and choose debug option
-Run icon in gutter area and selecting debug option
-Run menu or pressing Shift F9

Debug code using IntelliJ
-pause
-Resume
-Restart
-Stop


IntelliJ Breakpoints
-Stops execution of program
	-Allows you to analyze state of code
-Set up a breakpoint on a line of code
	-Click in gutter area
	-Use shortcut Ctrl + F8(Win/Linux)
	-Command key F8(macOS)



IntelliJ Debug Window
-Frames
-Console Window
-Threads
-Step action icons
- Variable Pane

IntelliJ Debugging Procedure
1. Define where program needs stopped
	-Breakpoints
	-Manually suspending
2. Run Program in debug mode
3. Use debugger to get information about state of program
	-Information about variable values, threads
	-Test program in various conditions
	-Stepping Feature
4. Fix without terminating session with intelliJ IDEA
	-Adjust and reload code on the fly


IntelliJ Debug Tips
-Debug non-responding applications
-Using pause
-Run pre-launch tasks



Java Debugging Best Practices
Java Breakpoints
-Conditional breakpoints
-Exception Breakpoints
-Watch points
-Trace points

Java Debugger Features
-Drop to frame
	-Jump back to a point in your stack frame
	- Eclipse enables uses to choose any frame
-Step filtering
	- Skip certain packages
	-Hepls filter out JDK classes from step Into
-Shortcuts
	-F5 for stepping into
	-F6 for stepping over and step return
	-F8 for running until next breakpoint


Best Practices When Debugging Code in Java
	Evaluate 
	Environment Variables
	Modify value of variable



Resolving Deadlocks in Java
-Two or more threads are blocked
	-Permanently
	-Cyclic dependency
-jstack deadlocks
	-Do not exhibit symptoms
		-Spike in memory, cpu, or OS metrics
	-Application monitoring solution
		-Advanced debugger and commercial APM tools




Remote Debugging in Java
- Allows you to debug Java code running on another machine
-Most IDEs support remote debugging
	-NetBeans
	-Eclipse
	-IntelliJ Idea
	-Visual Studio

Debugging Code in Java
Tips
-Copy stack option
-Suspend and resume threads 
-Step into feature
-Step over feature
-Under the step return option



Java syntax and logic errors

Errors in Java code

Syntax
	-Language used to create code is incorrect
	-Compiler will catch most errors
	-Does not cover mistakes in logic of program itself

Logic
	-Code isn't performing as expected
	-Difficult to find
	-Time consuming going through code to find reason for errors



Syntax errors in Java
Unintelligible commands
	Java has its own syntax
Compiler error
	-will be detexted immediately
Runtime error
	-not detected until program running

Common Syntax Errors in Java
	Forgetting to import a class
	Missing parenthesis
	Splitting a string over two lines
	Treading s static method as an instance method
	Using incorrect capitalization
	Forgetting the class or object
	Missing curly braces
	Mistyping the header for the main() method
	Omitting the break clause from switch statements
	Omitting a return statement



Common Logic Errors in Java
	Assuming a condition is true
	Defining the wrong count
	Using incorrect operator precedence
	Misplacing a semicolon
	Relying on integer values
	Relying on a floating point numbers




Java Exception Handling
	Often Overlooked and underestimated
	Unavailable stock
		Failure in delivery
	Ability to alter the flow of code

Why use Exceptional Handling
	File cannot be found
	Intenet connections breaks
	Not enough memory

Exception Hierarchy
Checked Exceptions
	Typically plan ahead
	Handled-or-declared when writing code
	Detectable before runtime

Unchecked Exceptions
	Also called Runtime Exceptions	
	Occur due to human error
	Checked at runtime
	Often can be countered

Errors
	Most serious exceptional condition
	Often irrecoverable
	Occur due to human and environment errors



Best practices for java Exceptions
	Clean up resources
	Prefer specific exceptions
	Document Exceptions
	Throw exception with descriptive message
	Catch the most specific exception first
	Don't catch throwable
	Don't ignore exceptions
	Don't log and throw
	Wrap the exception


Common Java Exceptions
	Checked Exceptions
		IOException
			Input/Output operation fails
		I/O Operations
			Java.io package
			Java.net package
		ParseException
			Used to create an object based on a given String
			Happens when parsing causes an error
			Formatting
				dd/mm/yyyy or dd,mm,yy
	Unchecked Exceptions
		
		InterruptedException
			join(), sleep(), wait()
				WAITING state or TIMED_WAITING state
			Thread can interrupt another thread
			Calling interrupt() method
		NullPointerException
			Application attempts to use null when requires object instance 
			Illegal use of null	
				Method of class that has no object instance
				Access or modify instance variable with null reference
		ArrayIndexOutOfBoundsException
		StringIndexOutOfBoundsException
		NumberFormatException
		ArithmeticException
		ClassCastException
		IllegalArgumentException
		IllegalStateException


Java Try Catch Blocks

Java Exceptions
Java try and catch
Finally statement

Exception handler syntax
	Surrounded in braces
	try{.....}.....
	Followed by catch
	catch(....){.....}

Java Catch Block
ExceptionType
	Exception handler
		Indicated by its argument
	Executed if and when the exception handler is invoked
		Runtime system

Triggered within the corresponding try block
	Try block "jumps" to catch statement
		Checks for matching exception type
	Error recovery
	Propmt users to make decisions
	Propagate errors

Java Exception Handler
Catch block can handle more than one type of exception
	In Java SE 7 and up
	Reduces code duplication
	Lessens temptation
	Catch parameter is implicitly final

Java Finally Block
	Resource clean-up
	Check for open file., network, and database connections
	Must handle both success and failure conditions


CONCLUSION:


What hotkey is used to set a breakpoint on the current line of code in IntelliJ running on Windows or Linux?
	ctrl + F8


What option is used with JDB to specify where to find class files?
	-classfiles



 What is the base exception superclass?
	Throwable

What exception block contains code that is run regardless of an exception being thrown or not?
	finally

Syntax Error
	Mistakes caught by the compiler
  	Misuse of the Java language
	

Logic Error
	Conditional statement error
	Code performance error


What IntelliJ shortcut key is used to step over a function call?
	F8

What is a common use for the finally block in exception handling?
	To clean up open resources


What type of exception is the ParseException?
	Checked exception

What type of exception must be caught and prevents a Java program from compiling if they are not caught?
		Checked Exception


What is a deadlock in a Java program?
	When two or more threads are blocking permanently


What option is used with JDB to specify where to find source files?
	-sourcefile



What exception is thrown by the code provided?


Int[] a = new int[5];
Int b = a[5];

	ArrayIndexOutOfBoundsException


_______________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Automated Software Testing

Comparing Manual & Automated Testing

Software Development Life Cycle
	Systematic Process
	Application Correctness
	Produces High-quality software
	
Importance of SDLC
	Project tracking
	Project Planning
	Project Control
	Project Scheduling
	Increases visibility & Development Speed


SDLC Phases
	

			Plan
					Define
	Deploy
			SDLC
				
	Test				Design
			Build
		


Requirement collection & Analysis
Feasibility study
Design 
Coding
Testing
Installation/Deployment
Maintenance


SDLC Model

Waterfall model
V-model	
Spiral Model
Incremental Approach
Agile Model
Big bang model


Manual Testing and Types

Manual test case execution
Primitive Approach
Requires more effort


Goal of Manual Testing
	Error Free
	100% test coverage
	Fixed defects
	Bug-free products 	


Types of Manual Testing
		

				    Black Box
	Acceptance Testing				White Box

	Integration Testing				Unit Testing
				    System Testing
	

Methods to Perform Manual Testing

	Read and Understand
	Draft test cases
	Review and baseline
	Execute
	Report bugs
	Again execute


Frameworks for Manual Testing
Selenium 
	Open source
	Web-Based
	Portable
	Playback
JMeter
	Open source
	Written in Java
	Static & Dynamic
	
TestLink
	Web-based
	Test management system
	Quality assurance
	Provides several support services
QTP and Quality Center
	Support regression and functional testing
	Quality Assurance
	Provides simple GUI
	Controls applications
	Convenient and user-friendly
FogBugz
	Web-based 
	Simple interface
	Easy to use
	Requires license


Manual Testing Models

Waterfall model
	Most basic software development life cycle process
	Phases of Waterfall
		Requirement gathering and analysis phases
		Software design
		Programmed implementation and testing
		Maintenance

	Advantages				Disadvantages
	Easy to implement			No alteration
	System help save time			No change in next Phase




V-Model
	Superior to waterfall model
	Development and test execution in parallel
	Phases of V model
		Unit testing
		Integration Testing
		Regression Testing
		System Testing
		Acceptance Testing

	Advantages		Disadvantages
	Easy to use		Rigid model
	aves time		Lack of early prototype products



Agile Model
	Collaboration between various cross functional teams
	Alse called iterative and incremental model

	Advantages			Disadvantages
	Customer satisfaction		Difficult to assess required effort
	Flexible model			Continuous interaction with customers


Spiral Model
	Like agile Model
	Phases of Spiral Model
		Planning
		Risk analysis
		Engineering
		Evaluation

	Advantages				Disadvantages
	High risk avoidance			Costly model
	Good for complex and large systems	Not good for simpler projects


Rational Unified Model
	Phases of Rational Unified Model
		Planning
		Risk Analysis
		Engineering
		Evaluation
	Each Iteration must satisfy defined criteria before the next phase


	Advantages			Disadvantages
	Able to resolve risks		Require expert knowledge
	Integration take less time	Can create confusion in big projects


Rapid Application Model
	Like agile Model
	Components are parallel to each other
	Assembles components into products

	Advantages			Disadvantages
	Reduces Development		Require strong team
	Resolves integration issues	Is module-based


Automated Testing and Types

Automated Testing Steps
	Execute test csase suite
	Enter test data
	Compare expected and actual results
	Generate reports

Importance of Automated Testing
	No Human intervention
	Increase speed
	Increases test coverage
	
Test cases to Automate
	High Risk
	Repeated executed
	Tedious to perform manually
	Time-consuming

Automated Testing Process
	
	Tool selection	------>	Scope definition ----->	Plan, design, and develop ----->  Execute ---->	Maintain


Benefits of Automation Testing
	Faster then manual testing
	Ensure consistency
	Save time and cost
	Improve Accuracy
	Achieve more cycles of execution	
	Early time to market



Frameworks afor Automated Testing
	
Test Automation Framework
	Coding Standards
	Test-data handling
	Beneficial outcomes
	Higher portability
	Increase code reuse

Types of Automation Framework
	Linear scripting	
		Advantages 								Disadvantages
		Fastest way to generate scripts						Little reuse of scripts
		Doesn't require automation expertise					Test data is hard-coded into scripts
		Easiest approach to learn the features of testing tools			Complex maintenance
	Test library architecture framework
		Advantages								Disadvantages
		Structured scripting							Requires technical expertise
		Less costly								Time-consuming
		Easier script maintenance						Hard-coded
	Data-driven testing framework
		Advantages								Disadvanatages
		Changes in test scripst do not affect test data				Require more time to plan
		Test cases can be executed with multiple sets of data			Require more time to prepare test scripts and test data
		Can execute variety of test scenarios	
	Table-driven testing framework
	Hybrid test automation framework



Automated Testing Models

Value of Automation
	Release small changes to production
	Toggling
	Fast feedback loops


Automated Testing tool
	Ranorex studio
		Functional UI and end-to-end testing
		Cross-browser testing
		Test SAP, ERP, Delphi, and legacy applications
		iOS and Android Testing	
		Run test locally
		Robust reporting
	Mabl	
		Test proprietary machine learning models
		Automatically repair test when UI changes
		Automated regression insights on every build	
	QTP
		Easy test case creation
		Helps fix defects faster
		Supports collapse test creation
		Easy parameterization
		Better object identification mechanism	
		Enchances existing QTP scripts

Manual Testing					vs. 			Automated Testing
Test are executed manully						Write code/test scripts
Performed to discover bugs						Test executes in less amount of time
Check all essential features						Relies on pre-scripted tests
Execute test case and generates test reports				Allows executing repetitive tasks
Utilizes classical method						Requires minimal manual effort


Key differences

Manual testing
	Performed manually
	Not accurate
	Time-consuming
	Possible without programming knowledge
	Allows random testing


Automated Testing
	Performed using scripts and code 
	Reliable
	Very fast
	Not possible without programming knowledge
	Does't allow random testing


Scenarios for Manual testing
	Exploratory
	Usability
	Ad hoc testing
	Frequently changing AUT


Scenarios for Automated testing
	Regression testing
	Performance Testing
	Load Testing
	Highly repeatable functional test cases




CONCLUSION:

What test elements can we use to transform a manual test to an automated test?
	Test scripts
	Test framework

Which of these elements do we need to specify in a test case template for manual testing?
	Test steps
	Test data


Identify some of the prominent features afforded by Ranorex Studio.
	Support for testing SAP, ERP, Delphi, and legacy applications
	Ability to run tests locally


Identify the QTP or UFT functions that we can use to implement automation testing.
	virtualObject()
	dialog()

 Select the different types of services that we can test using Postman.
	SOAP
	REST


What are the different types of test cases that we can automate?
	High risk
	Time consuming
______________________________________________________________________________________________________________________________________________________________________________________________________

Automated Software Testing


Regression Testing
	used to ensure that any changes that have been made to software haven't broken the software
	
Unit testing 
	a form of white box testing
	isolates and test one portion(unit) of the software



Functional Testing
	A form of black box testing
	Does the software do what it should?
	Does the software meet design requirements?

Fuzzing
	 form of black box testing
	analysis performed on executed code
	fuzzing uses unexpected randomized inputs to determine how software will respond

Black box testing mean that testers don't have access to the source code or implementation details
White box testing mean that testers have access to the source code or implementation details


Steps for implementing Fuzzing
-Identify the target software/system
-Identify software inputs
-Generate fuzz data
-Execute our test using our fuzzing software
-Observe the behavior 
- Review the fuzzer log as well as the application software logs


Web Application Firewalls (WAFs)
	can be deployed on-premises or in the cloud depending on where traffic that destined for the web application is routed
	- the purpose of it is to mitigate HTTP-specific attacks	 

Load Testing
	test software under normal load conditions
	requires a baseline of normal activity
	
Stress Testing
	Test software under extreme load conditions
	commonly used to test high availability solutions


CONCLUSION:

Which of the following is covered by Integration testing?
	Inter-component communication

What type of testing uses unexpected randomized inputs to determine how software will respond?
	Fuzzing
	

GUI testing normally follows which type of test?
	API

 When should unit testing be performed? Choose two.
	Prior to functional testing
	Prior to code check in

Which command starts the Google Chrome web browser in headless mode?
	chrome --headless --disable-gpu --remote-debugging-port=9222


What category does Functional testing fall under?
	Black box


 What type of testing ensures that patches have not broken existing functionality?
	Regression


How are headless browers normally invoked?
	CLI

Web application firewalls listen to which type of network conversations?
	HTTP

Why is regression testing important?
	Problems are not expected for things that already work

Which type of testing focus on tweaking software performance?
	Load


You have created a TestComplete project for a desktop application. What must be added to the project?
	Applications to test

What category does API testing fall under?
	White box

__________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Types of Test Doubles

Dummy objects
Stub class
Fake objects
Mock object


Using Test Double

	Mock
	 |
	Execution
	 |
	Validation

Benefits Of Mocking API
	API MOCK
FOr tester to stimulates external dependencies and unexpected behavior
For operation and architect to enable isolated development project
For functional tester to create test during development 
For Customers to try APIs 
For developers to be independent of API availability and functionality


4 types of machine Learning Problems

Never mock values
Avoid mocking concrete classes
Use Intergration tests
Mock Selectively


Course Summary

Implementing Unit Testing Best Practices
	Unit Testing pattern and frameworks
	JUnit and TestNG AAA testing
	Testing REST APIs 
	Unit testing with TDD
	Automated testing with JUnit and selenium


ESSENTIAL CHECKLIST FOR PLANNING AGILE TESTING
-Listing deliverables and milestones
-Planning load and performance testing


PROMINENT TESTING PATTERN THAT IS USED TO IMPLEMENT UNIT TESTING
-Database test pattern
-State test pattern

Characteristics of bad test
-Using non-deterministic factors in the codebases
-Mocking interfaces and classes outside the codebases

Valid category of test automation framework
-Hybrid
-Keyword-driven


Annotation we use to implement AAA pattern in JUnit
@RunWith
@Parameters

Best Practices that we can follow when using Mocks
-We should avoid mocking concrete classes
-we should never mock values


Different Approach that we can use to mock object using Mockito
-Using the @Mock annotation
-using the static mock() method



Assert libraries that we can use with Mocha to test RESTfuk APIs
-Chai
-Should.js

Different type of Mocks that we can use with SoapUI to unit test web services.
-Soap mock
-REST mock


Subclass of DBTestCase that we can use to write DBUnit test cases to connect and execute test cases
-JdbcBasedDBTestCase
-DataSourceBasedDBTestCase


Annotation can we use to manage test fixtures to implement Test-driven Development
-@After
-@Before

Classes of openQA package that we use to integrate unit test creation with JUnit and Selenium to test browser compatibility
-By
-WebDriver


Automated Testing: Design Patterns
Importance of Automated Testing
Why Test?
	- reliability
	- Accuracy
	- Safety
	-Efficiency

Repetitive Tasks
- Automation
-Bug Prevention
-Productivity

Improve Understanding
-Documentation
-Auditing
-Refactoring

Manual Testing
-Discovery
-Establish Patterns
-Determine what to automate

Software Developers Testing Roles
QA Tester- traditional software development role
Automation test Engineer- Test-centric code and operations


Roles and Responsibilities
Test strategy - testing methodologies
Coordination- Reporting and tracking
Tools- getting the job done

Domain Considerations
Scalability
Efficiency 
Reliability

Unit testing
	verify individual parts

Code paths
Code coverage
	
Manually- testing the test
Automated-testing regressively

Testing Effectively
Proactive
Creative
Think Outside-the-box

Functional Tests- comprehensive end-to-end

High-level Planning
Goals
Support
Ease to use


Functional testing
-unit testing
-intregration testing
- White box and black box testing
-regresssion testing

Non-Functional
-Performance Testing
-Stress Testing
-Penetration Testing
-Migration Testing

Strategic components
Team expertise
Maintainability
Ecosystem
Efficiency

Unit Testing-code-centric
API testing-interface-centric

UNIT Testing
Code coverage
Testing possible paths
Individual parts
Developer-driven

API Testing
Inputs ans outputs
Expected behavior
Integration
QA-driven

Complementary Features
Work outwards


Test-Driven
Write tests first- then code to pass test
Consider all inputs- expected errors
Improve refactoring- refactor test first

The AAA Pattern
Arrange
Act
Assert

Behavior-driven Development (BDD)
Outside-in
User Interactions
Multi-step Automation
Case-based

Outside-in 
User-centric
Use cases
Highest level
Customers expectation
Validation

Inside-out
Code-centric
Application units
Lowest level
Specification details
Verification

Programming Libraries-driven by unit tests
Command Line applications
	Inside-out
	Options and Arguments
	Limited Interaction

GUI applications
	Underlying code
	Interface code
	Stateful assumptions

Web application
	Server-page generation and API tests
	Browsers-Multi-client considerations
	Page tests-behavior and functional

Traditional- scripts and macros

Programming Language Oriented
	Request Libraries
	Simulation
	Unit testing
	Framework testing
	Postman and  swagger
	Web-driven- selenium webDriver
	Page Objects- reusable components

Navigationg with Selenium webDriver

python --version
pip --version
pip3

Conclusion

The main purpose of manual testing is to determine what to automate

Quality Assurance Tester- Traditional software developments team role
Automation Test Engineer- test centric code and operations role

Unit Test effectively used in automated testing by testing the smallest testable parts


Web- type of application is often associated with multi-client considerations

Web bases- type of testing tool is Selenium

Web browser- element does the selenium WebDriver provide interface for.


Assertion- the result of  a unit test typically verified

Creating reusable code- main benefits of using the Selenium page Object pattern

TestCase- class that implemented in creating a test case using the Python unittest library.

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

JUnit Fundamentals


When doing regression testing we want to be able to manage test in small groups. What class is defined in JUnit to allows us to do this?
	---@SuiteClasses


The @After annotation provides us a way to help clean up our testing environment. The @After annotation signals JUnit to run the methods at which point in the testing cycle?
	--After each test has been run

There are times when we want to put control to the results in the hands of the test designer and developer, which may or may not be the same person that's developing the code. What annotation in JUnit allows us to be able to specify what will be returned by the called method regardless of how that method actually behaves?
	---@Mock

In JUnit there is a really powerful way to allow us me to focus in, to just run a specific type of test. We can define at a method level much more than at class level, which types of test I want to run. Which annotation allows us to unlock this functionality?
	---@Category


JUnit provides a basic test runner that will execute most test cases for you. As we expand the custom features that needs special test condition or use third party solutions, we need to use the smarter test runner to execute our test. What must be passed as a parameter into the @RunWith cutom runner annotation in order for test cases to execute correctly?	
	--A class object



While the test fixture capability provides many good options Managing files, database connection, pr any customized solution you wish to create, in a reusable way can be accomplished by which of the following annotations?
	--@Rule

Test cases are written to check functionality, but the test space can often be expanded dramatically by simply changing the input values to a test. JUnit provides a mechanism, by which we can execute a test many times across a changing set of inputs. What is the annotation that allows us to use this functionality?
	--@Parameters

When doing performance testing or testing to see how the system responds to a lot of data, JUnit provides us with a tool to simplify the process. This tool allows us to perform rapud test data generation and clear mechanism for externalizing data. It even gives us the ability to check that the data is valid and this reducing false failures. What is the feature within JUnit that allows us to do so?
	--Theories


Test suites have always existed in JUnit, but have changed quite a bit from the legacy to the current approach. If you deal with legacy test suites, it may be useful to see how they can be used or converted into their modern equivalent. Legacy JUnit testing required you to do what to the TestSuitee class in order to be able to use it?
	--extend

In JUnit there is an annotation that provides us an extension to give us universal checks across all test cases within a JUnit test, or further details and control within each test. It gives us moere granularity and control to create customized testing, beyond what is provided in basic JUnit. What is that annotation?
	--@Rule


JUnit has been a solid testing framework for a very long time. The most recent versions take a great advantage of annotations. But many test were created before this job enchancement. Legacy test cases had extended out what class?
	--TestCase

JUnit is most effective when run with every change, to ensure that the code is always working. Integrating JUnit into tools, which executes many Java builds these days, allows us to test the code each time it is recompiled. What is a tool that can be integrated with JUnit to do this?
	--Maven

While we wan out test to always be passing, it's inevitable that some will fail ovet time. As features are not yet developed, are being changed, or simply we just don't have time to fix the test. While we still may want that test around, we now have the ability to temporarily ignore it's execution using a simple annotation. Which of the following annotation allows for this functionality?
	--@Ignore


Most testing is directed at funtional requirements and satisfying the behavior within the system. We cannot forget, however, that execution time is a factor for the acceptability of solution as well. Which of the following is a properly formatted annotation that will have a time limit of 2 seconds before the test is considered to have failed?
	--@Test(timeout=2000)


By default JUnit will execute test cases in whatever order it decides, which could vary each time the test is executed. Some test designs must assume a specific orfer for each test case. What annotation in JUnit allow us to be able to specify the order that tests will run?
	--@FixMethodOrder

_________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

CompTIA Linux+ 

Introduction to Linux & Command Line Interface

Crtl + Alt + F1 = open CLI

Pound symbol = root user
Dollar sign = regular user

COMMANDS
ls =shows all the file that are in my home directory 

uname = show the Unix name of the system

history = show all the different command that you've typed since you started the system

clear = clear the screen

pwd = show your present working directory

echo = used to show text on the screen

touch = create a empty file

vi = use to edit file 
nano = use to edit file

cat = shows the text  index

whoami = shows you what user account you're logged in as.

su = substitute to other user

su root = become a root user
su - 

cd/etc = access sudoer file
sudo = stands for super user do, we're telling the super user to do something, use if you only use dew commands

sudoer file = if you make mistake in sudoer's file you could make  it where you're no longer able to use the sudo command, and you might end up locking yourself out of the machine 


sudo visudo = special version of vi that is specifically set to edit the sudoer file
sudoedit = shortcut for the default sudo editor
which ip = which command tell you where that command actually exist




Conclusion

There are hundreds of linux distribution.

sudo vi/etc/sudoer  &
sudoedit /etc/sudoers - command that grants additional users access to use the sudo command

[root@localhost ~]# ls -la /usr = the argument is the /usr

man = linux shell command that is used to display help

sudo <command> = command is used to run only a single command under the root administrator context

1991 =Linus Torvalds annouce his new free operating system

When changing user contexts what benefits if there to using su -<username> instead of su <usename>, it create a full login session that changes directories.
 
What is the impact of running the dash shell instead of bas shell?
	A small percentage of the commands will be different

What is the focus of Open Source software
	enabling community collaboration

What domain in the Linux+ Exam is particularly useful to new user who are frustrated when their installation of a Linux based OS doesn't work and they don't know how to fix it?
	Linux Troubleshooting and Diagnostics





CompTIA Linux+: Managing Users & Groups


man useradd
useradd = command that add users
-c = command that allows you to put comment
  ex. -c "Elizar Gimenez"

-e = command that is use for expiration date of the user
  ex. 2019/12/31

-s = command to change the shell
  ex. -s /bin/dash

-d = command to create a folder
  ex. -d home/jane_smith


Example of adding user 
sudo useradd -c "Jane Smith" -e 2019/12/31 -s /bin/dash -d /home/jane_smith jsmith


Get the user id
	sudo useradd sarah
	sudo id sarah 

Delete account = deleting user is not a good practice but if you do add -r to remove their home directory 
	sudo userdel sarah
	sudo userdel -r sarah



man usermod =command where you can modify any login

usermod -l = -l  change the name

sudo passwd <username>= change password

man chage = designed to change the age of a password or set an expiration

sudo chage -l <username> = it will tell everything about their password

sudo useradd -D = it will show all the defaults

cd /etc/skel = skeleton folder


sudo less /etc/login.defs = login definition


GROUP creating
ex. sudo groupadd Sales
    tail  etc/group


Group deletion
	groupdel or group delete

Changing the name
sudo groupmod -n <new name> <old name>


Add user into the group
sudo gpasswd -a <username> <group name> = group password command and also allow you to add user to the group

Remove the user from the group
sudo gpasswd -d <username> <group name>

Make the user the administrator to the group
sudo gpasswd -A <username> <group name>

CHANGE THE GROUP CONTENT FOR A MOMENT
newgrp <group name> = change the context for a moment

chown = to change the owner

getent or get entity = used to find information inside of the /etc/group/ and /etc/passwd file as well

CONCLUSION:

passwd = command can an administrator use to change the password of an existing user account

The advantage of using the -r switch in the context of the userdel command is it removes user's home directory

Currently the most common use of the -c switch of the useradd command is to store user's fullname

cat etc/group |grep <username> = command that would reveal the MOST information about groups of a certain username.

The effects of using the -A switch when executing the gpasswd command are add a user to a group and then makes the defined user a group administrator


CompTIA Linux+: File Access & Permissions
Working with File Permission and Ownership

ls -l = command for longer list of names



	
	Owner 
	permissions
	   |
	   |	Other permissions
	   |       |
	d rwx r-x r-x DirA
	|      |	  
    Type     Group
    of 	     permission
    Objects


rwx= means read, write, execute

Identities
u            = user
g	     = group
o	     = other

Permissions
- 		=none
r		=read
w		=write
x		=execute  

Numerical Values
4		= Read
2		= write
1		= execute

Numerical Notation
0	=none
1	=execute
2	=write
3	=Write and execute
4	=read
5	=read and execute
6	=read and write
7	=read, write and execute


Modify Permissions

man chmod
ex.
chmod g+w <file>
chmod o-r <file>
chmod g+w, o-r <file>
chmod u=rw, g=rw, o-rwx <file>   // Equal symbol override the permission

File listing
ls -l file* = files details


umask = what defines the default permission

umask Values

0 =read, write and execute
1 =read and write
2 = read and execute
3 =read only
4 = write and execute
5 =write only
6 =execute only
7 = no permissions

mkdir <directory name> = make directories

chown <specify the owner you want to be> 
sudo chown <name of owner>:<group> <file> = change the owner


Change the group
chgrp <group> <file>

Change the group without changing the owner
sudo chown :<group> <file>


Change the ownership in sub-directories
sudo chown -R <name> /home/<filename>/*

When you take the archieve, if you use the tar command to wrap up the files first, the tar
command will actually back up the permission as well.

USING FILESYSTEM ACCESS CONTROL  LISTS

What FACLs do, is they allows us to assign extra stuff, you still have the UGO that doesn't change

getfacl
setfacl = modify new style FACL permission and also the old style Unix.
-m = means modify
ex. setfacl -m o::r <file> 
    setfacl -m u:<username>:rw <file>
    setfacl -m g:<group name>:rw <file>


-t = Sticky bit is designed for shared folders, it tells the folder to watch for when people create documents to be able to tack that on and keep track of who created it

Turn on the sticky bit using the chmod
ex. chmod o+t,g+t CorpData

CONCLUSION:

setfacl and getfacl commands enables for Linux administrator to access to more advance and granular permissions

chmod u=rwx,g=rw,o=r file2.txt & chmod u+x,o-w file2.txt =commands that grant owners read, write and execute; group memeber read and write; and other read only permission on afile named file2.txt that already had the permission -rw-rw-rw

An administrator types ls -l they recieve the results d rwx r-x r-wx DirA. What does the "r-x" represent in this output?
	group permissions


What is the purpose of the sticky bit in Linux permission?
	ensure that only file creators can delete their files



CompTIA Linux+: Disk Partition & File Systems

lsblk partition command 

sudo fdisk /dev/sdb = take you to the fdisk editor 



man mkfs = show the help files for make file system
ls usr/sbin/mkfs*


making swap partition
sudo mkswap /dev/sdv3
sudo swapon /dev/sdv3

CONCLUSION:

MBR	-default Linux partition ID is 83
	-Uses the fdisk utility to manage partitions
	- Limited to 4 primary partitions
	-Support an extended number of partitions through logical partitions

GPT	-Limited to 128 partitions
	-Uses the gdisk utility to manage partitions
	-Default Linux partition ID is 8300


ext4	-A very mature and fully supported file system used as the default by ubuntu.
ZFS	-Has a strong following but mainly designed foe network storage appliances or clusters doing shared storage.
Btrfs	-Tends to be a more cutting edge file system that has built-in support for software raid.
XFS	-Has built-in support for partition resizing, backed by Red Hat, and is the default in CentOS.

Which commands can format the first partitions of /dev/sdb using the XFS file system?
	mkfs.xfs /dev/sdb1
	mkfs -t xfs /dev/sdb1

What command makes the first ext4 formatted disk partition on /dev/sdb available from /mnt/private?
	mount/dev/sdb1/mnt/private


CompTIA Linux+: Logical Volumes & Filesystem Hierarchy

Logical Volume Manager	
	allows us to have a lot of flexibility with our file systems.

sudo yum list lvm*

if the lvm is not installed
sudo yum install lvm2
lsblk
ls /usr/sbin/vg*
ls /usr/sbin/lv*
sudo pvcreate /dev/sdb1/dev/sdc1 
sudo pvdisplay
sudo vgcreate vgl /dev/sdb1/dev/sdc1 
sudo lvcreate -L 1500G vgl -n lv1
sudo lvdisplay


CONCLUSION:

What directory represents all of the executable that are currently running in memory?
	-proc

What is the correct descriptive syntax for creating a logical volume using LVM?
	-lvcreate -L <size> <physical disk name> -n <logical volume name>


What is the purpose of the Linux Foundations Filesystem Hierarchy Standard?
	-Ensure user and software can file and directory locations


What directory is designed to hold data that is temporary and not mission critical?
	-var

What commands are needed to increase the size of a logical volume located on physical volumes that are completely allocated?
	-lvresize
	-pvcreate
	-vgextend

What LVM component represent the aggregation of disk space before it is dispersed to mountable blocks of storage?
	- Volume Group

What is the purpose of the Linux Foundation Filesystem Hierarchy Standard?
	- Ensure users and software can file and directory locations


_______________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Project Management Overview

Project Management  Definition of Terms
PMBOK guide definition

Project
A temporary endeavor undertaken to create a unique product, service, or result.

Project Management
Application of knowledge, skill, tools and techniques to project activities to meet project requirements.

Project Stakeholders
Persons and organizations such as customers, sponsors, performing organization, and the public, that are  actively involved in the project, or whose interests may be positively or negatively affected by execution or completion of the project.


5 Main Phases of the Project Life Cycle

Monitoring And Controlling
Initiating
Planning
Executing 
Closing


Project Planning
Purpose: 
	To develop a plan that enables the project to be executed and controlled. Planning defines the overall parameters of a project and to establish the appropriate project management and quality environment required to complete the project. 


Project Manager
(Accountable / Responsible)

Project Planning activities are:

Definition and scope of the project
Identification of development phases or software development cycle (SDLC)
Identifying necessary resources 
Defining project organization
Estimates and Project schedule
Identifying project processes
Identification of related plans (Quality Plan, Test Plan, CM Plans)





Project Scope

Scope refers to work that must be done to deliver a product with the specified features and functions

Project requirements
Deliverables (internal and external)
Development phases to be carried out
	Required input and output of each phase
Support Activities
	Configuration Management
	Reviews
	Trainings 



Project Resources and Organization
They can be people, equipment, facilities,funding, or anything else capable of definition (usually other thanlabour) required for the completion of a project activity. 



Human Resources
	Manpower needed
	Knowledge and Skills necessary 
Organizational responsibilities and work assignments
Organizational and technical interfaces between different groups
Equipment, Software, Facilities, Tools
	Availability
	Make, buy or reuse
	Budget for purchase
	When to buy, when is it needed




Quality Plans

Quality planning is identifying which quality standards are relevant to the project and determining how to satisfy them


Quality Targets
Processes
	rules, practices and conventions
	templates, procedures and guidelines
	tools and techniques

Quality Assurance and Control Activities
	Reviews
	Testing
	SWQC


Engineers Role in Planning

Project member
Project Planning is the PM / PLs responsibility. So What is my role in project planning ?


Project Manager
Basically you are expected to do the following:
Provide inputs for estimation
Inform PM of your skills
Accept roles and responsibilities assigned
Inform PM of any concerns or issues that you think should be considered in planning
Give PM your commitment to the project plan
Note: Commitments are obtained during Project Kick-off



Project Control

Control is the process whereby the project manager determines the degree to which the project plan is being met.

Control reduces the difference between project plan and reality.


When to Exercise Project Control

When there is still time for corrective action

Throughout the project life cycle




Monitoring and Controlling Activities

Gather information			------>   Evaluate information and do corrective actions as needed
 Meetings
 Reports	




What to Monitor and Control in Projects

Scope
	Project Objectives
	Project Deliverables
	Project Requirements
Project Schedule
Project Cost
Risks
Issues
Quality
Project Performance
Project Changes
Commitments
Support Activities such as Planning, CM, Requirements Manageme




Project Status Report
Reporting period (From / To)
Tasks and % Completion
Actual Start and Finish Dates
QCD Data
Size of deliverable
No. of Defects / Bugs
Man-hours for creation, review, rework
Review status and coverage
Tasks scheduled for next reporting period (Planned start and finish dates)
New or unplanned risks
Issues / problems (Impact on project, recommended solution)



Project Scope
Scope refers to work that must be done to deliver a product with the specified features and functions

Project requirements
Deliverables (internal and external)
Development phases to be carried out
Required input and output of each phase
Support Activities
Configuration Management
Reviews
Trainings 

Project Resources and Organization

They can be people, equipment, facilities,funding, or anything else capable of definition (usually other thanlabour) required for the completion of a project activity. 
Human Resources
Manpower needed
Knowledge and Skills necessary 
Organizational responsibilities and work assignments
Organizational and technical interfaces between different groups
Equipment, Software, Facilities, Tools
Availability
Make, buy or reuse
Budget for purchase
When to buy, when is it needed


Quality Plans
Quality planning is identifying which quality standards are relevant to the project and determining how to satisfy them

Quality Targets
Processes
rules, practices and conventions
templates, procedures and guidelines
tools and techniques

Quality Assurance and Control Activities
Reviews
Testing
SWQC


Project Planning is the PM / PLs responsibility. So What is my role in project planning ?
Basically you are expected to do the following:
Provide inputs for estimation
Inform PM of your skills
Accept roles and responsibilities assigned
Inform PM of any concerns or issues that you think should be considered in planning
Give PM your commitment to the project plan
Note: Commitments are obtained during Project Kick-off


Control is the process whereby the project manager determines the degree to which the project plan is being met.

Control reduces the difference between project plan and reality.


What to Monitor and Control in Projects
Scope
Project Objectives
Project Deliverables
Project Requirements
Project Schedule
Project Cost
Risks
Issues
Quality
Project Performance
Project Changes
Commitments
Support Activities such as Planning, CM, Requirements Management



Reporting Guides
Submit reports on time
Follow reporting schedules of the group (daily/weekly)
Determine if the task are on-schedule or delayed
If delayed provide the following information:
[cause]		: what is the cause of the delay?
[countermeasure]	: how to cope with the delay and when is it 			  achievable.
Inform PM/PL early for any issues or concerns with the task. (e.g task is delayed) This will give the PM/PL enough time to make necessary countermeasures to solve issues
Follow the groups reporting guidelines, status or percentage reporting guides


Solution?
Define what is a meant by a task completed, e.g.
Design and Coding:
100% = Work product has been reviewed and approved
Testing
100% = All test items are executed and all bugs are fixed and confirmed

Control on deliverables:
0-100 rule:
task completion is 0%, unless
the task is finished = 100% complete
0-50-100 rule:
task completion is 0% initially,
50% when someone is working on it, and
100% when the task is finished


0-25-50-75-100 rule:
task completion is 0% initially,
25% when someone is working on it, and
50% when output is done and is ready for review
75% work product has been reviewed and is currently being updated
100% defects has been confirmed and approved


Guidelines for Project Team Operation
Review and approval of Project Work Products 
Approval of Leaves, Overtime and Undertime 
Transferring/acquiring team members to/from another project or DC
Project Teams performance of the company operation activities






____________________________________________________________________________________________________________________________________________________________________________________________________________________







SOFTWARE DEVELOPMENT LIFE CYCLE (SDLC)

A carefully outlined engineering approach to the development of software.
It facilitates management control of the product development.


Why is SDLC is needed?
Because of the complexity of software products, software development must be carried out in a disciplined manner
To minimize the problems that usually occur during software development
To maximize customer satisfaction

SDLC  Model
Waterfall Model
V-Model
W-Model
Iterative/Incremental
Prototyping



Tailoring NSP Software Process
Phase Merger / Phase Exclusion:  Certain phases will be merged or skipped.
Scope of requirements to develop or work identified by the client
Input documents from client
Schedule of development
Size of the project
Note: When merging test phases, test viewpoints must be properly identified.

BD document is already provided by client, so BD phase is skipped.
Merging of FD & BD or UT & IT
Software Integration & Integration testing will be performed by client.


Task Details:  Expected input/output work product and task details is different from the standard.
Certain task details is different or not needed to be performed (as requested by the client).
Client may already provide certain work products as input.
Client may require different output work products to be delivered.

E.g. SOW is not needed since the project is a maintenance project.
E.g. Source Code Release will not be performed since source codes is not a deliverable.
E.g. PHS for all UT bugs is not needed, project equivalent is online Bug Tracking Tool.



Describe where?

Process List  SWD Process
Usage value is: Tailored from NSP for the following task:
Phase Merger
Usage value is: N/A if certain task is not performed or work products is not a deliverable.  Process waiver is required.
Project Planning 1  Development Life Cycle sheet
List down only the phases that the project will perform.
Identify only the work products that are deliverables or that the project intend to create.


Tailored Review Process (1/2)
Review Types:  The Project define a more detailed or add review types from NSP defined types: Team, Group and User reviews. (E.g. Team review = Buddy, PL, PM reviews)
Review Methods:  Projects can add Review Methods for their project provided that they describe each method in detail and that it is not similar to an existing NSP defined review method.  The added review method must be clearly understood by all project stakeholders.
Review Criteria:  The Project has their own specific review criteria defined in the Review Checklist for the different Review Objects to be reviewed.
Review Objects:  The Project can define levels of review for each review object base from their identified Review Types.
Review Management:  The Project has their own define Review Management where they identify their review schedules, monitoring and control of reviews and data (e.g. bug count, bug types, bug severity, etc). They may choose not use the NSP defined Review Management Sheet.


Describe where?

Process List  Reviews
Review Criteria usage value is: Project
Plan and Monitor Reviews usage value is: Project
Note: Process Waiver is needed
Project Planning 1  Review Plan
Review Types
Review Methods
Review Criteria
Review Objects / Work Products to be reviewed
Review Management


Tailored Testing Process (1/2)
Test Viewpoints:  The Project will identify their UT and IT viewpoints wherein certain mandatory test types will not be performed.  This depends on the Project requirements and Test requirements from the client.
Test and Bug Management:  The Project has their own defined tool in monitoring and controlling the testing activities and managing of bugs.
Test Tools and Execution:  The Project can define their own testing method and test tools to use.
Integration and Integration Testing:  The Project can introduce an integration phase between UT and IT where in setup of build environment and assemble of software product is performed.  And Function Test (FT) and System Test (ST) may also be performed.


Describe where?

Process List  Testing
Monitor Test and Integration: Project
Plan and Monitor Reviews usage value is: Project
Note: Process Waiver is needed
Project Planning 1  
Development Life Cycle
Integration Plan
Test Plan 
Test Approach
Test Viewpoints
Items to be Tested
Test Tools
Test Management Tools
Test Completion Criteria
Bug Tracking and Management
Top-Level WBS




What is Software Engineering?
The application of a systematic, disciplined, quantifiable approach to the development, operation, and maintenance of software; that is, the application of engineering to software. SWEBoK 2004  IEEE Computer Society
Designing, building and maintaining software products...
...in a timely fashion...
...and in a reliable process...
...and cost-effectively


The Process Management Premise
The quality of a (software) system is largely governed by the quality of the process used to develop and maintain it.

The premise implies focus on process as well as product.

It implies process thinking!


Absence of Process Focus

The absence of a focus on the process could very well result in what W. Edwards Deming calls the fire fighting syndrome
One gets a good rating for fighting a fire. The result is visible, can be quantified.
If you do it right the first time, you are invisible. You satisfied the requirements. That is your job.
Mess it up, and correct it later, you become a hero.
- (Deming 1986)


Process Discipline (1/2)

System of rules used to maintain control or order over a group of people. Concise Oxford Dictionary
A disciplined process has rules that result in behavior consistent with them.

Characteristics of Process Discipline (2/2)
Process is documented
Process training exists, is scheduled, and is conducted
Process is followed as normal part of the job
Process is monitored and enforced



NSP Software Processes

Project Management
Project Initiation
Project Planning
Project Monitoring and Control
Kick-off
Project Closure



Software Development
Requirements Analysis
Basic Design
Detailed Design
Coding
Unit Testing
Integration Testing
Release




Quality Assurance and Control
Reviews
Phase Evaluation
Wrap-up
SWQC
Process and Product Quality Audits
Measurement and Analysis


Support Processes
Configuration Management
Project Registration



Kickoff Meeting 
A meeting held at the beginning of the project 
to align peoples' understanding of project objectives, procedures and plans, and 
to begin the team-building process. 


This meeting allows the project managers/leaders to energize the group, set proper expectations and establish guidelines that will help the project finish on schedule.

The following individuals should attend the kick-off meeting.
Project manager
Project leader
Project team members
SQA representative
Client representative


Your Role in Kickoff meetings . . .
Attend the kickoff meeting.
Note down items important to you.
Raise questions on unclear items.
When asked to:
Discuss your roles and responsibilities accurately
Discuss your expectations
Express your commitment to the plan:
Schedules
Task assignments
Roles and responsibilities
Requirements
Check minutes of meetings


Outputs of Kick-off meetings	
Meeting Minutes
Updated Project Plans
Commitments


_________________________________________________________________________________________________________________________________________________________________


Requirements Engineering

Requirements Engineering is a disciplined, process-oriented approach to the
definition, documentation, and maintenance of software requirements throughout 
the software development life cycle. The two major processes are requirements development and requirements management.

Requirements Management (REQM)
    Establishing and maintaining an agreement with the customer on the requirements for the software project.
    The management of all requirements received by or generated by the project, including both technical and nontechnical requirements as well as those requirements levied on the project by the organization.

When Requirements Management is not done well

Requirements are accepted by staff from any source they deem to be authoritative
The project experiences a high level of requirement changes.
There are high levels of rework throughout the project.
There is an inability to prove that the product meets the approved requirements.
Lack of requirements traceability often results in incomplete or incorrect testing of product.

NSPs Requirements Management Process
Purpose:  1. To ensure that project requirements are managed, understood, validated
                      tracked and agreed upon by the stakeholders of the project. 

          2. Modification Requests are implemented and modified work products
                      are baselined.




Requirements Management Planning
The REQM Plan is included in the Project Plan and will ensure that requirements are validated, tracked and agreed upon by the stakeholders of the project.  This will be used as the basis for estimation, planning, execution and monitoring of the project.
The Project Manager or Project Leader is responsible for creating and monitoring the REQM plan.


Requirements Analysis / Development(RA/RD)
The determination of product-specific performance and functional characteristics based on analyses of customer needs, expectations, and constraints; operational concept; projected utilization environments for people, products, and processes; and measures of effectiveness.



Requirements Analysis/Development
When Requirements Development is not done well

Unstated requirements or poorly stated requirements lead to confusion among staff and customers.
Design, implementation, and test work products inconsistently interpret the requirements.
It takes an inordinary long time to get agreement on product design.
There is an increased potential for higher costs to meet customer expectations.



Requirement Analysis Guideline
Provides a guide on the activities to be carried out during the Requirements Analysis activity of the project including verification and validation activities.
Definition of Terms



Requirements Analysis Activities

			Balance Requirements
			with Stakeholders Needs

Requirements -----> 	Develop				------> Baseline RA ------> Requirements 
Elicitation	    Customer & Product Requirements 		documents		Management



Requirements Elicitation
Purpose: The Project Manager/Project Leader ensures that all stakeholder needs, expectations, constraints, and interfaces for all phases of the product lifecycle are identified and has a common understanding between Requirements Provider and Project Team.

Activities
Identify the stakeholders and their corresponding roles and responsibilities.
Solicit and identify the needs and expectations of each stakeholders.
Study, analyze, and translate the input documents.
Discuss and validate correctness of understanding the input documents or requirements.

Output
Requirements Management Plan 
Meeting Minutes
List of stakeholders needs
Discussion, clarification and agreements
Filled up Q&A Monitor
Validated translation of input documents *
Software Prototype * 
DAR Form *


* If necessary 
Eliciting Stakeholders Needs
Basic questions to ask to get the stakeholders needs:
Who are the stakeholders involved in this project?
What are the work products or output per phase?
What are the expectations per stakeholder for each output per phase?
How to satisfy the expectations of the stakeholders (validation method)?

Additional guide questions to elicit stakeholders needs:
What is the purpose of the software product and what will it be used for?
Are there other subcontractors that will provide input to NSP or NSPs output will be given to?
What are the input documents to be provided?
What are the functional and non-functional requirements?
What are the operational scenarios applicable to the system?


Develop Customer & Product Requirements
Purpose:  To establish the Customer Requirements, that answers the customer and other stakeholders needs and expectations.  And to establish the Product Requirements, that defines the product functions and product components that will be the basis for creating a solution or the detailed design on how the product will be implemented.

Activities
Extract necessary information from the input documents.*
Discuss and clarify with Requirements Provider unclear/undefined items.
Agreement on the requirements to develop.
Record discussion and agreements.
Create the SOW and RL based on agreement.
Create the product functions and product components.

Output
Filled up RA Checklist
Minutes of the meeting
Discussions and agreements
Commitments
SOW, Requirements List (RL)
SRS / BD / Investigation Reports
DAR Form


RA Checklist

Checkpoints

Project Background
Skills Requirement
Scope of Work
Project Schedule
Organizational Structure
Development Process
Product Overview System Summary
System Architecture
Software Components or Functional Blocks
System Features: Functional
System Features: Non-Functional
	Performance Requirement
	Usability
	Reliability
	Efficiency
	Maintainability
	Portability
	Safety Requirements
	Security Requirements

External Interfaces
	User Interface*
	Hardware Interface
	Software Interface
	Communication Interface
Operational Scenarios
	User Types and Characteristics*
	Use Case
	Screen Transition Diagram*
	Operation Sequence Diagram
	State Transition Diagram*
System Environment
Hardware and Software Requirements
Technologies and Middleware
Availability of Simulator(s)*
User Manual Creation*
Assumption and Constraints
Limitation(s)*

Statement of Work
SOW Contents

Project Background
Skills Requirement
Scope of Work
	High Level Requirements
	Development Lifecycle
Overall Project Schedule
Organizational Structure
File Management Plan
Required Hardware and Software Resources
Progress Management
Development Standards


Requirements List
RL Contents

Requirements ID
Feature
Requirements Description
Priority
Status
Change Mode
Change Date
Reference Documents


Priority
Essential
Conditional
Optional


Status
Open
Active
Deferred
Cancelled
Completed
Released
Accepted


Change Mode
Initial
Added
Modified
Change Priority


Software Requirement Specification
SRS Contents

Product Overview
External Interface Requirements
	User Interface
	Hardware Interface
	Software Interface
	Communication Interface
Operational Concepts
Target Environment
User Documentation
Assumptions and Constraints
System Features
	Functional Requirements
	Non-Functional Requirements
		Performance
		Usability
		Reliability
		Efficiency
		Maintainability
		Portability
		Safety Requirements
		Security Requirements
		Software Quality Attributes


Balance Requirements with Stakeholder Needs
Purpose: To reconcile conflicting requirements from stakeholders. And to review and balance what the stakeholder needs with what the Project Team can deliver.

Activities
PM/PL should weigh and analyze all the requirements with all stakeholder needs and constraints.
	functionality
	priorities
	reusable components
	maintainability
	risk
	conflicting requirements
	technology
	budget/cost
	schedule/time
	product or project performance

If necessary, consult relevant stakeholder to determine priorities and what changes may be needed.
Identify, address and resolve risks and issues as a result of balancing stakeholder needs.


Output
Minutes of the meeting
	Discussions and agreements
	Commitments
Risk List
Issue Monitoring
DAR Form



Making SMART Requirements
Requirements should follow the SMART criteria:

Specific
	Unambiguous and not confusing
	Not in conflict with other requirements
	Does not pose a specific solution on design (i.e. implementation free)
Measurable
	It can be determined, via testing, that the system meets the requirement
Attainable
	Can be accomplished within cost and schedule
Relevant
	Is inline with customer needs
Timely
	Is inline with current technological trends and industry standards


Example of Bad Requirements
	The system must have good usability (Not Specific)
	The system shall work just like the previous one, but on a new platform (Not Specific)
	Response time should be less than X seconds (Not Measurable)
	Round-the-clock availability (Confirm if Attainable)
	The system must be accessible to mobile devices (Confirm if Relevant)
	The system shall run on Windows 98 (Not Timely)


Requirements Verification and Validation
	Verification is the project teams review of Requirements documents they had created. (Requirements documents: SOW, RL, SRS)
	Validation is the client review of the Requirements documents created by the project team. (Requirements documents: SOW, RL, SRS)
	The following Requirements Elicitation activities are also Validation:
		Prototypes created by the Project Team
		Demonstration to the client by the Project Team
		Q&A between the client and the Project Team


Baseline RA Documents
Purpose:  To establish the agreed requirements to develop.
Activities
Project Manager ensures that Customer and Product Requirements are agreed and approved by both Requirements Provider and Project Team before moving to the next phase.
Project Manager ensures that all risks and issues to balance stakeholder needs are identified and will be monitored until closure.
Project Manager approves the RA documents as discussed and agreed with Requirements Provider. 

Output
Approved Customer Requirements:
	SOW
	Requirements List (RL), 
Approved Product Requirements:
	SRS / BD / Investigation Reports
Minutes of the meeting
	Discussions and agreements
	Commitments
Risk List
Issue Monitoring


Requirements Management
Purpose:  To ensure that all requirements are identified, managed and controlled throughout the development lifecycle.  And all baselined requirements are only changed through Modification Request Process.

Activities
Manage requirements through RL.
Use RTM to ensure traceability of requirements.
Control requirements changes.

Output
Requirements List (RL)
Requirements Traceability Matrix (RTM)
Modification Request Log
Modification Request Form
Risk List & Issue Log
DAR Form


Requirements Traceability
	Forward Trace
	Backward Trace

Benefits of Requirements Traceability
Make obvious to the client that the software is being developed as per the requirements. 
To make sure that all requirements included in the test cases. 
To make sure that developers are not creating features that no one has requested. 
Easy to identify the missing functionalities. 
If there is a change request for a requirement, then we can easily find out which test cases need to update.
The completed system may have Extra functionality    that may have not been specified in the design specification, resulting in wastage of manpower,          time and effort.


Requirements Traceability Matrix

The RTM template will help track the requirements traceability as each requirement is implemented in the different phases of the SDLC. 


Input	 ------>  Requirements ---> Design ----> Implementation ------> Testing
Documents



Modification Request
Modification Request (MR)  are the changes in requirements, or changes that needs to be implemented in the project, that may occur at any time during the project development.  MRs usually come from external and internal project stakeholders.

MR is related to the CM Processs Change Control activity for work products affected by changes to the requirements.

Modification Request Procedure
	Shows the flow on how to perform the 
     		Modification Request.


Modification Request Procedure 1/2
Workflow
	
	Entry Criteria 
		A modification request has been received from the Client (e.g. e-mail, verbal through meetings)
		A requirement modification has been requested by the Development team
		A modification request has been identified by Development team from new or modified input documents by client.



	Exit Criteria 
		Client Acceptance section in the MR template has been filled-up. 
			If the client has accepted the Impact Analysis and MR Assessment information in the MR template:
				The modification plan is integrated in the overall 
     					project plan.
				MR Log is updated. 
			Otherwise, 
				MR Log is updated. 



Modification Request Templates
The MR template is composed of two major sections:
	1.  Modification Request section which contains a detailed  information about the modification request and its impact analysis.
	2.  Modification Assessment section contains the details of the configuration items affected and the activities that needs to be done in order to implement this MR.
The MR Log document is a list of all the MRs of the project.  All MRs must be logged even if it is not approved or accepted by the stakeholders of the project.


______________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________


Software Development Life Cycle


Verification and Validation through Reviews


What is a Review?
Reviews involve a methodical examination of work products by the reviewers to identify defects for removal and to recommend other changes that are needed.
Review is an important and effective verification method implemented via walkthroughs and desk review.
Reviews are applied to work products developed by projects, but can also be applied to documentation and training work products.


Importance of Reviews
Ascertain that the tasks accomplished meets the project requirements.
Determine premature errors to avoid rework or time consuming alterations in succeeding phases.
To consider the risks of proceeding to the next stage of development even though there are unresolved deficiencies.
To learn from mistakes so that the same errors can be avoided next time.
Ensure quality of the overall project condition.


Negative Attitudes Toward Reviews
Not enough time for an extra activity like reviews, too busy in project development.
Some people get offended when defects are found in their work.
Some people think reviews are a waste of time because defects are easily found during testing.
Some people think they do not need reviews because they are very proficient technically and they rarely (if ever) commit mistakes.

REVIEW GUIDELINES
Review Types
Review Objects
Review Materials
Levels of Review
Review Methods
Criteria for Reviews
Bug Types and Severity
Analysis of Review Data
Review Ethics
Tips of Effective Review
Review Tailoring


Definition and Terms

Reviewee - The author of the review object.

Reviewer- A person who is knowledgeable enough to review the review object.

Review Coordinator - The person who plans, monitor and control the review activities of the project.

Review Management Sheets - Sheets used to record the Review Plan and Actual: schedule, total defects, reviewer, reviewee, review record card.

Review Record Card (RRC) - A sheet used to record the defects and comments found during the review.

Work Product -This can include files, documents, products, parts of a product, services, process descriptions, specifications, and invoices. A key distinction between a work product and a product component is that a work product is not necessarily part of the product.




Review Types
Team Review
	Review performed within the project group only.
	This is to verify the work product reviewed meet the specified requirements.

Group Review
	Review performed with other groups / stakeholders not part of the project group
	This is to verify the work product reviewed meet the specified requirements.


User Review
	Review performed with the client or any stakeholder who will use the work product.
	This is to validate the work product reviewed meet the user needs and expectations.

	

Review Objects
	This refers to the material(s) to be reviewed.

	Requirements Document
		SOW, SRS, RL, RTM
	Project Plan
		PP 1&2, Quality Plan, CM Plan, Test Plan
	High Level Design
		Basic Design, Function Design
	Detailed Design
	Test Specification
		UT Specs, IT Specs
	Source Codes
	Project Procedure/Template/Checklist
	Other documents which the group deemed necessary


Levels of Review
	The number of review a review object has to go through by different stakeholders.

To ensure that the stakeholders viewpoints and needs are properly captured or satisfied in the work products created by the project team.


Sample viewpoints of review

Review Object			Who			Review Type		Purpose														Priority
																					
Requirements			Project Team		Team Review		To ensure that the project team has a common understanding on the customer needs and requirements.		Mandatory
 Documents			Client			User Review		To ensure that all customer needs and requirements were listed and documented. 					Mandatory
(SOW, RL, RTM, SRS)		Tester/Test Team	Group Review 		To check the testability of the requirements.									Recommended
										To check that the document is enough for the test team to create a test plan and test specifications.


Review Methods
Walkthrough
The review object will be discussed in a face-to-face meeting.
	The Reviewee will present the review object.
	Using a defined criteria to guide in the review, the Reviewer will inspect the review object and identify the defects found.

Desk Review
The review object will be checked by the Reviewer in his/her desk.
	Reviewee sends the review object to Reviewer.
	Using a defined criteria to guide in the review the Reviewer will inspect the review object and identify the defects found.

Desk Review
The creator of the review object will do a self-review.  This is usually done before a Reviewee will request a walkthrough or desk review to a Reviewer.
	A defined criteria is used to help in the review.



Purpose of Criteria for Reviews
To guide the Reviewer during the review.
To have a consistent review process.
	No matter who the reviewer is, view points or items that will be checked is consistent.
These are the view points to consider during the review (e.g. completeness, correctness, conformance to requirements, traceability and others).




Criteria for Reviews
Review Entry Criteria
	To determine when to begin the review (e.g. review object is created, self check of review object is finished).
Review Criteria
	To determine what are specific items that will be checked in reviewing the review object. These criteria is specified in the Review Checklist for each Review Object.  (see next slide for details)
Re-review Criteria
	To determine if after the confirmation or modification a review object will be reviewed again.
Review Exit Criteria
	To determine if review is completed (e.g. RRC is updated, all review bugs are closed, RTM is updated)



Review Criteria (Review Checklist)

Project Plan		Standards		Completeness and Correctness		Consistency
			Clarity


Requirements		Standards		Correctness				Traceability
			Completeness		Non-Functionality



Architecture		Structure		Standards and Traceability		Interfaces
			Correctness			Logic				Clarity
			

High Level Designs	Data			Correctness and Completeness		Interfaces
			Structure		Standards and Traceability		Robustness

			
Designs			Data			Correctness and Completeness		Robustness
			Structure		Standards and Traceability

			
Source Codes		Structure		Arithmetic Operations			Interface
			Documentation		Loops and Branches			Variables
						Defensive Programming

			
Test Specifications	Standards		Correctness, Completeness and Traceability




Review Criteria Sample
Below are the sample criteria for Requirements Document Review:
Completeness
	To ensure that all requirements have been stated explicitly based on the agreed scope.
Correctness
	To ensure that the interpretation of requirements have consistent and single meaning. 
Traceability
	To ensure the source (origin) of the requirements is known and can be referenced/located throughout the system. 
		


			
Review Bug Types
Purpose
	To have a common understanding and consistent classification of defects found during the review.
	To help the project analyze and identify improvements on their QCD or processes.
Sample Bug Types for Design Review


Lacking functionality		
	A functionality described in input document/s is not included the design.

Unnecessary functionality
	A functionality NOT described in input document/s is included in the design. An unnecessary function and process was added.

Wrong functionality
	The functionality described in the design is not consistent with the input documents. 


Lack of maintainability
	Non-optimal design from the maintainability point of view. Design is not flexible. Tightly coupled design.




Bug Severity

Purpose
	To have a common understanding and consistent classification of the severity of the defects found during the review.
	To help the project analyze and identify improvements on their QCD or processes.

Sample Bug Severity for Design Review

Critical
	 Lacking Functionality
 		Functionality described in input document is not included in the design.
 	Wrong Functionality
 		Functionality is not the same as the input documents.


Minor
	Unnecessary functionality found during review.
 	Maintainability
 		Not optimal design from maintainability point of view.
 		Not too flexible.
 		Tightly coupled design

	
Review Activities (1/5)
	Review activities are performed for specific project work products for review, throughout the software development life cycle of a project.


Review 		------>	Actual -----> Rework ---> Review
Preparation		Review			Confirmation




Review Activities (2/5)


Review 		------>	Actual -----> Rework ---> Review
Preparation		Review			Confirmation


Review Coordinator plans the review, which includes:
	Review Types
	Review Objects
	Levels of Review
	Review Methods
	Review Criteria and Checklist
	Review Materials
	Review schedules



Reviewee prepares the review materials
	Do a self-check on the review object
	Make sure RTM is updated
Reviewee requests for review

Input: Review Plan, Review materials, Review Object, RTM
Output: Initial review comments, review schedule

Prepare the review materials includes checking of the RTM
Show the following documents:
Review Plan Sheet
Review Management Sheet




Review Activities (3/5)
Review 		------>	Actual -----> Rework ---> Review
Preparation		Review			Confirmation


Reviewer performs actual review, depending on the review method selected.
Use the review criteria to guide in the review (e.g. Review Checklist)
Check for traceability of requirements
Record defects and comments in RRC
Decide for re-review or review confirmation
Review Coordinator updates the Review Management Sheets



Input: Review Object, RTM
Output: Review checklist, RRC, Review Management Sheets

Show the following documents:
Review Checklist
RRC
 Review Management Sheet

Demo how to use review management sheet




Review Activities (4/5)
Review 		------>	Actual -----> Rework ---> Review
Preparation		Review			Confirmation

Reviewee updates the review object base on the defects found.
Reviewee inputs the necessary fields in the RRC. (e.g. solution/countermeasure, bug types, etc)
The Reviewee requests for review confirmation


Input: RRC
Output: Updated Review Object, Updated RRC

Add who will perform
Update review object base on the defects found (first item)
Update RRC
   -solution/countermeasure
   -bug types
   -etc


Review Activities (5/5)
Review 		------>	Actual -----> Rework ---> Review
Preparation		Review			Confirmation



Reviewer checks and confirm the RRC in a walkthrough or desk review
Reviewer inputs the Confirmation column of the RRC
Revise RRC and review object if necessary
Reviewee completes the RRC
Make sure all fields are filled up (e.g. Bug Type, Bug Severity, size of review object, Confirmation, etc)
Reviewee informs Review Coordinator review status
Reviewee submits the RRC and review data to the Review Coordinator



Input: Updated Review Object, Updated RRC
Output: Complete RRC, Reviewed Review Object, 
              Review Management Sheet, Review Data




Verification and Validation through Reviews


Verification and Validation through Reviews

Verification
	Verification ensures that selected work products meet their specified requirements. CMMI for Dev. v.1.2
	To review and check that the selected work product is created according to the requirements and will work according to the specification or requirements.
Validation
	Validation demonstrates that a product fulfills its intended use when placed in its intended environment. CMMI for Dev. v.1.2
	This is to review and check if the selected work product will satisfy the customer needs and will work on its intended use and environment. 



Verification 								Validation
Check if you build it right						Check if you build the right thing


Check if it was built according to the requirements			Check if it was built based on the need of the client


Check if it works based on specification or requirements		Check if it does work based on intended use


									Check if it solves or addresses the problem to which the system was created for


Importance of VER and VAL in Project Planning Review


The project team will perform reviews on the project plans to verify if all plans are correct, complete and it does not conflict with each other.
The Client will validate if the plans created by the project team meet their targets (e.g. schedule, quality, etc)




Importance of VER and VAL in Requirements Analysis

The project team will review the Requirements Analysis documents (e.g. RL, SRS) to verify if all requirements provided is enough to develop the product.
The Requirements Provider will then validate if they have a common understanding with the project team and if it satisfy their needs through reviewing the RL and SRS.


Importance of VER and VAL in Design Review

The project team will review the design documents (e.g. Basic Design, Functional Design, Detailed Design) to verify the correctness and completeness of the design.
The Client will perform review on design documents to validate if all features required are included in the design.
Both project team and Client will review the high level designs to check if all requirements has an equivalent design.
In the Test Group/Tester point of view, design are reviewed to validate if design documents are enough to create the test specification.



Importance of VER and VAL in Test Specs Review


The project team will perform review on the Test Specification created to verify that all required features has an equivalent test item.
The Client will perform review to validate if the required features has an equivalent test item and it conforms to the intended environment.



Importance of VER in Coding


The project team will perform reviews in coding to verify that the design is implemented correctly.
This is also to verify that all required features is implemented.




Analysis of Review Data

This is to evaluate the result of the reviews (e.g. # of bugs found, bug types, bug severity, productivity, etc)
Purpose
	To analyze the possible cause of the issues / defects found during review.
	To determine possible countermeasures or action items.
	To avoid issues / defects from happening again.
	To determine if quality targets are met.
	For historical data that can be used in future reviews.
	To find strength and weaknesses of the process.
	To identify and prioritize process improvement that can result to improvement of QCD.



Review Tailoring

The following are the tailoring for the review process:
Selection of review objects.
	This depends on the development life cycle of the project and deliverables per phase identified.
Levels of review per review object.
	The project can define their own levels of review depending on the identified review objects and stakeholders. This will be defined in the Review Plan.
Review Method
	The project can define their own review method that will be more appropriate for project.  This will be defined in the Review Plan.
Review Procedure
	The project can define their own review procedure, given that it is defined and informed to all stakeholders.
Review Criteria
	The project can define their own review criteria or use the clients defined criteria that is more suitable for their project.
	Make sure that all required criteria is identified. (e.g. review checklist for project planning review, requirements review, design review and etc)



Tailored Review Process (2/2)


Describe where?

Process List  Reviews
	Review Criteria usage value is: Project
	Plan and Monitor Reviews usage value is: Project
Note: Process Waiver is needed
Project Planning 1  Review Plan
	Review Types
	Review Methods
	Review Criteria
	Review Objects / Work Products to be reviewed
	Review Management




Review Ethics
	Review the object, not the reviewee.  
	Review sessions should be on track and on schedule.  
	Avoid spending too much time on a particular issue.
	Review sessions are limited to finding defects, not solutions.
	The group should end the activity properly.  Never leave unresolved issues behind.
	Review sessions should be limited to at most 2 hours.  


Reviewers should address issues professionally and objectively.  
See to it that uttered comments do not get personal.  
The reviewee should get the feeling of being helped not criticized.
2. Reviews should start on time unless a major problem is encountered.
3. If time allotted is not enough, schedule another review session.  
This will avoid disrupting earlier scheduled reviews.


Tips for Effective Reviews
	Include the review in the project schedule.
	Define the goals to be accomplished through review.
	Use a review checklist.
	Make use of review records.
	Focus on the review targets.
	Perform a self-check on your own output.
	Discuss the defects found during review and NOT the solution.
	Keep useful records.


Workshop 2: Review Planning

Provided are the following:
	WBS
	Review Plan Template
Create a Review Plan based on the WBS.
Refer to the Reviews Workshop section.





____________________________________________________________________________________________________________________________________________________________________________________________________________

Configuration Management Overview


Common Problems in Configuration Management
Product shipped contained the wrong version of the source code.
	Difficulty in recreating a reported problem
	Reoccurrence of fixed bugs
	Inability to obtain the same version that our customers have
	Lost/misplaced source files
Simultaneous Update
	Modification made in a file was overwritten
Double Maintenance
	Need to update both copies of the same files in two directories for different releases
Share Code / Share Data
	Some are not notified of bug fixes in code shared by several engineers.
= Confusion and lack of control which would result to waste of time and effort.


What is Configuration Management?

Is the discipline of identifying the configuration of a system at distinct points in time for the purpose of systematically controlling changes to the configuration, and maintaining the integrity and traceability of the configuration throughout the system life cycle.

 The key is to have a control system that answers the following questions:
 	What is my current software configuration?
	What is its status?
 	How are changes to my configuration controlled?
	 How do I inform everyone else of my changes?
	 What changes have been made to my software?
	 Do anyone elses changes affect my software?



Configuration Management Principles

Integrity
	The existence and correctness of the configuration items stored in the repository.
Traceability
	The ability to trace or monitor the changes made to the configuration items in the repository.
	The ability to trace or monitor the relationship between the software and all other related software products.




Configuration Management Activities 


To establish and maintain the integrity of work products using:
Configuration Identification
Configuration Control
	Baselines
	Change Control
	Releases
	Backup
Configuration Status Accounting
Configuration Audits



As a member what is your responsibility to help maintain the integrity and traceability of your configuration items?
	You help implement and perform the configuration activities planned by the CM-in-charge.



NSP Standard Directory Strcuture
	Know wher to locate/put the work products.

	[ ]<Product name>
		|.....Baseline Map.xls
		|.....Work Product Resgistry.xls
		|.....[ ] 01 Project Management
		|	|....[ ] 01 Initiation
		|	|....[ ] 02 PPMC
		|	|....[ ] Closing
		|.....[ ] 02 Engineering
		|	|.... [ ] 01 Requirements
		|	|.... [ ] 02 Coding
		|	|.... [ ] 03 Coding
		|	|.... [ ] 04 Testing
		|	|.... [ ] 05 User Documentation	
		|	|.... [ ] 06 Release
		|	|.... [ ] 07 Libraries
		|.....[ ] 03 Support
			|....[ ] 01 QA
			|....[ ] 02 Communication
			|....[ ] 03 References
			|....[ ] 04 Tools


Document Control



Document registration
A unique document identifier.
					       /-----> RRC Series
					      /
			SWD10-05100-PLN008-001 
				/	\
		Project Registration No. \
				          Document Type & Series



Versioning
A unique instance of a configuration item which is distinct in some way from the different instances of the same configuration item.

					XX.YY.ZZ  ----> Draft Version
					/   |
		Final Copy / Major Revision |
					    |
					Minor Revision


Revision History
Records the changes made from one version to another.




Samples of Revision History

								Bad Practice							Good Practices

Updating design document dure to review comments		-Updated section 5						Updated based on review #01;
								-Retrieval of neType is not indicated in page 8.			- Corrected Recovery Time and Hold-off Time in 
																Section 5 Scenario Value Pattern
																-Added retrieval of neType in Section 7 interface


Updating design document due to requirements change		Modified Window Image, Window Specifications, Event and  	Removed function related to LO X-CON in sections: Windows Image, Window Specifications, Event and Interface based on MR#012
								Interface
								_______________________________________________________________________________________________________________________________________________________________________________________________
								svn log sample:							svn log sample:
								Updated file Based on MR					Updated file Based on MR#012



Modifying source Code due to bug fix				Modification in source code is not accounted in revision 	2010/12/15 by M. Bean - Modified to fix bug #01:
								history								Removed function related to LO X-CON

								___________________________________________________________________________________________________________________________________
								svn log sample:							svn log sample:
								Modified file due to bug fix					Modified file for bug fix #01
																Removed function related to LO X-CON

Removing file from repository					svn log sample:							svn log sample:		
								Removed File							Removed testdata10.zip
																Reason: Unnecessary data due to MR#143









						
Revision History Tips						
Purpose of revision history
Traceability of changes
	To know what was changed from the previous version



Tips in writing revision history
	Be descriptive
	Be brief
	Be precise / specific




Naming Convention							


									File Extension
									/
				SWD10-05100-PLN008-001_Project Plan 1.xls
						|		   |
			Document Registration No.		Document Name


Purpose of Naming Convention
To uniquely identify each configuration item
To structure and organize the configuration items
To provide consistent naming of configuration items
To make it easy to navigate through the configuration items
To provide a common language for identifying configuration items



Repository Check in/Check out

The activity of putting/retrieving work products into/from the repository using a version control application.
Purpose:
To be able to follow the standard procedure in accessing the repository.
To have a consistent access logging guideline.
To be able to control the levels of access to the repository.



Tips:
Make sure that the files will be placed in the correct directory of the repository.
When checking-in source codes, make sure that the checked-in code will not contain or introduce errors when the whole system is compiled/built.
Be sure to check-in all work products before weekends or long vacations.  If possible, check-in work products at the end of the day.  This will keep the work product updated even if the responsible person will be absent on the next day.


Repository Access (1/2)
Features of a version control system
Trunk
	Used for the main directory for the development.
Branch
	Used to isolate changes onto a separate line of development.
Tag
	Used to mark particular revisions (e.g. a release version), so you can, at any time, recreate a certain build or environment. 
	Used to create a static snapshot of the project at a particular stage. 



Repository Access (2/2)
Demonstration of Tortoise svn
	Check-in / Check-out
	svn lock
	Commit
	Revision log
	Delete, Move, Rename


Tips:
Before updating a document make sure to get the latest version. (svn update)
To avoid document conflict, lock the document that will be updated. (get lock)
Do not delete/move/rename files in your local copy, instead use the RepoBrowser




Baselines
A set of specifications or work products that has been formally reviewed and agreed on, which thereafter serves as the basis for further development, and which can be changed only through change control procedures. CMMI for Dev. v.1.2 

Configuration Item Baseline
An instance of a configuration item that has been formally reviewed and agreed upon, that thereafter serves as the basis for further development, and that can be changed only through formal change control procedures.
Configuration Milestone Baseline
May consist of one or multiple configuration item baselines that will serve as an approved snapshot of the system at appropriate points in the project lifecycle. (e.g Release)



Importance of Baselines

A baselined Requirements List indicates what features of the product will be developed by the group.
A baselined Design Document indicates that it supports the required features (in RL) and will be the basis for the implementation of the product.
A baselined Source Code will be the basis for the testing activities to check if all required features are implemented and supported.


Tip:
When creating a work product make sure that the referenced document used is the latest baseline.


Change Control
To manage the changes of the baselined configuration items.


Without Change Control
An engineer could make an important change to a configuration item or its interfaces without a lot of extra work and red tape.
	But no record would be kept for:
		What the change was and why the change was requested
		Who wanted the change made
		Who approved the change
		Who made the change
		Who verified the change
		
Is this what we want???


Without Change Control
And it would be hard to find out
	Why doesnt my software link this morning? It linked last night!?
	Why does this regression test fail now? It worked yesterday!
	Why does the product behave this way now? It didnt before!
	Why are we running out of memory now? We did not have that problem yesterday?



Importance of Change Control

To manage configuration items that are affected by the changes (requirements, design, reviews, etc..)
To assess impact of changes to the baselines.
To maintain traceability of the configuration items.
To ensure integrity of configuration items.



Change Control Process
	_________________________________________________
	|	Issue Change Request		   	|	<-----------	Triggers
	|		|				|		Modification Request (Client/Developer)
	|						|			Changes in requirements
	|	Analyze, Propose, Review, and Approve	|			Changes in design
	|	MR Procedure, Bug Report, RRC		|			Changes in behavior
	|		|				|		Bug fix
	|	Implement Modification			|		Reviews
	|		|				|		
	|		|				|		 _______|\
	|		|				|		|	| \
	|	Confirm Modification			|		|_______| /	Monitored, Managed and Controlled by CM-In-charge
	|		|				|			|/
	|	Release Changes				|
	|_______________________________________________|




Other CM Activities
Planning
Release
Configuration Audits
Backup
Configuration Status Accounting



Related Documents

Configuration Management Plan
Work Product Registry
Release Procedure
Document Registration Code, Version Number and File Naming Guideline
Directory Structure Guideline
CM Audit Guideline
CM Audit Checklist
Release Notes and Guidelines
Release Checklist
CM Plan Review Checklist

___________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________



Software Development Life Cycle
Design


Basic/Function Design Phase

Entry Criteria: Requirements Analysis output documents such as Requirements List and Software Requirement Specification are already baselined.


Activities
	
	Identify, investigate and evaluate ----> Create Basic/Function Design Document ----> Review and Modify
	possible solutions									|
												|
	Create Integration	------> Review and Modify	--------------------------------|-----------> Approve


Description: It presents a solution to the problem. It describes how the system works to meet the requirement specifications. There may be many solutions to the problem and the basic design focuses on the best solution decided. Whatever the solution is, the two basic needs are: it should work and it should do the required job well.


Activities:

Check client requirements for any specified technology or framework

Identify possible technologies and framework to use that can help address the requirements

Technologies and framework include the following but not limited to: OS, Programming Language, Software Framework, Communication Protocols, Middleware, Design patterns, Methodology, Techniques, Peripherals / Hardware Components

Create prototypes, if necessary, to test solutions being considered



Basic / Function Design Phase

Activities: [continued: Identify, investigate and evaluate possible solutions]

Conduct design meetings to come up with possible software architectures
 
Perform make, buy or reuse analysis
Identify components to be created
Evaluate if the components will be created, reused from previous projects or buy it off the shelf.

Set criteria to use to evaluate and select solutions

Evaluate each proposed solution based on criteria

Select best solution

Document results of evaluation and selection

Outputs:
Prototypes
Minutes of meetings
Study documents or results of investigations
Proposed solutions
Design Evaluation and Selection document


Activity:
Create the basic design based on the selected solution.


Activities:
Review the Basic Design and Function Design documents
Modify and update the BD and FD documents based on results of review
Confirm changes made to BD and FD documents

Refer to: NSP08-00000-GDL019_Review Guideline.doc



Activity:
Create Integration Test Specification document based on requirements, basic design and function design

Refer to: NSP08-00000-GDL018_Testing Guideline.doc



Activities:
Review the Integration Test Specifications document
Modify and update the ITS based on the results of review
Confirm changes made to ITS documents

Refer to: NSP08-00000-GDL019_Review Guideline.doc


Activity:
Approve the Basic Design, Function Design, and Integration Test Specification. 


Outputs:
Baselined BDD, FDD, ITS
RRCs
Review Checklists
Basic/Function Design Phase Evaluation Report



Design Evaluation and Selection Document Guide
This document records the alternative solutions considered to address the requirements as well as the evaluation performed and the decisions and rationale behind the solution selected. Its contents are the ff:

Document Sections		Description

Problem Domain			Describe briefly the problem or condition to be addressed. It could be to evaluate technologies to be used, third party libraries or system architecture.

Solution Approaches		Describes the alternative solutions identified and being considered.

Evalutation 			Presents the criteria and the resilt of the evaluation of each solution.

Conclusion			Present the solution selected and the rationale of the decision.




Sample: Design Evaluation and Selection Document

SWD09-06400-TLS002_INMS-NML Rel4.0 Design Evaluation for Manual.doc 
      this is a sample for the use of DES for Make, Buy Analysis.
SWD09-05100-DED111-01 ChassisViewMgr.xls 
      this is a sample for the use of DES for a solution to a  design/ implementation problem.


Note: Please refer to the above sample DES documents for reference on how it is used by the INMS project.



Basic Design Document Guide
	The Basic Design Document should contain all the non optional sections as described below.

Document Sections 			Description
System overview				Describes th system to be developed. Each of the major components of the system is listed with a description of its major functionalities.

System Environment			Describe the different environment that will be used for this system software. It is usually divided into 2 sections as follows:
						Target Environment
						Development Environment

System Architecture			This is the diagram of the system architecture of the system to be developed which includes:
						Each component of the system.
						The Interface/Communication/ access/relationship between the different components of the system.

Software Components/ Functional Block	This display the diagram of the Software Compomemts of the System. Functional block can also be illustrated in this section, depending on the software design.

User Interface[Optional]
Screen Transition Diagram[Optional]
Operations Sequence Diagram[Optional]
Limitation List


Interface Specification Document Guide

The Interface Specification Document should contain all the non optional sections as described below.  
     
Document Sections			Description
System Interfaces			This describes the external and internal system interfaces of the system.
						Inteface to other machines or computers
						Interface to other systems or networks

Interface Definition Language (IDL) [Optional]
Inter Process Communication (IPC) [Optional]
System Files [Optional]
External Data Files[Optional]
Message List[Optional]
Error Message List[Optional]
Log Files [Optional]



Function Design Document Guide 1/4

The Function Design Document should contain all the non optional sections as described below.  



Document sections			Description

Module Overview				Module Description - A brief description of the major function of processing of the module
					Module diagram - a diagram that show this module's, sub-module interface/communication/ file access/ network connection etc.


External Interfaces			External Functions - the content of the External Functions are usually written in table format containing the Function identifier, function summary, return value and description
					Interfaces - contains the declaration argument name/ type/detail, return value name/ type/ detail
					class - contains the interfaces classes provided for each module.



Function Design Document Guide 2/4



Document sections			Description

Data Composition [Optional]

User Interface Image			An illustration or a screenshot of the user interface for a particular module or operation.
					For GUI:
						a. A screenshot or illustration of the window to be displayed.
						b. Contains the window title and layout of the GUI components in the window
					For Console-based:
						a. A screenshot of the console may be shown.
						b. A text-based illustration of the user interface

User Interface Specification 1/2	Each user interface must have an equivalent specification
					Usually this is presented in tabular form. The following are the list of user interface specifications necessary to be provided.
					For Console-based:
						List of valid command line inputs
						Valid input parameters for each command
						Valid output displayed for each command operation
						Description of the operation of the command



Function Design Document Guide 3/4

Document sections			Description

User interface Specifications 2/2	For GUI (window-based):
						Window title
						Maximize and Minimize capabilities
						Tab order of GUI components
						Type of GUI components (e.g. Button, List, etc)
						Valid input values for GUI components that prompts for user input (e.g. Text Field, text area)
						Valid output values for GUI components that shows and prompt for users for selection (e.g. List, Combobox, Spinners)
						Label for GUI components
						Operation of GUI components (e.g. action when button is clicked or item in combobox is selected)
						Default states of GUI components (e.g. enabled, disabled, selected)
						State transitions of GUI components (e.g. enabled to disabled when radio button is selected)
			
					For GUI (menu-based)
						List of menus and submenus
						Description of each menu
						Labels for each menu
						Operation of each menu (e.g. when selected display login window)
						Menu Transitions
						Component Type of menu (e.g. plain menu item, checkbox menuitem)






Function Design Document Guide 4/4

Document Sections					Description
						
Error, Warnings And Information Messages		List of all the error, warnings and information meddages of the module. Usual contents of the messages are the following:
								Message Code
								Message Displayed
								Solution for Warning or error Messages

Logs [Optional]




Design Activities

Detailed Design 
Phase

Detailed Design Phase
Entry Criteria: Basic Design outputs such as Basic / Function Design documents are already baselined.

____________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Every Project has to balance scope, cost, time, and quality to achieve project success
		Time and cost can be checked against the project schedule and budget


What is quality?
Quality is "the degree to which a set of inherent characteristics fulfills requirements" - (ISO9000:200)
Other experts defien quality based on:

	Conformance to requirements: The project processes and product meet written specifications
	Fitness for use: A product can be used as it was inteded


Quality vs Grade

Quality is defined as the degree to which characteristics meet requirements

Grade is a category  assigned to product that have similar functional uses but different technical characteristics.
	grade covers the number of features present in a product or servi


Precision vs Accuracy

Precision - Refers to how close measurements of the same item are to each other.
Accuracy - refers to how close a measurements is to the true or accepted value


Precision is independent of Accuracy 
That means it is possible to be very precise but not very accurate, and it is also possible to be accurate without being precise.



Example: Decision in relatin to Accuracy, Precision,Quality, Grade

Important Metrics in NSP
	
	QCD - Quality Cost Delivery
	CS - Customer Satisfaction

In NSP, how do we measure Quality?
	We Measure Quality in terms of bugs detected
		At each phase (During reviews and testing)
		In upstream and downstream phases
		In post-release


Cost - the total amount spent for goods or services including money, time, and labor.
In NSP, how do we measure COST?
Direct Manhours

Hours spent on project-related activities. 
Also includes overtime.

Ex. CD Creation Manhours
	Manhours spent in creating the source code
	Note: Manhours means number of hours multiplied by the number of engineer joining or involved in the activity


Rework Manhours
	Hour spent correcting the work products of a work product type

Ex. Bug Fixing
	Updating design documents after review




Productivity
	Measures the efficiency by which we produce an application expressed in terms of size specifically LOC/manhr

Productivity = Total LOC / Total Direct Manhours


Turn Around Time
Hours spent form receiving of bug reports to the repoting of initial response


What is delivery?
Delivery - the voluntary transfer of something (software) from one party to another (customer)
	Example
		Release software products to NCOS


What is Customer Satisfaction?
	Customer Satisfaction - a measure of how products amd sevices supplied by a company meet or surpass customer expectation.
		Example
			Receives commendation email from customer
			High score in the customer satisfaction survey




Quality  Cost - Delivery (QCD) Relationship
Cost
Quality
Delivery

These three are related. A change in one can affect the others.

What is Quality Control (QC)?
A process employed to ensure a certain level of quality in a product or service

Actions necessary to provide control and verification of certain characteristics of a product or service



QC Goal
To ensure that products, services, or processes provided meet specific requirements before they are released to customer
Examples of QC activities in NSP
Review of design documents and source codes
Testing ( UT, IT)


What is Quality Assurance (QA)?
Means of monitoring the software engineering processes (NSP standard processes) and methods used to ensure quality. 

The methods by which this is accomplished are many and varied, and may include ensuring conformance to one or more standards, such as ISO 9000 or a model such as CMMI. 




Task:  Conduct PPQA Evaluation

What is Process and Product Quality Assurance (PPQA)?

A process area that provides specific practices for objectively evaluating performed processes, work products and services against the applicable process descriptions, standards, and procedures.


What is PPQA Evaluation?
Checking of actual work products if they were created following the standard process ( NSP and project procedures, guideline, templates).

Checking of actual process performed if they were according to standard process ( NSP and project procedures, guideline, templates).



When is evaluation done?

   Evaluations are done during the entire project development cycle from the time the project is registered to SQA until the project closes.



How does QA perform evaluation?

Evaluate project if they followed NSP standard processes

Send issues for noncompliance/unpracticed process

Monitor and evaluate countermeasure of issues
Report results to Top Management



What is your role during evaluation?


Understand the standard processes.  
	Ex. Review process
           Source Coding standards

2.  See to it that you are following the NSP standard processes when performing development activities. 
     
    Ex. Perform review according to standard procedure.




Task: Collect and analyze data

Why we collect and analyze data?

  - To measure how the project is in relation to the NSP goals and the project plans
  - To create countermeasures to resolve issues and prevent further problems


When to  collect and analyze data?

Every end of each activity
     Every end of creation, review, rework of work product.
End of Phase: 
	Before a development phase ends to serve as input during projects (Phase Evaluation)
Monthly: 
	Consolidate all collected phase data for reports to Top Management
Fiscal Year: 
	Consolidate all data of closed projects as historical data. These serves as reference for estimates and target setting.



What is your role during data collection?

Correct man hours is inputted in DTS for every development task.
Correct bug counts during review
Understand measures to ensure correctness and soundness of data



Task: Support SWQC activities of projects

SoftWare Quality Control

NSPs problem solving process.
It is based from PDCA cycle (Plan-Do Check-Act)
SWQC is based on the KAIZEN method.
continuous incremental improvement activity



How is SWQC done in NSP?
1. Identify QCD problems
2. Prioritize problems
3. Determine root cause
4. Set measurable targets
5. Make action plan

6. Implement and monitor action plans
7. Evaluate results

8. Standardize process
9. Make SWQC Report




Quality Control and Quality Assurance Concepts
What is Quality Management is all about 
	Identifying and following quality requirements,
	Auditing the results of quality control measurements and 
	Using quality measurements to control quality
	Recommending project changes if necessary

Quality Management has 2 goals:
	1. Ensuring a quality end-product.	
	2. Ensuring that all of the process involved during the project lifecycle are carried out efficiently.


Why Quality Management?
	Project or products with unnecessary features can be too expensice to meet the business need

	Prevention is much cheaper than inspection, build quality in early to minimize cost/maximize quality
		Quality should be planned, designed, and built into the project's deliverables.
		It should not be inspection driven.



Project Quality Management
1. Plan Quality
	This involves identifying the quality requirements for both the project and products and documenting how the project can show it is meeting the quality requirements.
	
	It provides guidance and direction on how quality will be managed and validated throughout the project.
	
	Outputs:
		Quality Management Plan,
		Quality Metric, 
		Quality Checklists
		Process Improvement Plan.

	Tools and Techniques
		Benchmarking
		Cost-benefit analysis (CBA)
		Cost of Quality (CoQ)
		Statistical Sampling
		Meetings


2. Perform Quality Assurance
	Applying the planned, systematic quality activities to ensure that the project employs all processes needed to meet requirements.
		Process-centric
		Proactive
		Focused on preventive action
	It facilitates the continuous quality improvement

	Tools and Techniques
		Quality Audits
		Problem Solving
		Root cause analysis
		Quality improvement methods




3. Perform Quality Control
	Monitoring and recording results of executing quality activities to assess performance and to determine whether they comply with relevant quality standards and identifying ways to eliminate causes of unsatistfactory performance.
		Product- Centric
		Reactive
		Focused on finding/ Correcting defects
	It facilitates the improvement of quality processes
	
	Tools and Techniques
		7 Basic Quality Tools
		Root cause analysis
		Inspection/ Reviews
		Testing/ Product evaluations 
		Meetings

__________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Introduction to CMMI


The Stability Myth
"Our defined, documented, trained, and used process is stable, and will remain effective without changes.


This is an "illusion".
A "stable" process is not necessarily "effective".
A process left behind by changes in the business will not be not effective. 
The process should reflect the changes in business, technologies, and methods.



Improving the Process means
 making the process EFFECTIVE.

Making the process effective is also a process

 the process of achieving PROCESS MATURITY.


Implementing SPI	<________________
Establish the Process			|-------------Monitoring by Support Group
	Process Definition		|		Progress
	Process Approval		|		Risk
					|		Issues
Institutionalize the process		|		Status
	Publication			|		Stakeholders
	Training			|
	Deployment			|			|
					|			|
Feeback					|		Report Status to Top Management
	Lessons Learned			|
	Best Practice			|
	Issues				|
					|
Process Improvement   -------------------






Critical Success Factors of SPI (1/2)

Alignment with business strategy and goals

Consensus and buy-in from all stakeholders

Senior management and middle management support

Dedicated resource to manage the implementation and coordination process improvement activities



Critical Success Factors of SPI (2/2)

Sensitivity to the organizational context

Management and Prioritization of change

Creation of support infrastructure

Monitoring the results of SPI

Learning from feedback results



What is a Process Model?


A process model is a structured collection of practices that describes the characteristics of effective processes.

Practices included are those proven by experience to be effective.



How is a Process Model Used?

A process model is used

To help set process improvement objectives and priorities.
To help ensure stable, capable and mature processes.
As a guide for improving project and organizational processes.
With an appraisal method to diagnose the state of an organizations current practices.



Why is a Process Model Important?
A process model provides

A place to start improving.
The benefit of a communitys prior experiences.
A common language and a shared vision.
A framework for prioritizing actions.
A way to define what improvement means for an organization.




Misunderstanding the Models


A model is NOT a process.
The model shows what to do, NOT how to do it nor who does it.

A model is NOT absolute. 
The model must be interpreted in the context of the organization.
The application of the model must be tailor-fitted to the specific needs of the organization.




Losing Sight of the Objective

The Rating Game
Real process improvement produces significant long-term benefits for the organization and for its members.

However, many organizations are being enticed to settle for an expensive piece of paper typically referred to as certificate because
 it seems painless
 it is quick (and dirty)

But we should remember the sayings
 No pain, no gain!
 easy come, easy go if it was there at all.



CMMI for Process Improvement

Capability Maturity Model Integration (CMMI)
Use CMMI in process improvement activities as a

Collection of best practices.
Framework for organizing and prioritizing activities.
Support for the coordination of multi-disciplined activities that might be required to successfully build a product.
Means to emphasize the alignment of the process improvement objectives with organizational business objectives.
   

 CMMI incorporates lessons learned from use of the SW-CMM, EIA-731, and other standards and models.





What is CMMI

What It Is

A Measurement and Rating System of Process Capability
A Set of Best Practices for Software & Systems Engineering
An Industry Standard
An Operational Foundation for Success
A Guideline for Continuous Improvement
A Risk Indicator


It Specifies What is Necessary to be Performed



What It Is NOT

A Certification
Methodology 
A Silver Bullet
A Guarantee of Success
Easy to Implement
Easy to Achieve Levels
Only for the Federal Government
Only used in the USA
A Risk Mitigator

It Does Not Specify How to Perform the Activities


CMMI Level Framework (Staged)
Level			Focus				Process Areas
5 Optimizing		Continuous Process		Organizing Performance Management
			improvement			Causual Analysis and Resolution

4 Quantitatively	Quantitative			Organizational Process Performance
   Managed		Management			Quantitative Project Management

3 Defined		Process				Requirements Development
			Standardization			Technical Solution
							Product Integration
							Verification
							Validation
							Organizational Process Focus
							Organizational Process Definition
							Organizational Training
							Integrated Project Management
							Risk Management
							Decision Analysis And Resolution

2 Managed		Basic Project			Requirements Management
			Management			Project Planning
							Project Monitoring and Control
							Supplier Agreement Management
							Measurement and Analysis
							Process and Product Quality Assurance
							Configuration Management

1 Initial			




CMMI Level Framework (Continuous)
Level			Engineering		Process Management			Project Management			Support
3 Defined		Requirements		Organizational				Project Planning			Measurement and Analysis 
			Management		Process
						Focus
			
			Requirements		 Organizational Process			Project Monitoring			Process and Product Quality Assurance
			Development		Definition				and Control


2 Managed		Technical		Organizational Training			Supplier Agreement Management		Configuration Management
			Solution

			Product			Oragnizational				Integrated Project Management		Decision Analysis and Resolution
			Integration		Process Performance

1 Performed		Verification							Risk Management				


0 Incomplete		Validation		Organizationl Performance 		Quantitative Project 			Causual Analysis and Resolution
						Management				Management




Technical Solution (TS)  Level 3
Purpose
	Design, develop and implement solutions to requirements. Solutions, designs and implementations encompass products, product components and product related lifecycle processes either singly or in combinations as appropriate.

When Technical Solution is not well done
An ineffective solution is chosen.
Products may not meet technical performance requirements or user needs.
Increased testing and rework is required to resolve design issues.
The product may not be able to accommodate technology upgrades and future growth if the technical solution is not well conceived.




Technical Solution (TS)  Level 3

Specific Goal and Practice Summary

SG 1 Select Product Component Solutions
	SP 1.1	Develop Alternative Solutions and Selection Criteria
	SP 1.2	Select Product Component Solutions

SG 2 Develop the Design
	SP 2.1	Design the Product or Product Component
	SP 2.2	Establish a Technical Data Package
	SP 2.3	Design Interfaces Using Criteria
	SP 2.4	Perform Make, Buy or Reuse Analysis

SG 3 Implement the Product Design
	SP 3.1	Implement the Design
	SP 3.2	Develop Product Support Documentation




Technical Solution (TS)  Level 3
Sample Mapping against NSP Software Development Process


Technical Solution (CMMI PA)						NSP Software Development Process
SG 2 Develop the	SP 2.1 						Procedures: Design Guidelines (BD,FD, DD)
Design			Design the product or product Component		Tools: Office, Astah (UML), BD/FD/DD retemplate
									Output:	
										BD Documents
										FD Documents
										DD Documents

			SP 2.3
			Design Interfaces using Criteria		Procedures: Design Guideline
									Tools: Interface Spec template
									Output:
										Interface Spec Document


SG 3 Implement 		SG 3.1						Coding Guideline/ Convention
the Product Design	Implement the design				Check Style, Find Bugs
									Output:
										Source Code

			SG 3.2
			Develop Product Support Documentation		Procedure: User Documentation Guideline
									Tool: Office, User Doc Template
									Output:
										User Manual
										Installation Manual
										Troubleshooting Guide
									Format: Online Help, Txt File, Word Document


Cost and Benefits of CMMI
Costs May Vary

	The cost of CMMI adoption is highly variable depending on many factors, including organizational

Goals
Size
Culture
Structure
Processes


	Regardless of the investment, organizations generally experience a respectable return on their investment.



Performance Measures - CMMI
The performance results in the following table are from 30 different organizations that achieved percentage change in one or more of the six categories of performance measures below.

Performance Category			Median Improvement
Cost					34%
Schedule				50%
Productivity				61%
Quality					48%
Customer Satisfaction			14%
Return of Investment			4:1


CMMI Can Benefit You

CMMI Provides

Guidance for efficient, effective improvement across multiple process disciplines in an organization.

Improvements to best practices incorporated from the earlier models.

A common, integrated vision of improvement for all elements of an organization.




SPI Infrastructure

STAC 
(Software Technologies Administration Center)


SEPG										Design Centers
-create/maintain process Asset						Provides Improvement Information
-Process Improvement							Uses and Tailor Process Assets

SQA
-Monitor Process Implementation				<------
-QCD collection and Analysis

ITNA
-Provides HW & SW resources				------>
-Maintain Network Infra

PMO
-PMO Project Review
-Project Status Monitoring

TTDG
-Technical Training
-Training Needs
-Plan and deliver training
|			|
|			|_____________> Process Asset Library
HR					NSP Process Assets
-Behavioral Trainings
-Training needs
-Coordination with TTDG





______________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________


Software Testing Level 1 Course Outline
Software Testing Overview
	Software QA vs. Testing
	Testing and Quality
	Testing Objectives
	Causes of Software Defects
	Principles of Software Testing
	Testing Phases
	Test Types vs. Testing Phases
	Testing Techniques

Testing Activities
	Integration and Testing Activities WBS
	Developer and Tester Meetings  
	Test Specs creation
	Test Environment preparation
	Test Execution
	Bug Management
	Bug Reporting
	Debugging Techniques



Software QA vs. Testing

Software QA is based on prevention
	Quality Assurance is applying the planned, systematic quality activities to ensure that the project employs all processes needed to meet requirements
	Make sure that standards (processes, procedures, guidelines) are followed
	Ensure that problems are checked and dealt with

Software Testing is based on detection
	The process of executing a program with the intent of finding errors 
	Check the software if it does what it is supposed to do and what its not supposed to
	Software testing is a critical process to assure that the software functions correctly




Testing and Quality

Testing makes it possible to measure the quality of software in terms of defects found, for both functional and non-functional software requirements and characteristics (e.g. reliability, usability, efficiency) 

Testing can give confidence in the quality of the software if it finds few or no defects.

When testing does find defects, the quality of the software system increases when those defects are fixed.

Lessons should be learned from previous projects. 
      By understanding the root causes of defects found in other projects, processes can be improved, which in turn should prevent those defects from reoccurring and, as a consequence, improve the quality of future systems. 
     
      This is an aspect of quality assurance.



Testing Objectives

Finding Defects

Gaining confidence about the level of quality and providing information

Preventing defects



Causes of software defects

	Error or  problem in Requirements
	Programming Errors
	Wrong Designs

Defects occur because human beings are fallible and because there is time pressure, complex code, complexity of infrastructure, changed technologies, and/or many system interactions.



Principles of Software Testing (1/2)

General Testing Principles
	- provide a standard framework to testers for conducting tests and discovering defects

     Principle 1: Testing shows presence of defects 
            - absence of defects does not mean that the software is defect free		 
     Principle 2: Exhaustive testing is impossible
            - when the application uses complex logic and requires a lot of user input

     Principle 3: Confusing an absence of errors with product fit is a fallacy
            - the absence of errors in testing does not mean that the software is suitable
              for customer



Principles of Software Testing (2/2)


Applied Software Testing Principles
    - provide a standardized format for creating test plans, and acts as a guide to effective testing

    Principle 1: Early testing
		       - testing should begin as early as possible in SDLC

    Principle 2: Defect clustering 
                       - based on Pareto principle which states that about 80% of 
                         defects will be found in approximately 20% of the modules

    Principle 3: Pesticide Paradox
                     - using the same set of tests over and over again, the tests will 
                       cease to uncover bugs

    Principle 4: Testing is context-dependent
                    - need to vary testing efforts depending on the circumstances




Testing Phases  Unit Testing 1/2
	A phase in software testing in which software verification is performed by programmers to test if individual units of source code are fit for use.

 	A unit is the smallest testable part of an application. It may be an individual procedure or function. 

	Test is performed if it meets the detailed design specification 

	Source code is evaluated if it is ready for integration and integration testing




Testing Phases  Unit Testing 2/2

	Stubs, Test drivers and simulators are usually created to perform the test.

	Test cases are derived from work products such as specification of the component, the software design (detailed design) or the data model.

	One approach to component testing is to prepare and automate test cases before coding. This is called test-first approach or test-driven development.

	Can use testing tools in this phase such as JUnit, Code Joker, Cobertura, C++Test 



Testing Phases  Integration Testing 1/2

			Integration Activities + Testing Activities


 	A phase in software testing in which individual software modules / components are built and combined to produce the software product and resulting software product is tested.

	Testing is performed on the software product to check for correctness of the interfaces between internal and external components

	To test the software product if it meets the basic design and requirements




Testing Phases  Integration Testing 2/2


			Integration Activities + Testing Activities

	To validate the software product if it meets the needs of the client

	Testing of specific non-functional requirements (e.g. performance)

	Simulators or test drivers may be necessary to test connectivity between external components of the system.

Ideally, testers should understand the architecture and influence integration planning. If integration tests are planned before components or systems are built, they can be built in the order required for most efficient testing.
				- from Certified Tester Foundation Level Syllabus by ISTQB




Testing Phases - System Testing

	Is concerned with the behaviour of a whole system/product as defined by the scope of a development project

	The test environment should correspond to the final target environment or production environment

	System Testing should investigate both functional and non-functional requirements of the system.

	An independent test team often carries out system testing



Testing Phases - Acceptance Testing
	Testing to verify and validate a software product if it meets customer specified requirements.

	A customer usually does this type of testing on a product that is developed externally.

	Software product is usually deployed to the field and tested.

	Acceptance testing may assess the systems readiness for deployment and use, although it is not necessarily the final level of testing.


Test Types vs Testing Phase
The table shows the relationship between Test Types and Testing Phase:

 		   \
 Type/Method of     \Phase		Unit Test Phase			Integration Test Phase		Priority
  testing	     \


Black Box Testing				/				/			Optional for UT
													Recommended for IT
White Box Testing				/							Recommended
Sanity Testing									/			Recommended
Interface Testing								/			Mandatory
Functional Testing								/			Mandatory
Regression Testing				/				/			Recommended
Load Test									/			Recommended
Stress Test									/			Recommended
Performance Testing								/			Recommended
Usability Testing								/			Optional
Install/uninstall Testing							/			Mandatory
Recovery Testing								/			Recommended
Security Testing								/			Optional
Compatibility Testing								/			Optional
System Testing									/			Recommended
Known Bugs Test									/			Recommended
Acceptance Testing			Usually Acceptance Testing is performed after IT		Mandatory
													Note: if part of project phase



Testing Techniques (Black Box, White Box)
Balanced among Viewpoints


				     User View
					|  /
					| /
		    Specification  _____|/_____ Design View
			   View	       /|
			    	      /	|
			             /	|
				    /   Fault View
				   /
          Black Box Testing	  /
				 /  White Box Testing
	
		
		Viewpoints: 
			User View
      				 - to think about users behaviour
			Specification View
     				  - to analyze specification
			Fault View
    				   - to think what kind of bugs you  
          					 want to detect
			Design View
      				 - to think about design



Testing Techniques  Black-Box Testing    (1/6)
	To check if the external behavior of a program is met   with the specification 
	No concern on the internal structure of the program 
	Test data are created based on the specifications
	Tester checks the input and output of the software
	Commonly used techniques of Black-Box Testing are:
		Equivalence Partitioning 
		Boundary-Value Analysis 
		Decision table testing
		State transition technique
		Use case testing



Black-Box Testing  (2/6)Testing Techniques

Equivalence Partitioning 

    - Divides the input domain of program into classes of data from which test cases can be derived 
     - Includes both valid and invalid partitions
     - Valid partitions consist of valid values that invoke the correct output  expected from the software
     - Invalid partitions on the other hand, includes values that are not specified  to be checked, but can be entered within the system. 
     The system would process these values to provide an error response.

Question: You want to write a test case for software that tracks the discount provided for photocopying in bulk. According to the discount chart, up to nine copies cost 10 cents each. Further, ten copies or more cost 9 cents each, while 8 cent per copu is the cost for 100 copies or more and 6 cents each for 1000 copies or more. What valid equivalence partitions would you identify for this test case?
	- 10 to 99
	- 1 to 9

Black-Box Testing  (3/6)Testing Techniques

Boundary-Value Analysis  
                                                     
     - tests the values at the edge of an equivalence partition
     - identify the lower boundary values and upper boundary values for each partition.
     - is applied to values such as numbers, text, date, time and currency

Question:
	You want to prepare a test case for the software that tracks the discount provided for bulk photocoping. According to he discount chart, up to nine copies cost 10 cent each. Ten copies or more cost 9 cent each. 100 or more copies cost 8 cent each while an order of 1000 copies or more cost 6 cent each. Four partitions based on the number of copies to be photocopied are identified for this test case: 1 to 9, 10 to 99, 100 to 999, and 1000 to a theoretical maximum value. You now want to identify the three boundary values for these partition taking into consideration the Summation value.

Conditions		Partitions		Lower boundary Values			Upper Boundary Values
10 Cents		1 to 9			0,1,2					8,9,10
9 cents			10 to 99		9,10,11					98,99,100
8 cents			100 to 999		99, 100, 101				998, 999, 1000
6 cents			1000 to max		999,1000,1001				max-1, Max,max +1			



Sample UTS for Black Box: Boundary Value Analysis
							Test cases
Item No.	Item			Sub-item no.		Sub-item			Precondition			Procedure				Expected Result
1. 	   fComputeTenCents(nCopies)	1			Lower Boundary value check	1. Code is finished  		1. Execute fComputeTenCents(0)		1. fComputeTenCents() will not be executed.
									for nCount=0		2. The program is running
												3. nCopies =0
					
					2.			Lower Boundary value check	1. Code is finished  		1. Execute fComputeTenCents(1)		1. Assigned nCost.
									for nCount=1		2. The program is running							value =10
												3. nCopies =1

					3.			Lower Boundary value check	1. Code is finished  		1. Execute fComputeTenCents(2)		1. Assigned nCost
									for nCount=2		2. The program is running							value =20
												3. nCopies =2

					4.			Upper Boundary value check	1. Code is finished  		1. Execute fComputeTenCents(8)		1. Assigned nCost.
									for nCount=8		2. The program is running							value =80
												3. nCopies =8


					5.			Upper Boundary value check	1. Code is finished  		1. Execute fComputeTenCents(9)		1. Assigned nCost.
									for nCount=9		2. The program is running							value =90
												3. nCopies =9


					6. 			Upper Boundary value check	1. Code is finished  		1. Execute fComputeTenCents(10)		1. fComputeTenCent() will not be executed
									for nCount=10		2. The program is running							
												3. nCopies =10


Note: a. fNumOfCopies(nCopies) calls fComputeTenCents (nCopies) if nCopies value is >0 & <10
      b. fComputeTenCents() computes and assigns the nCost value as nCopies * 10




Black-Box Testing (4/6)Testing Techniques

Decision table testing

     - validates system requirements that contain logical conditions with associated actions
      - list all conditions and expected actions and then calculate the number of test cases using this formula: x^y
        (where x = number of condition entry values , y = number of conditions)


Decision Table = Exercise 1
Question: Using a decision table, you're testing an application that allows users appropriate access tp database based on their position in the company. What result should you expect from the application when you test it as a junior employee with no administrative rights?
	-You should be able to read and edit files



Black-Box Testing (5/6)Testing Techniques

State transition technique
     
     - helps create the test cases that are based on an event that cause different states in the software
     - analyze and test each transition of state


Black-Box Testing (6/6)Testing Techniques
Use case testing       
                                                               
      - a use case is a scenario that contains of a realistic tasks that end users will frequently perform
      - moreover, use cases include the outcome expected from the system for each tasks, then write the possible error handling methods
      - uncovers defects in the process flows of a system







Testing Techniques  White-Box Testing  (1/5)
	To check each logic in a program
	Test data are created by investigating internal logic of the program
	Four techniques of White-Box Testing are:
		Statement Coverage
		Decision Coverage
		Condition Coverage
		Multiple-Condition Coverage



White-Box Testing (2/5)Testing Techniques

Statement Coverage
    - measures the percentage of statements exercised by a test case suite    during statement testing 
     - statement testing is testing the individual lines of code in a program
     - effective and efficient test case suites should aim for 100% statement coverage
     - a test case suite cannot be considered complete and exhaustive unless each line of code is exercised at least once

Question: You have written a code to calculate the mesian of three integers. Create the test sets necessary to achieve 100% statement coverage for the median program.

Answer:
	To achieve  100% statement coverage, you need four test sets with three integer values each.
	Four test sets with values:
	10,20,30;
	10,30,20;
	20,10,30;
	and 30,10,20

Sample UTS for White Box: Statement Coverage
							TEST CASES
Item No.	Item			Sub-item no.		Sub-item			Precondition			Procedure						Expected Result
1. 	  	Median			1			a.10				1. Code is finished  		1. Input the integer a,b and c based on column 		1. a,b and c integer values are displayed.
								b.20				2. The program is running	    Sub-item.						2. 20 is displayed as median.
								c.30								2.  Check the output.

					
1.					2.			a.10				1. Code is finished  		1. Input the integer a,b and c based on column 		1. a,b and c integer values are displayed.
								b.30				2. The program is running	    Sub-item.						2. 20 is displayed as median.
								c.20								2.  Check the output.


1.					3.			a.20				1. Code is finished  		1. Input the integer a,b and c based on column 		1. a,b and c integer values are displayed.
								b.10				2. The program is running	    Sub-item.						2. 20 is displayed as median.
								c.30								2.  Check the output.


1.					4.			a.30				1. Code is finished  		1. Input the integer a,b and c based on column 		1. a,b and c integer values are displayed.
								b.10				2. The program is running	    Sub-item.						2. 20 is displayed as median.
								c.20								2.  Check the output.






White-Box Testing (3/5)Testing Techniques


Decision Coverage
    - measures the percentage of decision outcomes exercised by a test suite
     - decision points in a program are depicted using IF statements
     - all decisions in the program must be exercised
     - 100% decision coverage guarantees 100% statement coverage

Question: Consider a program that eads 2 integers. The progran set the values of both integers and prints them. You want 100% decision testing for the program so you need to create some test sets. What will be the test sets that will meet 100% decision coverage?

Answer:
	100% Decision coverage would mean testing both outcomes of the decision point. So there will be 2 test sets. (Sample test sets: 1,2 and 2,1)
Sample UTS for white Box: Decision Coverage
							TEST CASES
Item No.	Item			Sub-item no.		Sub-item				Precondition			Procedure						Expected Result
1. 	  	PrintNum		1			Test Set 1 (path that passes		1. Code is finished  		1. Set a to 1						1. A:3, B:2
								inside IF decision)			2. The program is running	2. Set b to 2    						
																	

					
					2.			Test Set 2 (path that passes		1. Code is finished  		1. Set a to 2						1. A:2, B:1
								outside IF decision)			2. The program is running	2. Set b to 1  						
												



White-Box Testing (4/5)Testing Techniques

Condition Coverage
   - checks and evaluates the outcomes of each individual condition
    - measures the percentage of conditional outcomes exercised by a test suite
    - typically condition coverage is performed after decision coverage
    - to achieve 100% condition coverage, each condition in the decision should be tested for both true and false outcomes

Question: You've ceated a program that prints the maximum of the three integers. You want to achieve 100% condition coverage for the program so you need to create some test sets. What will be the test set that will help you achieve 100% condition coverage?

Answer:
	To achieve 100% cindition coverage, you need four test sets with three integer values each.
	The ff are the sample test set in order to achieve 100% condition coverage:
	3,2,1 (TRUE TRUE for decision point 1 , and TRUE for decision point 2)
	2,1,3 (TRUE FALSE for decision point 1, and FALSE for decision point 2)
	2,3,1 (FALSE TRUE for decision point 1, and TRUE for decision point 2)
	1,2,3 (FALSE FALSE for decision point 1 , and FALSE for decision point 2)


Sample UTS for white Box: Condition Coverage


							TEST CASES
Item No.	Item			Sub-item no.		Sub-item			Precondition			Procedure						Expected Result
1. 	  	MaxNum()		1			TRUE TRUE for decision		1. Code is finished  		1. Set a to 3 						1. Print a
								point 1, and TRUE for 		2. The program is running	2.Set b to 2						
								decision point 2						3. Set c to 1	

					
					2.			TRUE FALSE for decision		1. Code is finished  		1. Set a to 2 						1. Print c
								point 1, and FLASE for 		2. The program is running	2.Set b to 1						
								decision point 2						3. Set c to 3

					3.			FALSE TRUE for decision		1. Code is finished  		1. Set a to 2 						1. Print b								
								point 1, and FLASE for 		2. The program is running	2.Set b to 3						
								decision point 2						3. Set c to 1

					4.			FALSE FALSE for decision	1. Code is finished  		1. Set a to 1 						1. Print c								
								point 1, and FLASE for 		2. The program is running	2.Set b to 2						
								decision point 2						3. Set c to 3





White-Box Testing (5/5)Testing Techniques

Path/Multi-condition Coverage
    - most comprehensive testing technique; it is usually reserved for critical sections of code (safety-critical system such as medical software where even a single instance of system failure is unacceptable)
    - 100% path coverage implies both 100% decision coverage and 100% statement coverage
    - the test is rigorous and exhaustive, maximizes the probability of detecting errors




Testing Techniques  Experienced-Based Testing


Primarily rely on the testers skill and previous experience 
Also referred to as ad hoc and reactive testing 
Two types of experience-based testing are:

	Error guessing  Need to understand how the software system works, make an educated guess about the possible weak points, and design & execute test cases on those points
	Exploratory testing  design test cases, execute them, and log test results based on a test charter within a time box.



Summary

Testing can give confidence in the quality of the software if it finds few or no defects.
General Testing Principles provide a standard framework to testers for conducting tests and discovering defects.
Applied Software Testing Principles provide a standardized format for creating test plans, and act as a guide to effective testing.
There are several test viewpoints (test types) to consider for Unit Test, Integration Test, System Test and Acceptance Test  phase.
Three testing techniques based on ISTQB are : 
     Black-box testing technique (also known as specification-based)
     White-box testing technique (also known as structured-based)
     and Experience-based testing technique






NSP Testing Activities  Developer & Tester Meetings
Developer and Tester Meetings


Meetings between Dev Team and Test team in RA and Design Phase to discuss requirements and designs
Reviewing the test basis (such as requirements, architectures, designs, interfaces)
Evaluating the testability of the test basis and test objects

Who performs: Development Team and Test Team

Test Specs Creation

Test cases are identified based on test approach
Test items are identified for each test case
Test procedures, input conditions and expected results for each test item are documented
Test Data are created
Who performs: Developer / Tester


Test Specifications
Test Spec Creation

Contains:
	Test Cases
	Test Items

Creating Test Cases
	A Test Case defines input data, procedures, and output
	A good test case is one that has high probability of finding yet undiscovered error
	The degree of detail depends on the organization/project
	Developing test cases allow us to thoroughly think of the behavior of a program
	Very helpful in finding problems in the requirements/design
	Should be prepared early in the development cycle


Test Specifications
Test Spec Creation

Using the Test Viewpoint List
	The UT/IT test viewpoint list can be used to determine the most common UT/IT test cases and test items needed for the specific software to be developed.
1. All types of project can use the following test viewpoint list since it covers the most common test viewpoint for any type of software project.
	Common UT/IT Test Viewpoint list (for both UT/IT testing)
	Integration Test Viewpoint list (additional test viewpoint for Integration Testing only) 
2. You may additionally use the following test viewpoint lists for your specific project type.
	Java Test Viewpoint list  (for Java UT/IT)
	C/C++ Test Viewpoint list  (for C/C++ UT/IT) 
	Client/Server Application Test Viewpoint list  (for Client/Server applications UT/IT) 
	Web Application Test Viewpoint list  (for Web Applications UT/IT)




Test Specifications
Test Spec Creation
Tips for Writing Test Specifications:

1. Keep it simple but not too simple; make it complex but not too complex.
	Keep all the steps of Test Cases atomic, precise with correct sequence and with correct mapping to expected results. 
2. After documenting Test cases, review once as Tester 
	Think rationally and try to dry run your Test Cases. Evaluate that all the Steps are clearly understandable, and expected results are in harmony with those steps. 
3. Bound as well as ease the testers 
	Do not leave test data on testers, give them range of inputs especially where calculations are to be performed or applications behavior is dependent on inputs. 
4. Be a Contributor 
	Never accept the Design Documents as it is. Suggest the drop-down-lists, calendar controls, selection-list, group radio buttons, more meaningful messages, cautions, prompts, improvements related to usability etc.  
5. Never Forget the End User 
	During the identification of test scenarios, never overlook those cases which will be mostly used by the user or are business critical even of less frequent use. 


Prepare Test Environment


	HW and SW needed to perform the test are prepared
	HW and SW are installed and configured to meet the required test environment

Who performs: Test Coordinator / Tester


Test Execution

Test is performed in accordance with the test plan and test specifications

Who performs: Tester / Developer



Bug Management

When Too Many/Critical Bugs are Found
	Perform the reporting process even if too many bugs or critical problems occur
	Focus on critical bugs
	Remember:
		These situations have significant impact on schedules
		May indicate deeper problems such as poor testing, bad design, poor coding skills, lack of code/design reviews, etc.
		Inform managers and provide sufficient evidence

Always determine the root cause of the bug. 


Bug Reporting  PHS 1/4Bug Management
PHS Fields				Description							Responsible Person
		PHS#			Unique identifier for the bug.
				
		Date reported		Date the bug was reported.
			
			
		Reported to		Name of person to whom the bug is reported to.
					This is to the development team.
		
Heading		Priority		Priority of the bug						Tester/Test Coordinator
					Priority dictates the level of importance in terms of when 
					the bug should be fixed.
					Values are: High, Medium, Low
		
		Target Fix Date		Date the bug is requested to be fixed.
					(as requested by test team)			
		
		Target Version		The next release version to which the bug must already fixed.
		
		Bug Summary		A brief summary about the bug
					


Bug Reporting  PHS 2/4Bug Management
PHS Fields				Description									Responsible Person
		Discovered by		Name of the Person who found the bug.
		by		
		
		Date 			Date the bug was detected.
		Discovered
			
		Affected Module		Module where the bug was found.
		
		Version			Version of the module or system where the bug occur.
			
		Confirmed by:		Person Who confirmed that it is indeed a bug.

Cause/		Phase the bug		Current Phase where the bug was detected			
Investigation	was  found
		
		Test Case No.		Reference to the test case and test item where the bug was detected
		
		
		Description		Complete description about the bug:
						1. Reference to test item or test case
						2. Input Conditions
						3. Procedure how to make the bug occur
						4. Expected output
						5. Actual Output (bug)
		
		Severity		Severity of the bug.
					Refer to NSP Definition for Bug Severity







Bug Reporting  PHS 3/4Bug Management
PHS Fields				Description							Responsible Person
		Investigated		Person assigned to investigate the bug
		by		
		
		Investigation		Start Data of when the bug was investigated.
		Date	
			
		Investigation		Number of man-hours used to investigate the bug
		Man hours
		
Cause/		Escaped from		Phase where the bug should have been detected			Developer/Development Team
Investigation	Phase
		
		Affected Modules/	Module, files, function which is affected by the bug.		
		Files			
		
		Cause			Explain the root cause of the bug
		
		Bug type		Type of bug.
					Refer to NSP Definition for Bug Types	




Bug Reporting  PHS 4/4Bug Management

PHS Fields				Description									Responsible Person
		Fixed by		Person who fixed the bug.
		Date Fixed		Date when the bug was fixed
		Fixed Modules/		Modules, files, functions which were modified to fix the bug
		files modified		
Solution	Bug fix man-hour	Number of man-hours used to fix the bug.
		Date	
		Solution		Explain the solution implemented for the bug.
		
		
		Version			The release of the module or software where the bug has been confirmed		Tester / Test Coordinator

		
Confirmation	Confirmed by		Person who confirmed that the bug was fixed					Tester / Test Coordinator
		
		
		Confirmation date	Date the bug was confirmed fix.
		
		

Bug ReportingBug Management
Bug Management Tools used in NSP
	Redmine

Bug Management Tools used by Customer
	Henkou Kanri
	Process Creator

	
Bug ReportingBug Management

Tips on how to make a bug report
	Bug report is a technical document written to describe the symptoms of a bug for the purpose of communicating its impact and circumstances.
	Key elements of Bug report
		Describe the symptom of the bug in the bug summary concisely. Be written in passive-voice sentence.
		Write down the exact test procedure that will trigger the problem. Be written in active-voice sentence.
		Describe the actual result- what really occurred? and the expected result- what is expected to happen?
		Include additional information  containing other observations which are useful for easy debugging of developer.
	Capture screen shots and collect logs as evidences



Devils Guide to Debugging 1

Find the defect by guessing
Dont waste time trying to understand the problem
Fix the error with the most obvious fix


In Dantes vision of hell, the lowest circle is reserved for Satan himself. In modern times, Old Scratch has agreed to share the lowest circle with programmers who dont learn to debug effectively. He tortures programmers by making them use these common debugging approaches.



Debugging Techniques
	Scientific Method of Debugging
		Stabilize the error
		Locate the source of the error 
			1. Gather the data that produces the defect
			2. Analyze the data and form a hypothesis about the defect
			3. Determine how to prove or disprove the hypothesis either by testing the program or examining the code
			4. Prove or disprove the hypothesis by using the procedure is 3
		Fix the defect
		Test the Fix
		Look for similar errors.


Fixing a Defect
	Understand the problem before fixing it
	Understand the program, not just the problem
	Confirm the defect diagnosis
	Relax
	Fix the problem, not the symptom


________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Software Testing Overview, Testing Activities & Integration Activities


Software Testing Level 1 Course Outline

Software Testing Overview
	Software QA vs. Testing
	Testing and Quality
	Testing Objectives
	Causes of Software Defects
	Principles of Software Testing
	Testing Phases
	Test Types vs. Testing Phases

Testing Activities
	Integration and Testing Activities WBS
	Developer and Tester Meetings  
	Test Specs creation
	Test Environment preparation
	Test Execution
	Bug Management
	Bug Reporting
	Debugging Techniques


Integration Activities
	Check work products for build
	Integration/Build Activities
	Prepare Build Environment
	Build and assemble
	Package and Release



Software QA vs. Testing


Software QA is based on prevention
	Quality Assurance is applying the planned, systematic quality activities to ensure that the project employs all processes needed to meet requirements
	Make sure that standards (processes, procedures, guidelines) are followed
	Ensure that problems are checked and dealt with

Software Testing is based on detection
	The process of executing a program with the intent of finding errors 
	Check the software if it does what it is supposed to do and what its not supposed to
	Software testing is a critical process to assure that the software functions correctly



Testing and Quality

Testing makes it possible to measure the quality of software in terms of defects found, for both functional and non-functional software requirements and characteristics (e.g. reliability, usability, efficiency) 

Testing can give confidence in the quality of the software if it finds few or no defects.

When testing does find defects, the quality of the software system increases when those defects are fixed.

Lessons should be learned from previous projects. 
      By understanding the root causes of defects found in other projects, processes can be improved, which in turn should prevent those defects from reoccurring and, as a consequence, improve the quality of future systems. 
     
      This is an aspect of quality assurance.



Testing Objectives
Finding Defects

Gaining confidence about the level of quality and providing information

Preventing defects



Causes of software Defects
	Errors or problems in requirements
	Programming Errors
	Wrong Designs


Principles of Software Testing (1/3)

General Testing Principles
	- provide a standard framework to testers for conducting tests and discovering defects

Applied Software Testing Principles
    - provide a standardized format for creating test plans, and acts as a guide to effective testing





Principles of Software Testing (2/3)


General Testing Principles
	
     Principle 1: Testing shows presence of defects 
            - absence of defects does not mean that the software is defect free		 
     Principle 2: Exhaustive testing is impossible
            - when the application uses complex logic and requires a lot of user input

     Principle 3: Confusing an absence of errors with product fit is a fallacy
            - the absence of errors in testing does not mean that the software is suitable
              for customer



Principles of Software Testing (3/3)

Applied Software Testing Principles

    Principle 1: Early testing
		       - testing should begin as early as possible in SDLC

    Principle 2: Defect clustering 
                       - based on Pareto principle which states that about 80% of 
                         defects will be found in approximately 20% of the modules

    Principle 3: Pesticide Paradox
                     - using the same set of tests over and over again, the tests will 
                       cease to uncover bugs

    Principle 4: Testing is context-dependent
                    - need to vary testing efforts depending on the circumstances




Testing Phases  Unit Testing 1/2

A phase in software testing in which software verification is performed by programmers to test if individual units of source code are fit for use.

 A unit is the smallest testable part of an application. It may be an individual procedure or function. 

Test is performed if it meets the detailed design specification 

Source code is evaluated if it is ready for integration and integration testing




Testing Phases  Unit Testing 2/2
Stubs, Test drivers and simulators are usually created to perform the test.

Test cases are derived from work products such as specification of the component, the software design (detailed design) or the data model.

One approach to component testing is to prepare and automate test cases before coding. This is called test-first approach or test-driven development.

Can use testing tools in this phase such as JUnit, Code Joker, Cobertura, C++Test 



Testing Phases  Integration Testing 1/2

		Intergration Activities  + Testing Activities


A phase in software testing in which individual software modules / components are built and combined to produce the software product and resulting software product is tested.

Testing is performed on the software product to check for correctness of the interfaces between internal and external components

To test the software product if it meets the basic design and requirements



Testing Phases  Integration Testing 2/2

		Intergration Activities  + Testing Activities




To validate the software product if it meets the needs of the client

Testing of specific non-functional requirements (e.g. performance)

Simulators or test drivers may be necessary to test connectivity between external components of the system.




Testing Phases - System Testing
	Is concerned with the behaviour of a whole system/product as defined by the scope of a development project

	The test environment should correspond to the final target environment or production environment

	System Testing should investigate both functional and non-functional requirements of the system.

	An independent test team often carries out system testing



Testing Phases - Acceptance Testing
Testing to verify and validate a software product if it meets customer specified requirements.

A customer usually does this type of testing on a product that is developed externally.

Software product is usually deployed to the field and tested.

Acceptance testing may assess the systems readiness for deployment and use, although it is not necessarily the final level of testing.




Test Types vs Testing Phase 1/2
Legend:
	Mandatory	 : This type of testing is mandatory to be performed for a project.
	Recommended : This type of testing is generally recommended to be  performed.
                             Additional criteria might need to be defined on how to performthis type 
                             of test.
	Optional		 : This type of testing may or may not be performed by the project.


		   \
 Type/Method of     \Phase		Unit Test Phase			Integration Test Phase		Priority
  testing	     \


Black Box Testing				/				/			Optional for UT
													Recommended for IT
White Box Testing				/							Recommended
Sanity Testing									/			Recommended
Interface Testing								/			Mandatory
Functional Testing								/			Mandatory
Regression Testing				/				/			Recommended
Load Test									/			Recommended
Stress Test									/			Recommended
Performance Testing								/			Recommended
Usability Testing								/			Optional
Install/uninstall Testing							/			Mandatory
Recovery Testing								/			Recommended
Security Testing								/			Optional
Compatibility Testing								/			Optional
System Testing									/			Recommended
Known Bugs Test									/			Recommended
Acceptance Testing			Usually Acceptance Testing is performed after IT		Mandatory
													Note: if part of project phase



Test Types vs Testing Phase 2/2
	The Table shows the relationship  between test types and testing phases:

		   \
 Type/Method of     \Phase		Unit Test Phase			Integration Test Phase		Priority
  testing	     \


Performance Testing								/			Recommended
Usability Testing								/			Optional
Install/Uninstall Testing							/			Mandatory
Recovery Testing								/			Recommended
Security Testing								/			Optional
Compatibility Testing								/			Optional
System Testing									/			Recommended
Known Bugs Test									/			Recommended
Acceptance Testing			Usually Acceptance Testing is 					Mandatory
					performed After IT						Note: If part of project phase


Notes: In most cases, above priorities applies to any type of project, there are however certain projects which needs specific types of testing. In these special cases, some types of testing identified here as Recommended or Optional may become Mandatory. These has to be properly identified in the Test Approach and Test Completion section of the test plan.



Verification and Validation definition

Verification 
	ensures that selected work products meet their specified requirements.[1] Testing is performed to check behavior of the system against the requirements. 
Validation 
	demonstrates that a product fulfills its intended use when placed in its intended environment.[2] Quite similar to verification but requires that the test environment is the same as target environment. Testing is performed in actual defined target environment. Checking for quality attributes or non-functional requirements are forms of validation and helps ensure that the software will run in intended environment. 



Test Viewpoints- Types of Testing 
Sanity Test
    - Testing to determine if a new software version is performing well 	
		enough to accept it for major testing effort. 
     - If application is crashing for initial use then system is not stable 	
		enough for further testing and build or application is assigned to fix.



Verification
	a. Stability of software (readiness for performing other tests)

Validation
	N/A



Test Viewpoints- Types of Testing 

Interface Testing
    - Type of integration testing where the interfaces between system components are tested.

Verification	
a. Connectivity between 2 modules or applications of the system
b. Connectivity with external interfaces like:
    -> equipment, external modules, external systems or applications

Validation

a. Connectivity with external interfaces like:
    -> equipment, external modules, external systems or applications (same viewpoint as Verification b) 
Note: 
   - Test environment must be same as target environment
   - Test is performed using actual target environment



Test Viewpoints- Types of Testing 

Functional Testing
    - This type of testing ignores the internal parts and focus on the 	output is as per requirement or not. Black-box type testing geared to functional requirements of an application.


Verification
	a. Conformance to requirements
	b. Conformance to features and functions of the software
	c. Fault Tolerance
	d. Boundary/Range Values


Validation
	a. Conformance to features and functions of the software
	b. Fault Tolerance
Note: Test Environment must be same as target environment




Test Viewpoints- Types of Testing 

Regression Testing
    - Testing the application as a whole for the modification in any module or functionality. 
    - Difficult to cover all the system in regression testing so typically automation tools are used for these testing types.


Verification
	a. Check for bug fixes
	b. Check for degrades or side effects introduced by modifications or bug fixes.


Validation
	N/A


Test Viewpoints- Types of Testing 

Load Test
    - Its a performance testing to check system behavior under load.
    - Testing an application under heavy loads, such as testing of a web site under a range of loads to determine at what point the systems response time degrades or fails.

Verification
	N/A


Validation
	a. Operability and stability in high load




Test Viewpoints- Types of Testing 
Stress Test
    - System is stressed beyond its specifications to check how and when it fails. 
    - Performed under heavy load like putting large number beyond storage capacity, complex database queries, continuous input to system or database load.


Verification
	N/A


Validation
	a. Operability and stability in overload


Test Viewpoints- Types of Testing 
Performance Testing
    - Term often used interchangeably with stress and load testing. 
    - To check whether system meets performance requirements. 
    - Used different performance and load tools to do this.


Verification
	Performance or system.
	Ex. Alarms per second, Transaction per seconds.

Validation
	Performance od system.
	Ex. Alarms per second, Transaction per seconds.



Test Viewpoints- Types of Testing 
Usability Testing
    - User-friendliness check. 
    - Application flow is tested, Can new user understand the application easily, Proper help documented whenever user is stuck at any 	point. 
    - Basically system navigation is checked in this testing.

Verification
	N/A

Validation
	a. Ease of use
	b. Correctness of User and Help manuals
	c. Consistency of User Interfaces


Test Viewpoints- Types of Testing 

Install/Uninstall Testing
    - Tested for full, partial, or upgrade install/uninstall processes on different operating systems under different hardware, software 	environment.


Verification
	a. Testing of Installers
	b. Correctness of installation manual

Validation
	a. Testing of installers
	b. Correctness of installation manual
	c. Installation time
	d. Simplicity of installation




Test Viewpoints- Types of Testing 
Recovery Testing
    - Testing how well a system recovers from crashes, hardware failures, or other catastrophic problems.


Verification
	a. Fault Tolerance
	b. Data Integrity

Validation
	a. Fault Tolerance
	b. Data Integrity



Test Viewpoints- Types of Testing 

Security Testing
    - Can system be penetrated by any hacking way. 
    - Testing how well the system protects against unauthorized internal or external access. 
    - Checked if system, database is safe from external attacks.


Verification
	a. Security
	b. Log-in, Log-out
	c. Access Level/Rights
	
Validation
	a. Security



Test Viewpoints- Types of Testing 

Compatibility Testing
    - Testing how well software performs in a particular hardware/software/operating system/network environment and 	different combinations of above.


Verification
	a. Backward compatibility with older systems (HW, SW, etc)
	b. Compatibility with different systems (ex. OS, HW, SW)
	c. Compatibility with different browsers


Validation
	a. Backward compatibility with older systems (HW, SW, etc)
	b. Compatibility with different systems (ex. OS, HW, SW)
	c. Compatibility with different browsers



Test Viewpoints- Types of Testing 

System Testing
    - Entire system is tested as per the requirements. 
    - Black-box type testing that is based on overall requirements specifications, covers all combined parts of a system.



Verification
	a. Conformance to requirements
	b. Conformance to features and functionality

Validation
	a. Conformance to features and functionality



Test Viewpoints- Types of Testing 

Acceptance Testing
    - Testing to verify a product meets customer specified requirements. 
    - A customer usually does this type of testing on a product that is developed externally.


Verification
	N/A

Validation
	a. Conformance against requirements by the client customers


Test Viewpoints- Types of Testing 
Known Bugs Test
    - To test a system against known bugs which were found and fixed in previous testing activities performed.

Verification
	a. Check fir degrades
	b. Check for sides effects of modification made.

Validation
	N/A


Summary

	Testing can give confidence in the quality of the software if it finds few or no defects.
	General Testing Principles provide a standard framework to testers for conducting tests and discovering defects.
	Applied Software Testing Principles provide a standardized format for creating test plans, and act as a guide to effective testing.
	There are several test viewpoints (test types) to consider for Unit Test, Integration Test, System Test and Acceptance Test  phase.
	

Test Specs Creation

	Test cases are identified based on test approach
	Test items are identified for each test case
	Test procedures, input conditions and expected results for each test item are documented
	Test Data are created
Who performs: Developer / Tester


Test Specifications
Test Spec Creation

Contains:
	Test Cases
	Test Items

Creating Test Cases
	 Test Case defines input data, procedures, and output
	A good test case is one that has high probability of finding yet undiscovered error
	The degree of detail depends on the organization/project
	Developing test cases allow us to thoroughly think of the behavior of a program
	Very helpful in finding problems in the requirements/design
	Should be prepared early in the development cycle



Test Specifications
Test Spec Creation

Using the Test Viewpoint List
	The UT/IT test viewpoint list can be used to determine the most common UT/IT test cases and test items needed for the specific software to be developed.
1. All types of project can use the following test viewpoint list since it covers the most common test viewpoint for any type of software project.
	Common UT/IT Test Viewpoint list (for both UT/IT testing)
	Integration Test Viewpoint list (additional test viewpoint for Integration Testing only) 
2. You may additionally use the following test viewpoint lists for your specific project type.
	Java Test Viewpoint list  (for Java UT/IT)
	C/C++ Test Viewpoint list  (for C/C++ UT/IT) 
	Client/Server Application Test Viewpoint list  (for Client/Server applications UT/IT) 
	Web Application Test Viewpoint list  (for Web Applications UT/IT)



Test Specifications
Test Spec Creation

Tips for Writing Test Specifications:

1. Keep it simple but not too simple; make it complex but not too complex.
	Keep all the steps of Test Cases atomic, precise with correct sequence and with correct mapping to expected results. 
2. After documenting Test cases, review once as Tester 
	Think rationally and try to dry run your Test Cases. Evaluate that all the Steps are clearly understandable, and expected results are in harmony with those steps. 
3. Bound as well as ease the testers 
	Do not leave test data on testers, give them range of inputs especially where calculations are to be performed or applications behavior is dependent on inputs. 
4. Be a Contributor 
	Never accept the Design Documents as it is. Suggest the drop-down-lists, calendar controls, selection-list, group radio buttons, more meaningful messages, cautions, prompts, improvements related to usability etc.  
5. Never Forget the End User 
	During the identification of test scenarios, never overlook those cases which will be mostly used by the user or are business critical even of less frequent use. 




Prepare Test Environment

HW and SW needed to perform the test are prepared
HW and SW are installed and configured to meet the required test environment

Who performs: Test Coordinator / Tester


Test Execution



Perform Testing
Test is performed in accordance with the test plan and test specifications

Who performs: Tester / Developer



Bug Management
When too many/critical bugs are found
	Perform the reporting process even if too many bugs or critical problems occur
	Focus on critical bugs
	Remember:
		These situations have significant impact on schedules
		May indicate deeper problems such as poor testing, bad design, poor coding skills, lack of code/design reviews, etc.
		Inform managers and provide sufficient evidence

Always determine the root cause of the bug. 

Bug Management Tools used in NSP
	Eventum
	Mantis
	Issue Tracker

Bug Management Tools used by Customer
	Henkou Kanri
	Process Creator


Tips on how to make a bug report
	Bug report is a technical document written to describe the symptoms of a bug for the purpose of communicating its impact and circumstances.
	Key elements of Bug report
		Describe the symptom of the bug in the bug summary concisely. Be written in passive-voice sentence.
		Write down the exact test procedure that will trigger the problem. Be written in active-voice sentence.
		Describe the actual result- what really occurred? and the expected result- what is expected to happen?
		Include additional information  containing other observations which are useful for easy debugging of developer.
	Capture screen shots and collect logs as evidences


Devils Guide to Debugging 1

Find the defect by guessing
Dont waste time trying to understand the problem
Fix the error with the most obvious fix

Debugging Techniques

	Scientific Method of Debugging
		Stabilize the error
		Locate the source of the error 
			Gather the data that produces the defect
			Analyze the data and form a hypothesis about the defect
			Determine how to prove or disprove the hypothesis either by testing the program or examining the code
			Prove or disprove the hypothesis by using the procedure is 3
		Fix the defect
		Test the Fix
		Look for similar errors.


Fixing a Defect
	Understand the problem before fixing it
	Understand the program, not just the problem
	Confirm the defect diagnosis
	Relax
	Fix the problem, not the symptom



Integration Planning

1.  Identify Integration Strategy and Schedules
2.  Identify Criteria for Integration
3.  Determine the Integration/Build Environment
4.  Determine Build Procedures
5.  Identify Evaluation and Testing

    OUTPUT: Integration Plan, WBS with schedules of build




Check work products for buildUnit Testing Activity
This activity determines if the work products / modules are ready for integration. 
	This refers to the Criteria for Integration which was defined in the Integration Plan 
	Status of source codes are checked (e.g. 100% finished)
	Evaluation of the results of Unit Testing phase is performed to determine readiness
	Execution of Phase Evaluation Activities




Prepare Build EnvironmentIntegration Testing Activities

Prepare Build Environment
	HW and SW are installed and configured based on integration plan


Prepare Integration Test Environment
	Refer to Test Plan for Test Environment


Build and assemble 
Integration Testing Activity

Integrate all product components 
	Based on planned items to be integrated
	Based on build procedures
	Use of build scripts

Create installers
	For deployment to testing




Deploy and Test
Integration Testing Activities

Install integrated product in the test environment

Perform Testing
	Perform testing to check readiness for a full Integration Testing(IT)
		Interface check / Sanity Test
	Perform verification and validation activities based on Integration Plan/Test Plan
		Refer to Test Execution



Guides for Integration

1. Define internal and external interfaces early in the design or requirements analysis phase
	Document the interfaces
2. Always manage changes to interfaces
	Most integration problems such as compilation errors are caused by incorrect interfaces used during coding
	Common bugs found in IT are caused by incorrect interfaces
3. Consider in your design and implementation schedules the dependencies between modules
	This prevents problems later during integration
	Allows for incremental builds to be executed early.
4. Include in your schedules build activities
	Most projects only explicitly schedule test execution activities
	They fail to account the amount of time needed for the build/compile of the software
	Delays in Test execution are sometimes due to delays or problems in the build activity.


Package and Release
Integration Testing Activities

Evaluate Testing Activity
	Check status and results of testing activity
	Evaluate readiness for release
		Passed IT Completion criteria in Test Plan
		Filled up Test Result and Release Evaluation checklist

Perform Release Procedures
Release to client

Always follow your groups baseline procedures




______________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Integration and Testing Activities WBS



	
	NSP Software Development Process			Integration and Testing Activities		:	Output
	  (based on NSP Toplevel WBS)										:
														:
	Planning ______________________________________________Create Integration Plan				:	Integration Plan
			|______________________________________Create Test Plan					:	Test Plan
														:	
	Requirements Analysis(RE)______________________________Developer & Tester Meetings			:	Schedules
														:
	----------------------------------------------------------------------------------------------------------------------------------
														:
	Basic Design(BD)/ Functional Design(FD)________________Create Test Specifications			:	IT Specs
	Detailed Design(DD)____________________________________Create Test Specifications			:	Unit Test Specs
	CD													:	RRC
	Unit Testing(UT)_______________________________________Prepare Test Environment				:	
				|______________________________Perform Testing					:	Test Results & Reports
				|______________________________Submit Bug Reports				:	Phase Eval Report
				|______________________________Debugging Activities				:	PHS/Bug list
				|______________________________Evaluate Testing					:		
				|______________________________Phase Evaluation					:
				|______________________________Check work products for build			:	Additional Outputs:
														:	Test Scripts/data Simulators
	Integration Testing(IT)________________________________Integration/Build Activities			:	
				|					|___Prepare Build Environment		:	
				|					|___Build and Assemble			:	SW Product
				|______________Prepare Test Environment						:
				|______________Perform Testing		  /|		Monitor and Control	:	Test Result &
				|______________Submit Bug Reports	 / |________	  Monitor Progress	: 	Reports
				|______________Debugging Activities	/  |	    |	  Monitor Risk/Issues	:	Test Result
				|______________Evaluate Testing		\  |________|	  Create Test Report	:	Evaluation
				|______________Phase Evaluation		 \ |		  Track and Manage Bugs	: 	Phase Eval Report
				|					  \|					:
				|										:
				|______________Package and Release						: 	SW Product Release Notes

_____________________________________________________________________________________________________________________________________________________________________________________________________________________________________________


Basic Configuration Management & NSP CM process Overview


What are the common problems you encountered with your project repository and project work products?

Common problems encountered...
Updates of interfaces document was not communicated.
Wrong version of the interface of document is used to create the Basic Design.
Product shipped contained the wrong version of the source code.
	Difficulty in recreating a reported problems
	Reoccurrence of fixed bugs
	Inability to obtain the same version that our customers have 
	Lost/Misplaced source files
Share Code/ Share Data
	Some are not notified of bug fixes in code shared by several engineer.
Simultaneous Update
	Modification made in a file was overwritten


What is Configuration Management?
	Is the discipline of identifying the configuration of a system at distinct point in time for the purpose of systematically controlling changes to the configuration, and maintaing the integrity and traceability of the configuration throughout the system life cycle.

Purpose of Configuration Management

To establish and maintain the integrity of work products using: 

	configuration identification,
	configuration control, 
	configuration status accounting and 
	configuration audits


CM Principles

Integrity - The existence and correctness of the configuration items stored in the repository.

Traceability - To be able to trace or monitor changes made to the configuration items in the repository.
		To be alble to trace or monitor the relationship between the software and all other software products.


NSP CM process

NSP Process Architecture		NSP CM Process				Output

Project Initiation			CM Planning				CM Plan
	|				     |		
Project Planning			Establish Repository			Project Repository
	|				     |
--------------------------------------------------------------------------------WPR
	|				     |					
      BD/FD									Meeting Minutes								
	|
        DD									Audit Results	
	|			Perform CM Activities				
	CD									Project Baselines
	|																	
	Testing									Release
	|				     |					Backup	
------------------------------------------------------------------------------------------------------
	|				     |
Project Closure				Archive					Archived Project WP



CM Planning & Establish Repository

Purpose: To be able to plan the activities necessary for the execution of CM of the project group.

	Plan CM Activities
	Establish Project's repository
		Learn and Understand the CM plan

Members do not know how to perform the necessary CM Activities
Not all configuration items will be identified and controlled
Changes will not be handled properly
Too many documents to handle



CM Planning Standard Documents
	Configuration Management Plan Template
	Review Checklist
	Review Record Card Template
	Directory Structure Standard Guideline
	Document Registration Code, Version Number, and File Naming Guideline
	Checkin and Checkout Guideline


CM Activities: Configuration Identification

Purpose: To identify the project work products to be placed under configuration management
	
	Identify the project work products to be manage.
	Assign unique identifiers and location
	Record fucntional and physical characteristics of identified configuration items.
	Support traceability between the software and all other related software products.
	
		You can only manage and control items that you identified.
		The project may use their WBS to help them identify the possible output work products they may create and manage.


Document Control 
	Registration
	Naming Convention
	Versioning	

1. Department/Section & FY
2. Project Registration Series
3. Project Series 
	00 - Main Project
	01 - Subproject
4.Document Type
5.Document Series
6.Supporting document series
	001 for RRC series

					     Document Registration No.
					     /
			SWD10-05100-PLN008-001_Project Plan 1.xls
						    |		\
				         	Document Name	File Extension



		Final Copy/Major   Minor Revision 
	         Revision       \   |
				XX.YY.ZZ
					\
					Draft Version

Assigning unique identifiers help easier management and control of project work products.



Document Control

NSP Standard Directory  Structure

<Project Name>
:----Baseline Map.xls
:----Work Product Registry.xls
:------- 01 Project Management
:        :
:	 :---01 Initiation
:	 :
:	 :---02 PPMC
:	 :
:	 :---03 Closing
:
:------- O2 Engineering
:	 :
:	 :---01 Requirements
:	 :
:	 :---02 Design
:	 :
:	 :---03 Coding
:	 :
:	 :---04 Testing
:	 :
:	 :---05 User Documentation
:	 :
:	 :---06 Release
:	 :
:	 :---07 Libraries
:
:------- 03 Support
	 :
	 :---01 QA
	 :
	 :---02 Communications
 	 :
	 :---03 References
	 :
	 :---04 Tools

Tailoring
	Project Development lifecycle
	Deliverables required by client
	Addition of directories/Sub-directories




__________________________________________________________________________________________________________________________

Git is ...
Distributed
	Does not require a constant connection to a central server

Adaptive
	model can adapt to fit the workflow of almost any team


Fast and Reliable
	Git branches are sparse, allowing for change-only tracking.

Flexible
	git can be command line or GUI driven, allowing everyone to contribute




Terms for working with Git

Branch
	A branch is an independent line of development
Tag
	Mark a specific point in time on a branch
Checkout
	Get a specific branch to start making your changes
Commit 
	Adds changes you've made to the repository
Push	
	Send changes to a remote repository
Workspace
	Directory where you store the repository on your computer

Untracked files
	New files that Git has not been told to keep track of yet
Working area
	Files that have been modified but not committed

Staging Area
	Modified/Added files that are marked to go into the next commit

Local repository ("repo")
	Local copy of the entire upstream repository

Remote (upstream) repo
	Hosted repository on a shared  server (e.g Gitlab)



Document Control 

Revision History
	Records the changes made from one version to another


Sample 				Bad Practice			Good Practice

Updating design 		-Update section 5		Updated based on review #01:
document due to review 		-Retrieval of neType is not		- Corrected Recovery Time and Hold-off Time in
comments			indicated in page 8		Section 5 Scenario Value Pattern
									Added retrieval of neType in Section 7 Interface

Updating design document	Modified Window Image,		Removed function related to LO X-CON in sections: Window Image, Window Specification, Event and Interface base on MR#012 
due to requirements change	Window Specification,
				Event and Interface


Modifying source code		Modification in source code 	2010/12/15 by M. Bean - Modified to fix bug #01:
due to bug fix			is not accounted in revision	Removed function related to LO X-CON
				history				

			
				svn log sample:			svn log sample:
				Modified file due to bug fix	Modified file for bug fix #01
								Removed function related to LO X-CON

Revision History should be descriptive, brief and precise/specific



Configuration Control Activities

1. Repository Check in/Check out
2. Baselines
3. Change Control
4. Release
5. Backup


CM Activities: Configuration Identification

	Misplaced work products
	Changes are not accounted
	Correct version are not used as input document


Standard Document:
	Document Registration Code, Version Number, and file Naming Guidelines
	Directory Structure Standard Guidelines
	Work Product Registry Template




Doc vs. Repo Mapping Exercise

Test Cases & Test procedures documents
Team Member weekly Status Report
Development Source codes
Requirements List
Release Notes
Test Data
Contracts
Risk Management Plan
Monthly Project Status Report
Minutes of the meeting
Project Schedule
Detailed Design
Emails
Third Party Binary Files
Interface Document from Client
Integration Test Procedure
Release Procedure
SQA Evaluation and Audit Report
Project Development Plan
Build Scripts
Estimation worksheet
Unit Test Procedures
Lessons Learned Document
Project Proposal Document
MR form
SQA Plan
MR Log
Basic Design
MakeFile
Customer Survey Form
Review Management Sheet
Configuration Management Plan
HW & SW Development Environment Guide
Installation & User's Manual Document


CM Activities: Configuration Control

Purpose: To manage and control configuration items, ensuring its safety and security so that it will not be changed without proper authorization.

	Control Repository Access
	Manage Changes to all configuration items.
		External and Internal Modification Requests
	Perform Baselines
	Perform Release 
	Backup


Update WPR at least once a week to avoid bulk and tedious update.


Configuration Control Activities
1. Repository Check in/Check out
2. Baselines
3. Change Control
4. Release
5. Backup

1. Repository Check in/Check out

Purpose: To put work products into the repository using a version control application for easier retrieval and management.

Establish and follow the standart procedure in accessing the repository.
	Level of access to the repository
	Consistent access logging


Make sure that the files will be placed in the correct directory of the repository.
When checking-in source codes, make sure that the checked-in code will not contain or introduce errors when the whole system is compiled/build.
Be sure to check-in all work products before weekends or long vacation. If possible, check-in work products at the end of the day. This will keep the work product updated even if the responsible person will be absent on the next day.



2. Baselines
 
Purpose: To establish that the approved configuration items will serve as basis for further development and that it can be changed only through formal change control procedures.


Agree and Approve the configuration items (e.g design, code)
Use the approved configuration items as the basis of the next task.
Take a snapshot of the system at appropriate points in the project lifecycle.


Importance of Baselines

Baselines RL Basis for what product to develop.
Baseline Design basis for implementation of the product.
Baseline Source Codes basis for testing Activities

When creating a work product make sure that the referenced document used is the latest baseline.


3. Change Control

Purpose: To manage the changes of the baselines configuration items.

Manage configuration items that are affected by the change  (Requirement, Design, Review, etc..)
Access impact of changes to the baselines.
Maintain Traceability of the configuration items.
Ensure integrity of configuration items.


To maintain integrity of the repository:
	Always monitor changes in the repository.
	Always follow project's change control procedure.



Change Control Process

Issue Change Request <------------------------------------ Triggers
	|							Modification Request (Client/Developer)
Analyze, Propose, Review, And Approve					Changes in Requirements
MR Procedure, Bug Report, RRC						Changes in design
	|				\				Changes in behaviour
Implement Modification	  _____________| \					Bug Fix
	|		  |	       |  \	Monitor, Managed		Reviews
Confirm  Modification     |	       |  /	And Controlled by
	|		  |____________| /	CM-In-Charge
Release Changes                        |/





4. Release Activities

Purpose: To check readiness of the release items, prepare the deliverables and send to its intended recipient.

Check readiness of deliverables for release
Prepare and package deliverables.
Send package deliverables to intended recipient
PM gets confirmation from recipient



5. Backup - preservation of the content of the configuration management system.

Purpose: To be able to store the configuration items on a separate medium as a precautionary measure to prevent loss of data should the primary storage medium fail.

Preform regular backup as planned.
Check integrity of backup


CM Activities: Configuration Control

	Cannot Trace proper location of work products.
	Cannot determine which version is latest.
	Changes are not accounted.

Incorrect version of design is used as basis for coding

	Cannot trace why a change was made
	Changes are not properly disseminated
	Not all configuration item subject for change was updated.
	Updates could cause errors.

Package release is incorrect or lacking
We do not have copy of the released package.


Configuration Control Strandard Documents

Work Product Registry Template
Directory Structure standard
Checkin and Checkout Guideline
Modification Request (MR) Procedure
Modifiacation Request (MR) Log Template
Modification Request (MR) Template
Review Record Card Template
Problem Handling Sheet (PHS) Template
Test Result and Release Evaluation Checklist
Release Procedure
Release Notes Guideline
Release Notes Template

CM Activities: Configuration Audits (1/2)

Purpose: To Check integrity of the configuration management system of the group

Use the CM plan as the basis for all CM Audits.
Check the existence and correctness of the configuration items stored in the repository.
Check if changes made to the configuration items in the repository are traceable.
Resolve non-conformance(s) found.
Confirm Resolution.

	Perform CM Audit to Maintain the integrity of the repository
	Do Regular audits to avoid bulk and tedious CM Audit
	Always follow project's guidelines and procedure to limmit too much rework.
	Improve project's CM process from the weakness found



CM Activities: Configuration Audits
	Project cannot ensure the integrity of configuration management system
	Project member's practice might not be aligned with project's defined standards.
	Project may encounter repeating problems.

Standard Documents:
	Configuration Management Audits Guideline
	Configuration Management Audit Checklist
	Configuration Management Plan Template
	Work Product Registry Template





CM Activities: Status Accounting
	
Purpose: To check the status of all configuration items and track any changes made to them.

Check and update status of each configuration item in the WPR at least once a week.
Notify all stakeholders if necessary.




CM Activities: Status Accounting
	Project Cannot ensure the integrity of configuration management system.
	Project Member's practice might not be aligned with project's defined standards
	Project may encounter repeating problems

Standard Documents:
	Configuration Management Audit Guideline
	Configuration Management Audit Checklist


Archive

Purpose: To be able to take a final snapshot of the project which can be used as basis for future endeavors related to this project or for future project reference by other projects

Archive Project Work Products
	Note: Request to ITNA of Project Team uses the company wide repository
Give archive to SQA for storage.

	Difficulty in retrieving latest version of project work products.
	Project work products is lost.



SUMMARY



NSP Process Architecture		NSP CM Process				Output

Project Initiation			CM Planning				CM Plan
	|				     |		
Project Planning			Establish Repository			Project Repository
	|				     |
--------------------------------------------------------------------------------WPR
	|				     |					
      BD/FD									Meeting Minutes								
	|                          Perform CM Activities
        DD				Identification				Audit Results	
	|				Control			
	CD				Status Accounting			Project Baselines
	|				CM Audit													
	Testing									Release
	|				     |					Backup	
------------------------------------------------------------------------------------------------------
	|				     |
Project Closure				Archive					Archived Project WP





Which document contains the list of registered work products of the group that is under CM.
- Work Product Registry

It is the activity of putting/retrieving work products into/from the repository using a version control application.
- Repository Check in/Check out


It refers to a set of specifications or work products that has been formally reviewed and agreed on, which thereafter serves as the basis for further development, and which can be changed only through change control procedures.
- Baselines


It refers to the record of the changes made from one version to another.
- Revision History


_________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Git vs.  Subversion

Distributed vs. Centralized Version Control Systems

Centralized
	RCS, CVS, Subversion
	All developers access a single central repository
	Working offline can be a challenge
	Need Access to repository to view history or to commit code.

Distributed
	Bitkeeper, Git, Mercurial
	Every developer has his/her own copy of the repository
	Developers can work offline - commit, branch, merge branches, view history
	Access to internet is only needed when synchronization with other team members is required.



Git vs. Subversion Features


Features			Subverion 			Git

Command Line			Monolithic			>150 Commands

File manager			Tight Integration		Command line front-end

IDE				All major IDEs 			All major IDEs

Continuous Integration		Jenkins, TeamCity,		Jenkins, TeamCity,		
				Bamboo...			Bamboo...	
				
Cloud				Private and Public Cloud	Private and Public Clous

Atomic commits			Snapshots No rollback		Snapshots with rollback

File renames			Manual renames 			Automatic and cross-repository
				Single repository		

Branches, tags, and		Supported as folders		First-class branches, tags, merge, rebase
Merging				Single-merge

Big files			Limited only by file-system	2 GB practical limit

Replication			Mirroring only			Master-slave
								Master-master
								Peer-to-peer



Git vs Subversion Security

		Channel Security	Authentication			Fine-grained security		Permission Model

Subversion	PKI, SSL, SSH		Basic Auth, X.509		Tag, path; branch		ACLs, RBAC
					Kerberos, SSH, LDAP/AD,
					SSO


Git		SSL, SSH		No auth, OS User, SSH		Only full repo R/W		OS file permmissions




Differences Between Git and SVN

Directory Structure
	Subversion	
		Trunk- represent the latest stable release
		Branches-activates features are developed in the subdirectories.

	
	Git
		Project are stored in single directory
		Master - contains the latest stable release
		branch - active features are developed in separate branches.
		Directory structure remains the same, but file content may change depending on the branch





Directory Structure


This is how an SVN directory structure look

Project ----> trunk -------> Current Sources
  |	\
  |	 \   
  |	  \ branches ------> Feature Branch
  |		     ------> Feature Branch 1
  |		     ------> Feature Branch 2
  |			O     O     O
  |		     ------> Experimental Brach	
  |
  |
   Tags ------> V1.0-beta1
	------> V1.0-rc1
	------> V1.0-RTM
		O   O    O
	------> V2.7.101
		




Comparison of Commands

Initial Checkout

Get a copy of the last revision from repository				Keep a copy of the entire repository
Can grab any particular path in the repository				Can grab only the entire respository

	
		SVN Repository							git central repository
		/								/
	       / Checkout						       /clone	
	      /								      /
	  dev A		dev B						  dev a 		dev B

$ svn checkout							$ git clone



Adding file

Used for adding new files				Used for adding new files and saving modification to existing files
							

	
		SVN Repository							git central repository
		/								
	       / add						 	   __    clone	
	      /								  |  |  
	  dev A		dev B						  dev a 		dev B
	path/file1.txt							path/file1.txt

$ svn add path/file1.txt					$ git add path/file1.txt


Status

Tracks unversioned, new, deleted, modified files				Track unversioned, new ,deleted, modified, and modified but not 'add'-ed
							

	
		SVN Repository							git central repository
		/								
	       / 						 	   __    
	      /								  |  |  
	  dev A		dev B						  dev a 		dev B
	path/file1.txt							path/file1.txt

$ svn status								$ git status






Commit

Send changes to remote repository					Only commit to local repository
Revision number is incrementing integer					Revision number is hash of the commit		

	
		SVN Repository							git central repository
		/								
	       / commit						 	   __  commit 	
	      /								  |  |  
	  dev A		dev B						  dev a 		dev B
	path/file1.txt							path/file1.txt

$ svn commit -m "Add file1"					$ git commit -m "Add file1"
$ svn log -q								$ git log -oneline
r3382 | eperez | 2017-05-12 14:04:34...								4ef8563 Add file1




Push

Send changes to remote repository				Send changes to the central repository
							

	
		SVN Repository							git central repository
		/								
	       /commit						 	   __  push	
	      /								  |  |  
	  dev A		dev B						  dev a 		dev B
	path/file1.txt							path/file1.txt

$ svn commit -m "Add file1"						$ git push





Compare

Compare file with central repository				Show the difference of local files
							

	
		SVN Repository							git central repository
		/								
	       / diff						 	   __ diff
	      /								  |  |  
	  dev A		dev B						  dev a 		dev B
	path/file1.txt							path/file1.txt

$ svn diff path/file1.txt						$ git diff path/file1.txt




Reverting

Revert changes in the working copy				Checkout a version of the last committed change
							

	
		SVN Repository							git central repository
		/								
	       / revert						 	   __  checkout	
	      /								  |  |  
	  dev A		dev B						  dev a 		dev B
	path/file1.txt							path/file1.txt

$ svn revert path/file1.txt					$ git checkout path/file1.txt






Updating

Bring changes from repository into working copy			Fetch from and integrate with another repository
							

	
		SVN Repository							git central repository
		/	\							/		\
	       / update	 \ commit					 	       / pull		 \ push
	      /		  \						      /   		  \
	  dev A		dev B						  dev a 		dev B
	path/file1.txt							path/file1.txt

$ svn update								$ git pull






Branching

Making changes immediately to remote repository				Local repository only
									Needs push to send to remote

	
		SVN Repository							git central repository
		/								
	       / copy						 	   __ checkout -b	
	      /								  |  |  
	  dev A		dev B						  dev a 		dev B
	path/file1.txt							path/file1.txt

$ svn copy .								$ git branch newbie
http://example.com/repo/branch/newbie					$ git checkout newbie
$svn switch -relocate
http://example.com/repo/branch/newbie



Example: Git workflow
# Clone and create "develop" branch
$ git clone ssh://user@host/path/to/repo.git
$ git checkout -b develop origin/develop		C2


# Create branch for new feature
$ git checkout -b some-feature develop
$git push -u origin some-feature			C3


#Feature is developed
$ git pull origin develop
$ git checkout develop
$ git merge --no-ff some-feature
$ git push origin develop

$ git branch -d some-feature


# Prepare a release, cleanup, test,...
$ git checkout -b release-0.1.0 develop			C14

# Finish the release
$ git checkout master 					C13
$ git merge --no-ff release-0.1.0
$ git push
$ git checkout develop
$ git merge --no-ff release-0.1.0
$ git push
$ git branch -d release-0.1.0

# If you pushed branch to origin
$ git push origin --delete release-0.1.0

$ git tag -a v0.1.0 master
$ git push-tags

#If customer found a bug, create a new branch
$ git checkout -b hotfix-0.1.1 master





Summary of Features comparison between svn and git


Feature			svn					git

Inital checkout		svn checkout				git clone
			http://example.com/repo			http://example.com/repo.git

Add file		svn aff path/file1.txt			git add path/file1.txt

Status			git status				git status

Commit			svn commit -m "Add file1"		git commit -m "Add file1"

Push			svn commit -m "Add file1"		git push

Compare			svn diff path/file1.txt			git diff path/file1.txt

Revert			svn revert path/file1.txt		git checkout path/file1.txt

Update			svn update				svn pull

Branch			svn copy:
			http://example.com/branch/newbie	git checkout -b newbie

Binary Storage		Support exclusive lock.			No support for exclusive lock and Copy-Modify-Merge is not applicable to binary files
							
								Not advisable for binary document (MS Word, excel, executable, libraries,...)

History			Keep track of all changes to a file/	Losses history if file is renamed. (Can be tracked in github/gitlab)
			folder					



_________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________

Git Branching

You can seel all the commands available with "show commands" at the terminal

Git Commits
A commit in a git repository records a snapshot of all the files in your directory. It's like a giant copy and paste, but even better!

Git wants to keep commits as lightweight as possible though, so it doesn't just blindly copy the entire directory every time you commit. It can (when possible) compress a commit as a set of changes, or a "delta", from one version of the repository to the next.

Git also maintains a history of which commits were made when. That's why most commits have ancestor commits above them -- we designate this with arrows in our visualization. Maintaining history is great for everyone working on the project!

It's a lot to take in, but for now you can think of commits as snapshots of the project. Commits are very lightweight and switching between them is wicked fast!
-git commit



Git Branches
Branches in Git are incredibly lightweight as well. They are simply pointers to a specific commit -- nothing more. This is why many Git enthusiasts chant the mantra:

"branch early, and branch often"

Because there is no storage / memory overhead with making many branches, it's easier to logically divide up your work than have big beefy branches.

When we start mixing branches and commits, we will see how these two features combine. For now though, just remember that a branch essentially says "I want to include the work of this commit and all parent commits."



git checkout <name>

This will put us on the new branch before committing our changes

ex. git checkout newImage; git commit



Here's a shortcut: if you want to create a new branch AND check it out at the same time, you can simply type 
git checkout -b [yourbranchname].





Branches and Merging
Great! We now know how to commit and branch. Now we need to learn some kind of way of combining the work from two different branches together. This will allow us to branch off, develop a new feature, and then combine it back in.

The first method to combine work that we will examine is "git merge". Merging in Git creates a special commit that has two unique parents. A commit with two parents essentially means "I want to include all the work from this parent over here and this one over here, and the set of all their parents."

It's easier with visuals, let's check it out in the next view

Here we have two branches; each has one commit that's unique. This means that neither branch includes the entire set of "work" in the repository that we have done. Let's fix that with merge.

We will merge the branch bugFix into master

git merge bugFix

Woah! See that? First of all, master now points to a commit that has two parents. If you follow the arrows up the commit tree from master, you will hit every commit along the way to the root. This means that master contains all the work in the repository now.

Also, see how the colors of the commits changed? To help with learning, I have included some color coordination. Each branch has a unique color. Each commit turns a color that is the blended combination of all the branches that contain that commit.

So here we see that the master branch color is blended into all the commits, but the bugFix color is not. Let's fix that...


git checkout bugFix; git merge master


Let's merge master into bugFix:

git checkout bugFix; git merge master

Since bugFix was an ancestor of master, git didn't have to do any work; it simply just moved bugFix to the same commit master was attached to.

Now all the commits are the same color, which means each branch contains all the work in the repository! Woohoo!



To complete this level, do the following steps:

Make a new branch called "bugFix"
	- git branch bugFix

Checkout the "bugFix" branch with "git checkout bugFix"
	- git checkout bugFix

Commit once
	- git commit

Go back to "master" with "git checkout"
	- git checkout master

Commit another time
	- git commit

Merge the branch "bugFix" into "master" with "git merge"
	-git merge bugFix
	-git merge master
Remember, you can always re-display this dialog with "objective"




Git Rebase
The second way of combining work between branches is rebasing. Rebasing essentially takes a set of commits, "copies" them, and plops them down somewhere else.

While this sounds confusing, the advantage of rebasing is that it can be used to make a nice linear sequence of commits. The commit log / history of the repository will be a lot cleaner if only rebasing is allowed.

Let's see it in action...


Here we have two branches yet again; note that the bugFix branch is currently selected (note the asterisk)
We would like to move our work from bugFix directly onto the work from master. That way it would look like these two features were developed sequentially, when in reality they were developed in parallel.
Let's do that with the git rebase command

git rebase master

Awesome! Now the work from our bugFix branch is right on top of master and we have a nice linear sequence of commits.
Note that the commit C3 still exists somewhere (it has a faded appearance in the tree), and C3' is the "copy" that we rebased onto master.
The only problem is that master hasn't been updated either, let's do that now...
Now we are checked out on the master branch. Let's go ahead and rebase onto bugFix...

git rebase bugFix

There! Since "master" was an ancestor of "bugFix", git simply moved the "master" branch reference forward in history.


To complete this level, do the following

Checkout a new branch named "bugFix"
- git checkout -b bugFix

Commit once
-git commit

Go back to master and commit again
-git checkout master
-git commit
Check out bugFix again and rebase onto master
-git checkout bugFix
-git rebase master
Good luck!





Moving around in Git
Before we get to some of the more advanced features of Git, it's important to understand different ways to move through the commit tree that represents your project.

Once you're comfortable moving around, your powers with other git commands will be amplified!



HEAD
First we have to talk about "HEAD". HEAD is the symbolic name for the currently checked out commit -- it's essentially what commit you're working on top of.
HEAD always points to the most recent commit which is reflected in the working tree. Most git commands which make changes to the working tree will start by changing HEAD.
Normally HEAD points to a branch name (like bugFix). When you commit, the status of bugFix is altered and this change is visible through HEAD.

Here we will reveal HEAD before and after a commit.

git checkout C1; git checkout master; git commit; git checkout C2

See! HEAD was hiding underneath our master branch all along.


Detaching HEAD
Detaching HEAD just means attaching it to a commit instead of a branch. This is what it looks like beforehand:
HEAD -> master -> C1

git checkout C1

And now it's
HEAD -> C1


To complete this level, let's detach HEAD from bugFix and attach it to the commit instead.
ex.
- git checkout C4
Specify this commit by its hash. The hash for each commit is displayed on the circle that represents the commit.




Relative Refs
Moving around in Git by specifying commit hashes can get a bit tedious. In the real world you won't have a nice commit tree visualization next to your terminal, so you'll have to use git log to see hashes.
Furthermore, hashes are usually a lot longer in the real Git world as well. For instance, the hash of the commit that introduced the previous level is fed2da64c0efc5293610bdd892f82a58e8cbc5d8. Doesn't exactly roll off the tongue...
The upside is that Git is smart about hashes. It only requires you to specify enough characters of the hash until it uniquely identifies the commit. So I can type fed2 instead of the long string above.
Like I said, specifying commits by their hash isn't the most convenient thing ever, which is why Git has relative refs. They are awesome!
With relative refs, you can start somewhere memorable (like the branch "bugFix" or "HEAD") and work from there.
Relative commits are powerful, but we will introduce two simple ones here:

Moving upwards one commit at a time with ^
Moving upwards a number of times with ~<num>
Let's look at the Caret (^) operator first. Each time you append that to a ref name, you are telling Git to find the parent of the specified commit.

So saying master^ is equivalent to "the first parent of master".
master^^ is the grandparent (second-generation ancestor) of master
Let's check out the commit above master here

git checkout master^

You can also reference "HEAD" as a relative ref. Let's use that a couple of times to move upwards in the commit tree

git checkout C3; git checkout HEAD^; git checkout HEAD^; git checkout HEAD^



To complete this level, check out the parent commit of bugFix. This will detach HEAD.

ex.
git checkout C4^
You can specify the hash if you want, but try using relative refs instead!

You can also reference HEAD as a relative ref. Let's use that a couple of times to move upwards in the commit tree

git checkout C3; git checkout HEAD^; git checkout HEAD^; git checkout HEAD^
Easy! We can travel backwards in time with HEAD^



The "~" operator
Say you want to move a lot of levels up in the commit tree. It might be tedious to type ^ several times, so Git also has the tilde (~) operator.
The tilde operator (optionally) takes in a trailing number that specifies the number of parents you would like to ascend. Let's see it in action
Let's specify a number of commits back with ~.

git checkout HEAD~4



Branch forcing
You're an expert on relative refs now, so let's actually use them for something.
One of the most common ways I use relative refs is to move branches around. You can directly reassign a branch to a commit with the -f option. So something like:
git branch -f master HEAD~3

moves (by force) the master branch to three parents behind HEAD.


git branch -f master HEAD~3

There we go! Relative refs gave us a concise way to refer to C1 and branch forcing (-f) gave us a way to quickly move a branch to that location.
Now that you have seen relative refs and branch forcing in combination, let's use them to solve the next level.

To complete this level, move HEAD, master, and bugFix to their goal destinations shown.
-  git branch -f master C6
- git checkout Head~1
-  git branch -f bugfix HEAD~1



Reversing Changes in Git
There are many ways to reverse changes in Git. And just like committing, reversing changes in Git has both a low-level component (staging individual files or chunks) and a high-level component (how the changes are actually reversed). Our application will focus on the latter.

There are two primary ways to undo changes in Git -- one is using git reset and the other is using git revert. We will look at each of these in the next dialog



Git Reset
git reset reverts changes by moving a branch reference backwards in time to an older commit. In this sense you can think of it as "rewriting history;" git reset will move a branch backwards as if the commit had never been made in the first place.
Let's see what that looks like:

git reset HEAD~1
Nice! Git moved the master branch reference back to C1; now our local repository is in a state as if C2 had never happened.

Git Revert
While reseting works great for local branches on your own machine, its method of "rewriting history" doesn't work for remote branches that others are using.

In order to reverse changes and share those reversed changes with others, we need to use git revert. Let's see it in action
git revert HEAD

Weird, a new commit plopped down below the commit we wanted to reverse. That's because this new commit C2' introduces changes -- it just happens to introduce changes that exactly reverses the commit of C2.
With reverting, you can push out your changes to share with others.
To complete this level, reverse the most recent commit on both local and pushed. You will revert two commits total (one per branch).

-git checkout pushed
-git revert C2
-git checkout local
-git reset Head~1 or git reset local^

Keep in mind that pushed is a remote branch and local is a local branch -- that should help you choose your methods.




Moving Work Around
So far we've covered the basics of git -- committing, branching, and moving around in the source tree. Just these concepts are enough to leverage 90% of the power of git repositories and cover the main needs of developers.
That remaining 10%, however, can be quite useful during complex workflows (or when you've gotten yourself into a bind). The next concept we're going to cover is "moving work around" -- in other words, it's a way for developers to say "I want this work here and that work there" in precise, eloquent, flexible ways.
This may seem like a lot, but it's a simple concept.


Git Cherry-pick
The first command in this series is called "git cherry-pick". It takes on the following form:

"git cherry-pick <Commit1> <Commit2> <...>"
It's a very straightforward way of saying that you would like to copy a series of commits below your current location (HEAD). I personally love cherry-pick because there is very little magic involved and it's easy to understand.
Let's see a demo!

Here's a repository where we have some work in branch side that we want to copy to master. This could be accomplished through a rebase (which we have already learned), but let's see how cherry-pick performs.
git cherry-pick C2 C4

That's it! We wanted commits C2 and C4 and git plopped them down right below us. Simple as that!



Git Interactive Rebase
Git cherry-pick is great when you know which commits you want (and you know their corresponding hashes) -- it's hard to beat the simplicity it provides.
But what about the situation where you don't know what commits you want? Thankfully git has you covered there as well! We can use interactive rebasing for this -- it's the best way to review a series of commits you're about to rebase.
Let's dive into the details...

All interactive rebase means is using the "rebase" command with the -i option.

If you include this option, git will open up a UI to show you which commits are about to be copied below the target of the rebase. It also shows their commit hashes and messages, which is great for getting a bearing on what's what.

For "real" git, the UI window means opening up a file in a text editor like vim. For our purposes, I've built a small dialog window that behaves the same way.
When the interactive rebase dialog opens, you have the ability to do 3 things:

You can reorder commits simply by changing their order in the UI (in our window this means dragging and dropping with the mouse).
You can choose to completely omit some commits. This is designated by "pick" -- toggling "pick" off means you want to drop the commit.
Lastly, you can squash commits. Unfortunately our levels don't support this for a few logistical reasons, so I'll skip over the details of this. Long story short, though -- it allows you to combine commits.
Great! Let's see an example.

When you hit the button, an interactive rebase window will appear. Reorder some commits around (or feel free to unpick some) and see the result!
git rebase -i HEAD~4

Boom! Git copied down commits in the exact same way you specified through the UI

git rebase -i overHere 
or git rebase -i C1,C3,C4,C5



Locally stacked commits
Here's a development situation that often happens: I'm trying to track down a bug but it is quite elusive. In order to aid in my detective work, I put in a few debug commands and a few print statements.
All of these debugging / print statements are in their own commits. Finally I track down the bug, fix it, and rejoice!
Only problem is that I now need to get my "bugFix" back into the "master" branch. If I simply fast-forwarded "master", then "master" would get all my debug statements which is undesirable. There has to be another way...

We need to tell git to copy only one of the commits over. This is just like the levels earlier on moving work around -- we can use the same commands:

git rebase -i
git cherry-pick
To achieve this goal.



This is a later level so we will leave it up to you to decide which command you want to use, but in order to complete the level, make sure master receives the commit that bugFix references.
- git rebase -i C1
- git branch -f master C4'




Juggling Commits
Here's another situation that happens quite commonly. You have some changes (newImage) and another set of changes (caption) that are related, so they are stacked on top of each other in your repository (aka one after another).
The tricky thing is that sometimes you need to make a small modification to an earlier commit. In this case, design wants us to change the dimensions of newImage slightly, even though that commit is way back in our history!!

We will overcome this difficulty by doing the following:

We will re-order the commits so the one we want to change is on top with "git rebase -i"
We will "commit --amend" to make the slight modification
Then we will re-order the commits back to how they were previously with "git rebase -i"
Finally, we will move master to this updated part of the tree to finish the level (via the method of your choosing)
There are many ways to accomplish this overall goal (I see you eye-ing cherry-pick), and we will see more of them later, but for now let's focus on this technique. Lastly, pay attention to the goal state here -- since we move the commits twice, they both get an apostrophe appended. One more apostrophe is added for the commit we amend, which gives us the final form of the tree

That being said, I can compare levels now based on structure and relative apostrophe differences. As long as your tree's master branch has the same structure and relative apostrophe differences, I'll give full credit
- git rebase -i HEAD~2
- git commit --amend
- git rebase -i HEAD~2 
- git rebase caption master



Juggling Commits #2
If you haven't completed Juggling Commits #1 (the previous level), please do so before continuing
As you saw in the last level, we used rebase -i to reorder the commits. Once the commit we wanted to change was on top, we could easily --amend it and re-order back to our preferred order.
The only issue here is that there is a lot of reordering going on, which can introduce rebase conflicts. Let's look at another method with git cherry-pick


Remember that git cherry-pick will plop down a commit from anywhere in the tree onto HEAD (as long as that commit isn't an ancestor of HEAD).
Here's a small refresher demo:

git cherry-pick C2

So in this level, let's accomplish the same objective of amending C2 once but avoid using rebase -i. I'll leave it up to you to figure it out! :D
Remember, the exact number of apostrophe's (') on the commit are not important, only the relative differences. For example, I will give credit to a tree that matches the goal tree but has one extra apostrophe everywhere

$ git checkout master

$ git cherry-pick C2

$ git commit --amend

$ git cherry-pick C3



Git Tags
As you have learned from previous lessons, branches are easy to move around and often refer to different commits as work is completed on them. Branches are easily mutated, often temporary, and always changing.
If that's the case, you may be wondering if there's a way to permanently mark historical points in your project's history. For things like major releases and big merges, is there any way to mark these commits with something more permanent than a branch?

You bet there is! Git tags support this exact use case -- they (somewhat) permanently mark certain commits as "milestones" that you can then reference like a branch.
More importantly though, they never move as more commits are created. You can't "check out" a tag and then complete work on that tag -- tags exist as anchors in the commit tree that designate certain spots.
Let's see what tags look like in practice.


Let's try making a tag at C1 which is our version 1 prototype

git tag v1 C1

There! Quite easy. We named the tag v1 and referenced the commit C1 explicitly. If you leave the commit off, git will just use whatever HEAD is at

For this level just create the tags in the goal visualization and then check v1 out. Notice how you go into detached HEAD state -- this is because you can't commit directly onto the v1 tag.
In the next level we'll examine a more interesting use case for tags.
-git tag v0 C1
-git tag v1 C2
-git checkout C2


Git Describe
Because tags serve as such great "anchors" in the codebase, git has a command to describe where you are relative to the closest "anchor" (aka tag). And that command is called "git describe"!
Git describe can help you get your bearings after you've moved many commits backwards or forwards in history; this can happen after you've completed a git bisect (a debugging search) or when sitting down at a coworkers computer who just got back from vacation.


Git describe takes the form of:

git describe <ref>

Where <ref> is anything git can resolve into a commit. If you don't specify a ref, git just uses where you're checked out right now (HEAD).
The output of the command looks like:

<tag>_<numCommits>_g<hash>

Where "tag" is the closest ancestor tag in history, "numCommits" is how many commits away that tag is, and "<hash>" is the hash of the commit being described.

Let's look at a quick example. For this tree below:

git tag v2 C3

The command "git describe master" would output:

v1_2_gC2

Whereas git describe side would output:

v2_1_gC4

That's pretty much all there is to git describe! Try describing a few of the locations in this level to get a feel for the command.
Once you're ready, just go ahead and commit once to finish the level. We're giving you a freebie :P



Rebasing Multiple Branches
Man, we have a lot of branches going on here! Let's rebase all the work from these branches onto master.
Upper management is making this a bit trickier though -- they want the commits to all be in sequential order. So this means that our final tree should have C7' at the bottom, C6' above that, and so on, all in order.
If you mess up along the way, feel free to use reset to start over again. Be sure to check out our solution and see if you can do it in fewer commands!

- git rebase master bugFix
- git rebase bugFix side
- git rebase side another
- git rebase another master


Specifying Parents
Like the ~ modifier, the ^ modifier also accepts an optional number after it.
Rather than specifying the number of generations to go back (what ~ takes), the modifier on ^ specifies which parent reference to follow from a merge commit. Remember that merge commits have multiple parents, so the path to choose is ambiguous.
Git will normally follow the "first" parent upwards from a merge commit, but specifying a number with ^ changes this default behavior.
Enough talking, let's see it in action.

Here we have a merge commit. If we checkout master^ without the modifier, we will follow the first parent after the merge commit.
(In our visuals, the first parent is positioned directly above the merge commit.)
git checkout master^

The ^ and ~ modifiers can make moving around a commit tree very powerful:
git checkout HEAD~; git checkout HEAD^2; git checkout HEAD~2

Even crazier, these modifiers can be chained together! Check this out:
git checkout HEAD~^2~2

The same movement as before, but all in one command.

Put it to practice
To complete this level, create a new branch at the specified destination.
Obviously it would be easy to specify the commit directly (with something like C6), but I challenge you to use the modifiers we talked about instead!

- git branch bugWork
- git branch -f bugWork C2
- git checkout master





Branch Spaghetti
WOAHHHhhh Nelly! We have quite the goal to reach in this level.

Here we have master that is a few commits ahead of branches one two and three. For whatever reason, we need to update these three other branches with modified versions of the last few commits on master.

Branch one needs a re-ordering and a deletion of C5. two needs pure reordering, and three only needs one commit!

We will let you figure out how to solve this one -- make sure to check out our solution afterwards with show solution.

- git cherry-pick C4
- git cherry-pick C3
- git cherry-pick C2
- git commit --amend
- git checkout C1
- git cherry-pick C5
- git cherry-pick C4'
- git cherry-pick C3'
- git cherry-pick C2'
- git branch -f two C2''
- git branch -f three C2


Git Remotes
Remote repositories aren't actually that complicated. In today's world of cloud computing it's easy to think that there's a lot of magic behind git remotes, but they are actually just copies of your repository on another computer. You can typically talk to this other computer through the Internet, which allows you to transfer commits back and forth.
That being said, remote repositories have a bunch of great properties:
First and foremost, remotes serve as a great backup! Local git repositories have the ability to restore files to a previous state (as you know), but all that information is stored locally. By having copies of your git repository on other computers, you can lose all your local data and still pick up where you left off.
More importantly, remotes make coding social! Now that a copy of your project is hosted elsewhere, your friends can contribute to your project (or pull in your latest changes) very easily.
It's become very popular to use websites that visualize activity around remote repos (like Github or Phabricator), but remote repositories always serve as the underlying backbone for these tools. So it's important to understand them!
Our Command to create remotes
Up until this point, Learn Git Branching has focused on teaching the basics of local repository work (branching, merging, rebasing, etc). However now that we want to learn about remote repository work, we need a command to set up the environment for those lessons. git clone will be that command

Technically, git clone in the real world is the command you'll use to create local copies of remote repositories (from github for example). We use this command a bit differently in Learn Git Branching though -- git clone actually makes a remote repository out of your local one. Sure it's technically the opposite meaning of the real command, but it helps build the connection between cloning and remote repository work, so let's just run with it for now.
Lets start slow and just look at what a remote repository looks like (in our visualization).

git clone

There it is! Now we have a remote repository of our project. It looks pretty similar except for some visual changes to make the distinction apparent -- in later levels you'll get to see how we share work across these repositories.

To finish this level, simply git clone your existing repository. The real learning will come in following lessons.
- git clone




Git Remote Branches
Now that you've seen git clone in action, let's dive into what actually changed.

The first thing you may have noticed is that a new branch appeared in our local repository called o/master. This type of branch is called a remote branch; remote branches have special properties because they serve a unique purpose.
Remote branches reflect the state of remote repositories (since you last talked to those remote repositories). They help you understand the difference between your local work and what work is public -- a critical step to take before sharing your work with others.
Remote branches have the special property that when you check them out, you are put into detached HEAD mode. Git does this on purpose because you can't work on these branches directly; you have to work elsewhere and then share your work with the remote (after which your remote branches will be updated).

What is o/?
You may be wondering what the leading o/ is for on these remote branches. Well, remote branches also have a (required) naming convention -- they are displayed in the format of:

<remote name>/<branch name>
Hence, if you look at a branch named o/master, the branch name is master and the name of the remote is o.

Most developers actually name their main remote origin, not o. This is so common that git actually sets up your remote to be named origin when you git clone a repository.
Unfortunately the full name of origin does not fit in our UI, so we use o as shorthand :( Just remember when you're using real git, your remote is probably going to be named origin!
That's a lot to take in, so let's see all this in action.

Lets check out a remote branch and see what happens

git checkout o/master; git commit

As you can see, git put us into detached HEAD mode and then did not update o/master when we added a new commit. This is because o/master will only update when the remote updates.


To finish this level, commit once off of master and once after checking out o/master. This will help drive home how remote branches behave differently, and they only update to reflect the state of the remote.
- git commit
- git checkout o/master
- git commit



Git Fetch
Working with git remotes really just boils down to transferring data to and from other repositories. As long as we can send commits back and forth, we can share any type of update that is tracked by git (and thus share work, new files, new ideas, love letters, etc.).
In this lesson we will learn how to fetch data from a remote repository -- the command for this is conveniently named git fetch.
You'll notice that as we update our representation of the remote repository, our remote branches will update to reflect that new representation. This ties into the previous lesson on remote branches

Before getting into the details of git fetch, let's see it in action! Here we have a remote repository that contains two commits that our local repository does not have.
git fetch


There we go! Commits C2 and C3 were downloaded to our local repository, and our remote branch o/master was updated to reflect this.
What fetch does
git fetch performs two main steps, and two main steps only. It:

	downloads the commits that the remote has but are missing from our local repository, and...
	updates where our remote branches point (for instance, o/master)
git fetch essentially brings our local representation of the remote repository into synchronization with what the actual remote repository looks like (right now).

If you remember from the previous lesson, we said that remote branches reflect the state of the remote repositories since you last talked to those remotes. git fetch is the way you talk to these remotes! Hopefully the connection between remote branches and git fetch is apparent now.

git fetch usually talks to the remote repository through the Internet (via a protocol like http:// or git://).


What fetch doesn't do
git fetch, however, does not change anything about your local state. It will not update your master branch or change anything about how your file system looks right now.

This is important to understand because a lot of developers think that running git fetch will make their local work reflect the state of the remote. It may download all the necessary data to do that, but it does not actually change any of your local files. We will learn commands in later lessons to do just that :D

So at the end of the day, you can think of running git fetch as a download step.
To finish the level, simply git fetch and download all the commits!
- git fetch




Git Pull
Now that we've seen how to fetch data from a remote repository with git fetch, let's update our work to reflect those changes!
There are actually many ways to do this -- once you have new commits available locally, you can incorporate them as if they were just normal commits on other branches. This means you could execute commands like:

git cherry-pick o/master
git rebase o/master
git merge o/master
etc., etc.
In fact, the workflow of fetching remote changes and then merging them is so common that git actually provides a command that does both at once! That command is git pull.
Let's first see a fetch and a merge executed sequentially

git fetch; git merge o/master

Boom -- we downloaded C3 with a fetch and then merged in that work with git merge o/master. Now our master branch reflects the new work from the remote (in this case, named origin)
What would happen if we used git pull instead?

git pull

The same thing! That should make it very clear that git pull is essentially shorthand for a git fetch followed by a merge of whatever branch was just fetched.


We will explore the details of git pull later (including options and arguments), but for now let's try it out in the level.
Remember -- you can actually solve this level with just fetch and merge, but it will cost you an extra command :P
- git pull




Simulating collaboration
So here is the tricky thing -- for some of these upcoming lessons, we need to teach you how to pull down changes that were introduced in the remote.
That means we need to essentially "pretend" that the remote was updated by one of your coworkers / friends / collaborators, sometimes on a specific branch or a certain number of commits.
In order to do this, we introduced the aptly-named command git fakeTeamwork! It's pretty self explanatory, let's see a demo...
The default behavior of fakeTeamwork is to simply plop down a commit on master

git fakeTeamwork

There we go -- the remote was updated with a new commit, and we haven't downloaded that commit yet because we haven't run git fetch.
You can also specify the number of commits or the branch by appending them to the command

git fakeTeamwork foo 3

With one command we simulated a teammate pushing three commits to the foo branch on our remote
The upcoming levels are going to be pretty difficult, so we're asking more of you for this level.

Go ahead and make a remote (with git clone), fake some changes on that remote, commit yourself, and then pull down those changes. It's like a few lessons in one!
$ git clone

$ git fakeTeamwork 2

$ git commit

$ git pull




Git Push
Ok, so I've fetched changes from remote and incorporated them into my work locally. That's great and all... but how do I share my awesome work with everyone else?
Well, the way to upload shared work is the opposite of downloading shared work. And what's the opposite of git pull? git push!
git push is responsible for uploading your changes to a specified remote and updating that remote to incorporate your new commits. Once git push completes, all your friends can then download your work from the remote.
You can think of git push as a command to "publish" your work. It has a bunch of subtleties that we will get into shortly, but let's start with baby steps...
note -- the behavior of git push with no arguments varies depending on one of git's settings called push.default. The default value for this setting depends on the version of git you're using, but we are going to use the upstream value in our lessons. This isn't a huge deal, but it's worth checking your settings before pushing in your own projects.
Here we have some changes that the remote does not have. Let's upload them!

git push

There we go -- the remote received commit C2, the branch master on the remote was updated to point at C2, and our own reflection of the remote (o/master) was updated as well. Everything is in sync!
To finish this level, simply share two new commits with the remote. Strap in though, because these lessons are about to get a lot harder!
- git commit 
- git commit
- git push




Diverged Work
So far we've seen how to pull down commits from others and how to push up our own changes. It seems pretty simple, so how can people get so confused?

The difficulty comes in when the history of the repository diverges. Before discussing the details of this, let's see an example...
Imagine you clone a repository on Monday and start dabbling on a side feature. By Friday you are ready to publish your feature -- but oh no! Your coworkers have written a bunch of code during the week that's made your feature out of date (and obsolete). They've also published these commits to the shared remote repository, so now your work is based on an old version of the project that's no longer relevant.
In this case, the command git push is ambiguous. If you run git push, should git change the remote repository back to what it was on Monday? Should it try to add your code in while not removing the new code? Or should it totally ignore your changes since they are totally out of date?
Because there is so much ambiguity in this situation (where history has diverged), git doesn't allow you to push your changes. It actually forces you to incorporate the latest state of the remote before being able to share your work.

So much talking! Let's see this situation in action

git push

See? Nothing happened because the command fails. git push fails because your most recent commit C3 is based off of the remote at C1. The remote has since been updated to C2 though, so git rejects your push
How do you resolve this situation? It's easy, all you need to do is base your work off of the most recent version of the remote branch.

There are a few ways to do this, but the most straightforward is to move your work via rebasing. Let's go ahead and see what that looks like.
Now if we rebase before pushing instead...

git fetch; git rebase o/master; git push

Boom! We updated our local representation of the remote with git fetch, rebased our work to reflect the new changes in the remote, and then pushed them with git push
Are there other ways to update my work when the remote repository has been updated? Of course! Let's check out the same thing but with merge instead.
Although git merge doesn't move your work (and instead just creates a merge commit), it's a way to tell git that you have incorporated all the changes from the remote. This is because the remote branch is now an ancestor of your own branch, meaning your commit reflects all commits in the remote branch.
Lets see this demonstrated...
Now if we merge instead of rebasing...

git fetch; git merge o/master; git push

Boom! We updated our local representation of the remote with git fetch, merged the new work into our work (to reflect the new changes in the remote), and then pushed them with git push
Awesome! Is there any way I can do this without typing so many commands?
Of course -- you already know git pull is just shorthand for a fetch and a merge. Conveniently enough, git pull --rebase is shorthand for a fetch and a rebase!
Let's see these shorthand commands at work.
First with --rebase...

git pull --rebase; git push

Same as before! Just a lot shorter.
And now with regular pull

git pull; git push

Again, exact same as before!

This workflow of fetching, rebase/merging, and pushing is quite common. In future lessons we will examine more complicated versions of these workflows, but for now let's try this out.

In order to solve this level, take the following steps:

	Clone your repo
	Fake some teamwork (1 commit)
	Commit some work yourself (1 commit)
	Publish your work via rebasing


-git clone
-git fakeTeamwork 1
-git commit
-git pull -rebase
-git push




Merging feature branches
Now that you're comfortable with fetching, pulling, and pushing, lets put these skills to the test with a new workflow.

It's common for developers on big projects to do all their work on feature branches (off of master) and then integrate that work only once it's ready. This is similar to the previous lesson (where side branches get pushed to the remote), but here we introduce one more step.

Some developers only push and pull when on the master branch -- that way master always stays updated to what is on the remote (o/master).

So for this workflow we combine two things:

	integrating feature branch work onto master, and
	pushing and pulling from the remote
Let's see a refresher real quick of how to update master and push work.

git pull --rebase; git push

We executed two commands here that:

	rebased our work onto new commits from remote, and
	published our work to the remote


This level is pretty hefty -- here is the general outline to solve:

	There are three feature branches -- side1 side2 and side3
	We want to push each one of these features, in order, to the remote
	The remote has since been updated, so we will need to incorporate that work as well
:O intense! good luck, completing this level is a big step.

$ git fetch

$ git rebase o/master side1

$ git rebase side1 side2

$ git rebase side2 side3

$ git rebase side3 master

$ git push



Why not merge?
In order to push new updates to the remote, all you need to do is incorporate the latest changes from the remote. That means you can either rebase or merge in the remote branch (e.g. o/master).

So if you can do either method, why have the lessons focused on rebasing so far? Why is there no love for merge when working with remotes?

There's a lot of debate about the tradeoffs between merging and rebasing in the development community. Here are the general pros / cons of rebasing:

Pros:

	Rebasing makes your commit tree look very clean since everything is in a straight line
Cons:

	Rebasing modifies the (apparent) history of the commit tree.
For example, commit C1 can be rebased past C3. It then appears that the work for C1' came after C3 when in reality it was completed beforehand.

Some developers love to preserve history and thus prefer merging. Others (like myself) prefer having a clean commit tree and prefer rebasing. It all comes down to preferences :D
For this level, let's try to solve the previous level but with merging instead. It may get a bit hairy but it illustrates the point well.

$ git checkout master

$ git pull

$ git merge side1

$ git merge side2

$ git merge side3

$ git push





Remote-Tracking branches
One thing that might have seemed "magical" about the last few lessons is that git knew the master branch was related to o/master. Sure these branches have similar names and it might make logical sense to connect the master branch on the remote to the local master branch, but this connection is demonstrated clearly in two scenarios:
	During a pull operation, commits are downloaded onto o/master and then merged into the master branch. The implied target of the merge is determined from this connection.
	During a push operation, work from the master branch was pushed onto the remote's master branch (which was then represented by o/master locally). The destination of the push is determined from the connection between master and o/master.

Remote tracking
Long story short, this connection between master and o/master is explained simply by the "remote tracking" property of branches. The master branch is set to track o/master -- this means there is an implied merge target and implied push destination for the master branch.
You may be wondering how this property got set on the master branch when you didn't run any commands to specify it. Well, when you clone a repository with git, this property is actually set for you automatically.
During a clone, git creates a remote branch for every branch on the remote (aka branches like o/master). It then creates a local branch that tracks the currently active branch on the remote, which is master in most cases.
Once git clone is complete, you only have one local branch (so you aren't overwhelmed) but you can see all the different branches on the remote (if you happen to be very curious). It's the best of both worlds!
This also explains why you may see the following command output when cloning:
local branch "master" set to track remote branch "o/master"


Can I specify this myself?
Yes you can! You can make any arbitrary branch track o/master, and if you do so, that branch will have the same implied push destination and merge target as master. This means you can run git push on a branch named totallyNotMaster and have your work pushed to the master branch on the remote!

There are two ways to set this property. The first is to checkout a new branch by using a remote branch as the specified ref. Running

git checkout -b totallyNotMaster o/master

Creates a new branch named totallyNotMaster and sets it to track o/master.
Enough talking, let's see a demonstration! We will checkout a new branch named foo and set it to track master on the remote.

git checkout -b foo o/master; git pull

As you can see, we used the implied merge target of o/master to update the foo branch. Note how master doesn't get updated!!
This also applies for git push

git checkout -b foo o/master; git commit; git push

Boom. We pushed our work to the master on the remote even though our branch was named something totally different


Way #2
Another way to set remote tracking on a branch is to simply use the git branch -u option. Running

git branch -u o/master foo

will set the foo branch to track o/master. If foo is currently checked out you can even leave it off:

git branch -u o/master
Let's see this other way of specifying remote tracking real quick...

git branch -u o/master foo; git commit; git push

Same as before, just a more explicit command. Sweet!


Ok! For this level let's push work onto the master branch on remote while not checked out on master locally. I'll let you figure out the rest since this is the advanced course :P

$ git checkout -b side o/master

$ git commit

$ git pull --rebase

$ git push



Push arguments
Great! Now that you know about remote tracking branches we can start to uncover some of the mystery behind how git push, fetch, and pull work. We're going to tackle one command at a time but the concepts between them are very similar.
First we'll look at git push. You learned in the remote tracking lesson that git figured out the remote and the branch to push to by looking at the properties of the currently checked out branch (the remote that it "tracks"). This is the behavior with no arguments specified, but git push can optionally take arguments in the form of:

git push <remote> <place>


What is a <place> parameter you say? We'll dive into the specifics soon, but first an example. Issuing the command:

git push origin master

translates to this in English:
Go to the branch named "master" in my repository, grab all the commits, and then go to the branch "master" on the remote named "origin." Place whatever commits are missing on that branch and then tell me when you're done.
By specifying master as the "place" argument, we told git where the commits will come from and where the commits will go. It's essentially the "place" or "location" to synchronize between the two repositories.
Keep in mind that since we told git everything it needs to know (by specifying both arguments), it totally ignores where we are checked out!

Let's see an example of specifying the arguments. Note the location where we are checked out in this example.

git checkout C0; git push origin master

There we go! master got updated on the remote since we specified those arguments.
What if we hadn't specified the arguments? What would happen?

git checkout C0; git push

The command fails (as you can see), since HEAD is not checked out on a remote-tracking branch.
Ok, for this level let's update both foo and master on the remote. The twist is that git checkout is disabled for this level!

Note: The remote branches are labeled with o/ prefixes because the full origin/ label does not fit in our UI. Don't worry about this... simply use origin as the name of the remote like normal.

$ git push origin master

$ git push origin foo




<place> argument details
Remember from the previous lesson that when we specified master as the place argument for git push, we specified both the source of where the commits would come from and the destination of where the commits would go.
You might then be wondering -- what if we wanted the source and destination to be different? What if you wanted to push commits from the foo branch locally onto the bar branch on remote?
Well unfortunately that's impossible in git... just kidding! Of course it's possible :)... git has tons and tons of flexibility (almost too much).

Let's see how in the next slide...


In order to specify both the source and the destination of <place>, simply join the two together with a colon:

git push origin <source>:<destination>

This is commonly referred to as a colon refspec. Refspec is just a fancy name for a location that git can figure out (like the branch foo or even just HEAD~1)
Once you are specifying both the source and destination independently, you can get quite fancy and precise with remote commands. Let's see a demo!
Remember, source is any location that git will understand:

git push origin foo^:master

Woah! That's a pretty trippy command but it makes sense -- git resolved foo^ into a location, uploaded whatever commits that weren't present yet on the remote, and then updated destination.
What if the destination you want to push doesn't exist? No problem! Just give a branch name and git will create the branch on the remote for you.

git push origin master:newBranch

Sweet, that's pretty slick :D
For this level, try to get to the end goal state shown in the visualization, and remember the format of:

<source>:<destination>
$ git push origin master^:foo

$ git push origin foo:master




Git fetch arguments
So we've just learned all about git push arguments, this cool <place> parameter, and even colon refspecs (<source>:<destination>). Can we use all this knowledge for git fetch as well?
You betcha! The arguments for git fetch are actually very, very similar to those for git push. It's the same type of concepts but just applied in the opposite direction (since now you are downloading commits rather than uploading).
Let's go over the concepts one at a time...

The <place> parameter
If you specify a place with git fetch like in the following command:

git fetch origin foo

Git will go to the foo branch on the remote, grab all the commits that aren't present locally, and then plop them down onto the o/foo branch locally.

Let's see this in action (just as a refresher).
By specifying a place...

git fetch origin foo

We download only the commits from foo and place them on o/foo
You might be wondering -- why did git plop those commits onto the o/foo remote branch rather than just plopping them onto my local foo branch? I thought the <place> parameter is a place that exists both locally and on the remote?

Well git makes a special exception in this case because you might have work on the foo branch that you don't want to mess up!! This ties into the earlier lesson on git fetch -- it doesn't update your local non-remote branches, it only downloads the commits (so you can inspect / merge them later).

"Well in that case, what happens if I explicitly define both the source and destination with <source>:<destination>?"
If you feel passionate enough to fetch commits directly onto a local branch, then yes you can specify that with a colon refspec. You can't fetch commits onto a branch that is checked out, but otherwise git will allow this.
Here is the only catch though -- <source> is now a place on the remote and <destination> is a local place to put those commits. It's the exact opposite of git push, and that makes sense since we are transferring data in the opposite direction!
That being said, developers rarely do this in practice. I'm introducing it mainly as a way to conceptualize how fetch and push are quite similar, just in opposite directions.
Let's see this craziness in action:

git fetch origin foo~1:bar

Wow! See, git resolved foo~1 as a place on the origin and then downloaded those commits to bar (which was a local branch). Notice how foo and o/foo were not updated since we specified a destination.
What if the destination doesn't exist before I run the command? Let's see the last slide but without bar existing beforehand.

git fetch origin foo~1:bar

See, it's JUST like git push. Git made the destination locally before fetching, just like git will make the destination on remote before pushing (if it doesn't exist).
No args?

If git fetch receives no arguments, it just downloads all the commits from the remote onto all the remote branches...

git fetch

Pretty simple, but worth going over just once.

Ok, enough talking! To finish this level, fetch just the specified commits in the goal visualization. Get fancy with those commands!

You will have to specify the source and destination for both fetch commands. Pay attention to the goal visualization since the IDs may be switched around!
$ git fetch origin master~1:foo

$ git fetch origin foo:master

$ git checkout foo

$ git merge master





Oddities of <source>
Git abuses the <source> parameter in two weird ways. These two abuses come from the fact that you can technically specify "nothing" as a valid source for both git push and git fetch. The way you specify nothing is via an empty argument:

git push origin :side
git fetch origin :bugFix
Let's see what these do...
What does pushing "nothing" to a remote branch do? It deletes it!

git push origin :foo

There, we successfully deleted the foo branch on remote by pushing the concept of "nothing" to it. That kinda makes sense...
Finally, fetching "nothing" to a place locally actually makes a new branch

git fetch origin :bar

Very odd / bizarre, but whatever. That's git for you!
This is a quick level -- just delete one remote branch and create a new branch with git fetch to finish!

git push origin :foo
git fetch origin :bar




Git pull arguments
Now that you know pretty much everything there is to know about arguments for git fetch and git push, there's almost really nothing left to cover for git pull :)

That's because git pull at the end of the day is really just shorthand for a fetch followed by merging in whatever was just fetched. You can think of it as running git fetch with the same arguments specified and then merging in where those commits ended up.

This applies even when you use crazy-complicated arguments as well. Let's see some examples:
Here are some equivalent commands in git:

git pull origin foo is equal to:

git fetch origin foo; git merge o/foo

And...

git pull origin bar~1:bugFix is equal to:

git fetch origin bar~1:bugFix; git merge bugFix

See? git pull is really just shorthand for fetch + merge, and all git pull cares about is where the commits ended up (the destination argument that it figures out during fetch).

Lets see a demo:
If we specify the place to fetch, everything happens as before with fetch but we merge in whatever was just fetched

git pull origin master

See! by specifying master we downloaded commits onto o/master just as normal. Then we merged o/master to where we are, regardless of what was currently checked out.
Does it work with source and destination too? You bet! Let's see that:

git pull origin master:foo

Wow, that's a TON in one command. We created a new branch locally named foo, downloaded commits from remote's master onto that branch foo, and then merged that branch into our currently checked out branch bar. It's over 9000!!!

Ok to finish up, attain the state of the goal visualization. You'll need to download some commits, make some new branches, and merge those branches into other branches, but it shouldn't take many commands :P
$ git pull origin bar:foo

$ git pull origin master:side


